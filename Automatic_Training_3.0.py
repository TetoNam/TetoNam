"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¤– AI í›ˆë ¨ ì‹œìŠ¤í…œ v3.0 - ì°¨ì„¸ëŒ€ í†µí•© ìë™í™” ì‹œìŠ¤í…œ 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ ì£¼ìš” ê¸°ëŠ¥ ë° íŠ¹ì§•:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ”¥ v2.2 â†’ v3.0 ì£¼ìš” ì—…ê·¸ë ˆì´ë“œ (2025-08-16):
  âœ¨ ì™„ì „íˆ ì¬ì„¤ê³„ëœ ëª¨ë“ˆí™” ì•„í‚¤í…ì²˜
  ğŸ›¡ï¸ ê²¬ê³ í•œ ê²½ë¡œ ê²€ì¦ ë° ë³´ì•ˆ ì‹œìŠ¤í…œ
  ğŸ“Š ì‹¤ì‹œê°„ í•˜ë“œì›¨ì–´ ëª¨ë‹ˆí„°ë§ (CPU/GPU/NPU)
  ğŸ¨ Rich ê¸°ë°˜ ê³ ê¸‰ UI ì‹œìŠ¤í…œ
  ğŸ¤– AI ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ì˜¤ë¥˜ í•´ê²°
  ğŸ’¾ ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ ì‹œìŠ¤í…œ
  ğŸŒ ë‹¤êµ­ì–´ ì§€ì› (í•œêµ­ì–´/ì˜ì–´)
  âš¡ ì••ì¶•íŒŒì¼ AI ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ ê°•í™”
  ğŸ“ˆ ì˜ˆì¸¡ ë¶„ì„ ê¸°ë°˜ ì„±ëŠ¥ ìµœì í™”
  ğŸ”„ ì„¤ì • ë°±ì—…/ë³µì› ì‹œìŠ¤í…œ

ì‘ì„±ì: AI Training System Team
ë²„ì „: 3.0.0
ìµœì¢… ì—…ë°ì´íŠ¸: 2025-08-16
ë¼ì´ì„ ìŠ¤: MIT License
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import sys
import json
import yaml
import hashlib
import logging
import platform
import subprocess
import threading
import time
import traceback
import zipfile
import rarfile
import tarfile
import shutil
import psutil
import GPUtil
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union, Any
from dataclasses import dataclass, asdict
from enum import Enum
from datetime import datetime
import configparser
import locale

# Rich ë¼ì´ë¸ŒëŸ¬ë¦¬ - ê³ ê¸‰ í„°ë¯¸ë„ UI
try:
    from rich.console import Console
    from rich.panel import Panel
    from rich.table import Table
    from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn, TimeRemainingColumn
    from rich.layout import Layout
    from rich.live import Live
    from rich.text import Text
    from rich.prompt import Prompt, Confirm, IntPrompt
    from rich.tree import Tree
    from rich.align import Align
    from rich.columns import Columns
    from rich.syntax import Syntax
    from rich.markdown import Markdown
    from rich.rule import Rule
    RICH_AVAILABLE = True
except ImportError:
    RICH_AVAILABLE = False
    print("âš ï¸ Rich ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ í„°ë¯¸ë„ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
    print("ì„¤ì¹˜ ëª…ë ¹: pip install rich")

# NPU ëª¨ë‹ˆí„°ë§ (Windows)
try:
    import win32pdh
    import win32api
    NPU_MONITORING = platform.system() == "Windows"
except ImportError:
    NPU_MONITORING = False

# í…ì„œí”Œë¡œìš°/í† ì¹˜ ê´€ë ¨
try:
    import torch
    import torchvision
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

# OpenVINO (NPU ê°€ì†)
try:
    import openvino as ov
    OPENVINO_AVAILABLE = True
except ImportError:
    OPENVINO_AVAILABLE = False

# Ultralytics YOLO
try:
    from ultralytics import YOLO
    ULTRALYTICS_AVAILABLE = True
except ImportError:
    ULTRALYTICS_AVAILABLE = False

# PIL for image processing
try:
    from PIL import Image
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸŒ ë‹¤êµ­ì–´ ì§€ì› ì‹œìŠ¤í…œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class LanguageManager:
    """
    ë‹¤êµ­ì–´ ì§€ì›ì„ ìœ„í•œ ì–¸ì–´ ê´€ë¦¬ì í´ë˜ìŠ¤
    - ì‹œìŠ¤í…œ ë¡œì¼€ì¼ ìë™ ê°ì§€
    - í•œêµ­ì–´/ì˜ì–´ ë©”ì‹œì§€ ë™ì  ì „í™˜
    - ì‚¬ìš©ì ì„¤ì • ê¸°ë°˜ ì–¸ì–´ ì„ íƒ
    """
    
    def __init__(self):
        self.current_language = self._detect_system_language()
        self.messages = self._load_messages()
    
    def _detect_system_language(self) -> str:
        """ì‹œìŠ¤í…œ ì–¸ì–´ ìë™ ê°ì§€"""
        try:
            system_locale = locale.getdefaultlocale()[0]
            if system_locale and system_locale.startswith('ko'):
                return 'ko'
            return 'en'
        except:
            return 'ko'  # ê¸°ë³¸ê°’ì€ í•œêµ­ì–´
    
    def _load_messages(self) -> Dict[str, Dict[str, str]]:
        """ë‹¤êµ­ì–´ ë©”ì‹œì§€ ë¡œë“œ"""
        return {
            'ko': {
                'welcome': 'ğŸ¤– AI í›ˆë ¨ ì‹œìŠ¤í…œ v3.0ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!',
                'system_check': 'ì‹œìŠ¤í…œ í™˜ê²½ ê²€ì‚¬ ì¤‘...',
                'hardware_detect': 'í•˜ë“œì›¨ì–´ ìë™ ê°ì§€',
                'dataset_search': 'ë°ì´í„°ì…‹ ê²€ìƒ‰ ì¤‘...',
                'training_start': 'í›ˆë ¨ ì‹œì‘',
                'error_occurred': 'ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤',
                'help_command': 'ë„ì›€ë§ì„ ë³´ë ¤ë©´ !helpë¥¼ ì…ë ¥í•˜ì„¸ìš”',
                'workflow_select': 'ì›Œí¬í”Œë¡œìš°ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”',
                'auto_mode': 'ì™„ì „ ìë™ ëª¨ë“œ',
                'semi_auto_mode': 'ë°˜ìë™ ëª¨ë“œ',
                'manual_mode': 'ìˆ˜ë™ ëª¨ë“œ'
            },
            'en': {
                'welcome': 'ğŸ¤– Welcome to AI Training System v3.0!',
                'system_check': 'Checking system environment...',
                'hardware_detect': 'Auto-detecting hardware',
                'dataset_search': 'Searching datasets...',
                'training_start': 'Starting training',
                'error_occurred': 'An error occurred',
                'help_command': 'Type !help for help',
                'workflow_select': 'Please select workflow',
                'auto_mode': 'Full Auto Mode',
                'semi_auto_mode': 'Semi-Auto Mode',
                'manual_mode': 'Manual Mode'
            }
        }
    
    def get(self, key: str) -> str:
        """ì–¸ì–´ë³„ ë©”ì‹œì§€ ë°˜í™˜"""
        return self.messages.get(self.current_language, {}).get(key, key)
    
    def set_language(self, language: str):
        """ì–¸ì–´ ì„¤ì • ë³€ê²½"""
        if language in ['ko', 'en']:
            self.current_language = language

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“Š ì‹œìŠ¤í…œ ì„¤ì • ë° ìƒìˆ˜ ì •ì˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class SystemConstants:
    """ì‹œìŠ¤í…œ ì „ì—­ ìƒìˆ˜ ì •ì˜ í´ë˜ìŠ¤"""
    
    # ë²„ì „ ì •ë³´
    VERSION = "3.0.0"
    VERSION_DATE = "2025-08-16"
    
    # ì§€ì› íŒŒì¼ í™•ì¥ì
    ARCHIVE_EXTENSIONS = ['.zip', '.rar', '.7z', '.tar', '.tar.gz', '.tar.bz2']
    IMAGE_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']
    
    # ê²€ìƒ‰ ìš°ì„  í´ë”
    PRIORITY_FOLDERS = [
        "Desktop", "Downloads", "Documents", "Pictures", "Videos",
        "ë°”íƒ•í™”ë©´", "ë‹¤ìš´ë¡œë“œ", "ë¬¸ì„œ", "ì‚¬ì§„", "ë™ì˜ìƒ"
    ]
    
    # ë¡œê·¸ ë ˆë²¨
    LOG_LEVELS = {
        'CRITICAL': 50,
        'ERROR': 40,
        'WARNING': 30,
        'INFO': 20,
        'DEBUG': 10
    }
    
    # í•˜ë“œì›¨ì–´ ëª¨ë‹ˆí„°ë§ ê°„ê²© (ì´ˆ)
    MONITORING_INTERVAL = 5.0  # 1.0ì—ì„œ 5.0ìœ¼ë¡œ ë³€ê²½
    TRAINING_MONITORING_INTERVAL = 10.0  # í›ˆë ¨ ì¤‘ì—ëŠ” ë” ëŠë¦¬ê²Œ
    
    # AI ê²€ìƒ‰ ê°€ì¤‘ì¹˜
    AI_SEARCH_WEIGHTS = {
        'filename_match': 0.4,
        'extension_match': 0.2,
        'path_priority': 0.2,
        'file_size': 0.1,
        'creation_date': 0.1
    }

@dataclass
class SystemConfig:
    """ì‹œìŠ¤í…œ ì„¤ì • ë°ì´í„° í´ë˜ìŠ¤"""
    
    # ì¼ë°˜ ì„¤ì •
    language: str = 'ko'
    log_level: str = 'INFO'
    auto_backup: bool = True
    check_updates: bool = True
    
    # í•˜ë“œì›¨ì–´ ì„¤ì •
    use_gpu: bool = True
    use_npu: bool = True
    gpu_memory_fraction: float = 0.8
    
    # ë°ì´í„°ì…‹ ì„¤ì •
    auto_extract: bool = True
    verify_integrity: bool = True
    max_search_depth: int = 5
    
    # í›ˆë ¨ ì„¤ì •
    default_epochs: int = 100
    batch_size: int = 32
    learning_rate: float = 0.001
    
    def to_dict(self) -> Dict[str, Any]:
        """ì„¤ì •ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return asdict(self)
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'SystemConfig':
        """ë”•ì…”ë„ˆë¦¬ì—ì„œ ì„¤ì • ìƒì„± (ë©”íƒ€ë°ì´í„° ì œì™¸)"""
        # ë©”íƒ€ë°ì´í„° ì œê±°
        config_data = {k: v for k, v in data.items() if not k.startswith('_')}
        
        # SystemConfigì— ì •ì˜ë˜ì§€ ì•Šì€ í‚¤ ì œê±°
        valid_keys = {field.name for field in cls.__dataclass_fields__.values()}
        filtered_data = {k: v for k, v in config_data.items() if k in valid_keys}
        
        return cls(**filtered_data)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”§ ê³ ê¸‰ ë¡œê¹… ì‹œìŠ¤í…œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AdvancedLogger:
    """
    5ë‹¨ê³„ ë¡œê·¸ ë ˆë²¨ì„ ì§€ì›í•˜ëŠ” ê³ ê¸‰ ë¡œê¹… ì‹œìŠ¤í…œ
    - íŒŒì¼ê³¼ ì½˜ì†” ì¶œë ¥ ë¶„ë¦¬
    - Rich ê¸°ë°˜ ì»¬ëŸ¬ ë¡œê¹…
    - ìë™ ë¡œê·¸ ë¡œí…Œì´ì…˜
    """
    
    def __init__(self, name: str = "AITrainingSystem", log_dir: str = "logs"):
        self.name = name
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        
        # Rich ì½˜ì†” ì„¤ì •
        self.console = Console() if RICH_AVAILABLE else None
        
        # ë¡œê±° ì„¤ì •
        self.logger = logging.getLogger(name)
        self.logger.setLevel(logging.DEBUG)
        
        # í•¸ë“¤ëŸ¬ ì„¤ì •
        self._setup_handlers()
    
    def _setup_handlers(self):
        """ë¡œê·¸ í•¸ë“¤ëŸ¬ ì„¤ì •"""
        # íŒŒì¼ í•¸ë“¤ëŸ¬
        log_file = self.log_dir / f"{self.name}_{datetime.now().strftime('%Y%m%d')}.log"
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.DEBUG)
        
        # í¬ë§·í„°
        formatter = logging.Formatter(
            '%(asctime)s | %(levelname)-8s | %(name)s | %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        file_handler.setFormatter(formatter)
        
        self.logger.addHandler(file_handler)
    
    def debug(self, message: str):
        """ë””ë²„ê·¸ ë¡œê·¸"""
        self.logger.debug(message)
        if self.console:
            self.console.print(f"ğŸ” [dim]{message}[/dim]")
    
    def info(self, message: str):
        """ì •ë³´ ë¡œê·¸"""
        self.logger.info(message)
        if self.console:
            self.console.print(f"â„¹ï¸ {message}")
    
    def warning(self, message: str):
        """ê²½ê³  ë¡œê·¸"""
        self.logger.warning(message)
        if self.console:
            self.console.print(f"âš ï¸ [yellow]{message}[/yellow]")
    
    def error(self, message: str):
        """ì˜¤ë¥˜ ë¡œê·¸"""
        self.logger.error(message)
        if self.console:
            self.console.print(f"âŒ [red]{message}[/red]")
    
    def critical(self, message: str):
        """ì¹˜ëª…ì  ì˜¤ë¥˜ ë¡œê·¸"""
        self.logger.critical(message)
        if self.console:
            self.console.print(f"ğŸš¨ [bold red]{message}[/bold red]")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ›¡ï¸ ë³´ì•ˆ ë° ê²½ë¡œ ê²€ì¦ ì‹œìŠ¤í…œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class SecurityManager:
    """
    ë³´ì•ˆ ë° ê²½ë¡œ ê²€ì¦ì„ ìœ„í•œ ê´€ë¦¬ì í´ë˜ìŠ¤
    - ì…ë ¥ ê²€ì¦ ë° SQL ì¸ì ì…˜ ë°©ì§€
    - ê²½ë¡œ íƒìƒ‰ ê³µê²© ë°©ì§€
    - ê¶Œí•œ ê´€ë¦¬ ì‹œìŠ¤í…œ
    """
    
    def __init__(self, logger: AdvancedLogger):
        self.logger = logger
        self.dangerous_patterns = [
            r'\.\./', r'\.\.\\', r'\.\./\.\.',
            r'<script', r'javascript:',
            r'SELECT.*FROM', r'DROP.*TABLE',
            r'EXEC.*sp_', r'UNION.*SELECT'
        ]
    
    def validate_input(self, user_input: str) -> bool:
        """ì‚¬ìš©ì ì…ë ¥ ê²€ì¦"""
        import re
        
        for pattern in self.dangerous_patterns:
            if re.search(pattern, user_input, re.IGNORECASE):
                self.logger.warning(f"ìœ„í—˜í•œ ì…ë ¥ íŒ¨í„´ ê°ì§€: {pattern}")
                return False
        
        return True
    
    def validate_path(self, path: Union[str, Path]) -> Tuple[bool, Optional[Path]]:
        """ê²½ë¡œ ê²€ì¦ ë° ì •ê·œí™”"""
        try:
            path_obj = Path(path).resolve()
            
            # ìœ„í—˜í•œ ì‹œìŠ¤í…œ ê²½ë¡œ ì²´í¬
            dangerous_paths = [
                Path.home() / "AppData" / "Roaming" / "Microsoft" / "Windows",
                Path("C:/Windows/System32"),
                Path("/etc"),
                Path("/usr/bin")
            ]
            
            for dangerous_path in dangerous_paths:
                try:
                    if path_obj.is_relative_to(dangerous_path):
                        self.logger.warning(f"ìœ„í—˜í•œ ì‹œìŠ¤í…œ ê²½ë¡œ ì ‘ê·¼ ì‹œë„: {path_obj}")
                        return False, None
                except (OSError, ValueError):
                    continue
            
            return True, path_obj
            
        except (OSError, ValueError) as e:
            self.logger.error(f"ê²½ë¡œ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False, None
    
    def check_file_permissions(self, path: Path) -> Dict[str, bool]:
        """íŒŒì¼ ê¶Œí•œ í™•ì¸"""
        permissions = {
            'readable': False,
            'writable': False,
            'executable': False
        }
        
        try:
            permissions['readable'] = os.access(path, os.R_OK)
            permissions['writable'] = os.access(path, os.W_OK)
            permissions['executable'] = os.access(path, os.X_OK)
        except Exception as e:
            self.logger.error(f"ê¶Œí•œ í™•ì¸ ì‹¤íŒ¨: {e}")
        
        return permissions

# Part 1ì—ì„œ ì´ì–´ì§‘ë‹ˆë‹¤...

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“Š ì‹¤ì‹œê°„ í•˜ë“œì›¨ì–´ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class HardwareMonitor:
    """
    CPU, GPU, NPU ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
    - ì‹¤ì‹œê°„ ì„±ëŠ¥ ì¶”ì 
    - ì˜ˆì¸¡ ë¶„ì„ ê¸°ë°˜ ë³‘ëª© í˜„ìƒ ê°ì§€
    - í•˜ë“œì›¨ì–´ë³„ ìµœì í™” ì œì•ˆ
    """
    
    def __init__(self, logger: AdvancedLogger):
        self.logger = logger
        self.monitoring = False
        self.monitor_thread = None
        self.performance_history = {
            'cpu': [],
            'memory': [],
            'gpu': [],
            'npu': []
        }
        
        # NPU ëª¨ë‹ˆí„°ë§ ì´ˆê¸°í™”
        self.npu_available = NPU_MONITORING
        if self.npu_available:
            self._init_npu_monitoring()
    
    def _init_npu_monitoring(self):
        """NPU ëª¨ë‹ˆí„°ë§ ì´ˆê¸°í™” (Windows Intel NPU)"""
        try:
            # Intel NPU ì„±ëŠ¥ ì¹´ìš´í„° ì´ˆê¸°í™”
            self.npu_counter = None
            if NPU_MONITORING:
                # win32pdhë¥¼ ì‚¬ìš©í•œ NPU ëª¨ë‹ˆí„°ë§ ì„¤ì •
                pass  # ì‹¤ì œ êµ¬í˜„ì‹œ Intel NPU SDK í•„ìš”
        except Exception as e:
            self.logger.warning(f"NPU ëª¨ë‹ˆí„°ë§ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.npu_available = False
    
    def get_cpu_info(self) -> Dict[str, Any]:
        """CPU ì •ë³´ ìˆ˜ì§‘"""
        try:
            cpu_percent = psutil.cpu_percent(interval=1)
            cpu_freq = psutil.cpu_freq()
            cpu_count = psutil.cpu_count()
            
            return {
                'usage_percent': cpu_percent,
                'frequency_mhz': cpu_freq.current if cpu_freq else 0,
                'core_count': cpu_count,
                'temperature': self._get_cpu_temperature()
            }
        except Exception as e:
            self.logger.error(f"CPU ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {}
    
    def _get_cpu_temperature(self) -> Optional[float]:
        """CPU ì˜¨ë„ ì¸¡ì • (ê°€ëŠ¥í•œ ê²½ìš°)"""
        try:
            if hasattr(psutil, "sensors_temperatures"):
                temps = psutil.sensors_temperatures()
                if temps:
                    for name, entries in temps.items():
                        if 'cpu' in name.lower() or 'core' in name.lower():
                            return entries[0].current if entries else None
        except Exception:
            pass
        return None
    
    def get_memory_info(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ì •ë³´ ìˆ˜ì§‘"""
        try:
            memory = psutil.virtual_memory()
            swap = psutil.swap_memory()
            
            return {
                'total_gb': round(memory.total / (1024**3), 2),
                'available_gb': round(memory.available / (1024**3), 2),
                'used_percent': memory.percent,
                'swap_used_percent': swap.percent
            }
        except Exception as e:
            self.logger.error(f"ë©”ëª¨ë¦¬ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {}
    
    def get_gpu_info(self) -> List[Dict[str, Any]]:
        """GPU ì •ë³´ ìˆ˜ì§‘"""
        gpu_info = []
        
        try:
            # NVIDIA GPU ì •ë³´
            gpus = GPUtil.getGPUs()
            for gpu in gpus:
                gpu_info.append({
                    'id': gpu.id,
                    'name': gpu.name,
                    'load_percent': round(gpu.load * 100, 2),
                    'memory_used_mb': gpu.memoryUsed,
                    'memory_total_mb': gpu.memoryTotal,
                    'memory_percent': round((gpu.memoryUsed / gpu.memoryTotal) * 100, 2),
                    'temperature': gpu.temperature
                })
        except Exception as e:
            self.logger.warning(f"NVIDIA GPU ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        # PyTorch CUDA ì •ë³´ ì¶”ê°€
        if TORCH_AVAILABLE and torch.cuda.is_available():
            try:
                for i in range(torch.cuda.device_count()):
                    device_name = torch.cuda.get_device_name(i)
                    memory_allocated = torch.cuda.memory_allocated(i) / (1024**2)  # MB
                    memory_reserved = torch.cuda.memory_reserved(i) / (1024**2)   # MB
                    
                    # ê¸°ì¡´ GPU ì •ë³´ì™€ ë³‘í•©í•˜ê±°ë‚˜ ìƒˆë¡œ ì¶”ê°€
                    found = False
                    for gpu in gpu_info:
                        if device_name in gpu['name']:
                            gpu.update({
                                'torch_memory_allocated_mb': memory_allocated,
                                'torch_memory_reserved_mb': memory_reserved
                            })
                            found = True
                            break
                    
                    if not found:
                        gpu_info.append({
                            'id': i,
                            'name': device_name,
                            'load_percent': 0,
                            'memory_used_mb': 0,
                            'memory_total_mb': 0,
                            'memory_percent': 0,
                            'temperature': 0,
                            'torch_memory_allocated_mb': memory_allocated,
                            'torch_memory_reserved_mb': memory_reserved
                        })
            except Exception as e:
                self.logger.warning(f"PyTorch CUDA ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return gpu_info
    
    def get_npu_info(self) -> Dict[str, Any]:
        """NPU ì •ë³´ ìˆ˜ì§‘ (Intel NPU ìš°ì„  ì§€ì›)"""
        npu_info = {
            'available': self.npu_available,
            'usage_percent': 0,
            'temperature': 0,
            'power_watts': 0
        }
        
        if not self.npu_available:
            return npu_info
        
        try:
            # Intel NPU ëª¨ë‹ˆí„°ë§ (ì‹¤ì œ êµ¬í˜„ì‹œ Intel NPU SDK í•„ìš”)
            # ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
            if NPU_MONITORING:
                # win32pdhë¥¼ í†µí•œ NPU ì„±ëŠ¥ ì¹´ìš´í„° ì½ê¸°
                pass
                
            # OpenVINOë¥¼ í†µí•œ NPU ìƒíƒœ í™•ì¸
            if OPENVINO_AVAILABLE:
                try:
                    core = ov.Core()
                    available_devices = core.available_devices
                    
                    npu_devices = [device for device in available_devices if 'NPU' in device]
                    if npu_devices:
                        npu_info['devices'] = npu_devices
                        npu_info['available'] = True
                except Exception as e:
                    self.logger.debug(f"OpenVINO NPU í™•ì¸ ì‹¤íŒ¨: {e}")
        
        except Exception as e:
            self.logger.warning(f"NPU ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return npu_info
    
    def start_monitoring(self):
        """ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if self.monitoring:
            return
        
        self.monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.monitor_thread.start()
        self.logger.info("í•˜ë“œì›¨ì–´ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
    
    def stop_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=2)
        self.logger.info("í•˜ë“œì›¨ì–´ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")
    
    def _monitor_loop(self):
        """ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while self.monitoring:
            try:
                # ì„±ëŠ¥ ë°ì´í„° ìˆ˜ì§‘
                cpu_info = self.get_cpu_info()
                memory_info = self.get_memory_info()
                gpu_info = self.get_gpu_info()
                npu_info = self.get_npu_info()
                
                # íˆìŠ¤í† ë¦¬ì— ì €ì¥ (ìµœê·¼ 100ê°œë§Œ ìœ ì§€)
                timestamp = time.time()
                
                if cpu_info:
                    self.performance_history['cpu'].append({
                        'timestamp': timestamp,
                        **cpu_info
                    })
                
                if memory_info:
                    self.performance_history['memory'].append({
                        'timestamp': timestamp,
                        **memory_info
                    })
                
                if gpu_info:
                    self.performance_history['gpu'].append({
                        'timestamp': timestamp,
                        'gpus': gpu_info
                    })
                
                if npu_info:
                    self.performance_history['npu'].append({
                        'timestamp': timestamp,
                        **npu_info
                    })
                
                # íˆìŠ¤í† ë¦¬ í¬ê¸° ì œí•œ
                for key in self.performance_history:
                    if len(self.performance_history[key]) > 100:
                        self.performance_history[key] = self.performance_history[key][-100:]
                
                time.sleep(SystemConstants.MONITORING_INTERVAL)
                
            except Exception as e:
                self.logger.error(f"ëª¨ë‹ˆí„°ë§ ë£¨í”„ ì˜¤ë¥˜: {e}")
                time.sleep(1)
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ìš”ì•½ ì •ë³´ ë°˜í™˜"""
        current_data = {
            'cpu': self.get_cpu_info(),
            'memory': self.get_memory_info(),
            'gpu': self.get_gpu_info(),
            'npu': self.get_npu_info()
        }
        
        # ì˜ˆì¸¡ ë¶„ì„
        predictions = self._analyze_performance_trends()
        
        return {
            'current': current_data,
            'predictions': predictions,
            'recommendations': self._get_optimization_recommendations(current_data)
        }
    
    def _analyze_performance_trends(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„ ë° ì˜ˆì¸¡"""
        predictions = {}
        
        try:
            # CPU íŠ¸ë Œë“œ ë¶„ì„
            if len(self.performance_history['cpu']) >= 10:
                cpu_usage = [entry['usage_percent'] for entry in self.performance_history['cpu'][-10:]]
                avg_usage = sum(cpu_usage) / len(cpu_usage)
                trend = 'increasing' if cpu_usage[-1] > avg_usage else 'stable'
                
                predictions['cpu'] = {
                    'trend': trend,
                    'avg_usage': round(avg_usage, 2),
                    'bottleneck_risk': 'high' if avg_usage > 80 else 'low'
                }
            
            # ë©”ëª¨ë¦¬ íŠ¸ë Œë“œ ë¶„ì„
            if len(self.performance_history['memory']) >= 10:
                memory_usage = [entry['used_percent'] for entry in self.performance_history['memory'][-10:]]
                avg_usage = sum(memory_usage) / len(memory_usage)
                
                predictions['memory'] = {
                    'avg_usage': round(avg_usage, 2),
                    'bottleneck_risk': 'high' if avg_usage > 85 else 'low'
                }
        
        except Exception as e:
            self.logger.error(f"ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        return predictions
    
    def _get_optimization_recommendations(self, current_data: Dict[str, Any]) -> List[str]:
        """ìµœì í™” ì¶”ì²œì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        try:
            # CPU ìµœì í™”
            if current_data['cpu'].get('usage_percent', 0) > 80:
                recommendations.append("CPU ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì´ê±°ë‚˜ í•™ìŠµë¥ ì„ ì¡°ì •í•´ë³´ì„¸ìš”.")
            
            # ë©”ëª¨ë¦¬ ìµœì í™”  
            if current_data['memory'].get('used_percent', 0) > 85:
                recommendations.append("ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ë°ì´í„° ë¡œë”ì˜ num_workersë¥¼ ì¤„ì—¬ë³´ì„¸ìš”.")
            
            # GPU ìµœì í™”
            for gpu in current_data.get('gpu', []):
                if gpu.get('memory_percent', 0) > 90:
                    recommendations.append(f"GPU {gpu['id']} ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì—¬ë³´ì„¸ìš”.")
                elif gpu.get('load_percent', 0) < 30:
                    recommendations.append(f"GPU {gpu['id']} í™œìš©ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ë°°ì¹˜ í¬ê¸°ë¥¼ ëŠ˜ë ¤ë³´ì„¸ìš”.")
            
            # NPU ìµœì í™”
            if current_data['npu'].get('available') and OPENVINO_AVAILABLE:
                recommendations.append("NPUê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. OpenVINOë¥¼ í†µí•œ ëª¨ë¸ ìµœì í™”ë¥¼ ê³ ë ¤í•´ë³´ì„¸ìš”.")
        
        except Exception as e:
            self.logger.error(f"ìµœì í™” ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {e}")
        
        return recommendations

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ’¾ ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ ì‹œìŠ¤í…œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class DataIntegrityManager:
    """
    ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ ë° ì²´í¬ì„¬ ê´€ë¦¬ ì‹œìŠ¤í…œ
    - SHA-256, CRC32 ë‹¤ì¤‘ í•´ì‹œ ì•Œê³ ë¦¬ì¦˜
    - íŒŒì¼ ì†ìƒ ê°ì§€ ë° ë³µêµ¬
    - ì¦ë¶„ ë°±ì—… ì‹œìŠ¤í…œ
    """
    
    def __init__(self, logger: AdvancedLogger):
        self.logger = logger
        self.checksum_cache = {}
        self.backup_dir = Path("backups")
        self.backup_dir.mkdir(exist_ok=True)
    
    def calculate_file_hash(self, file_path: Path, algorithm: str = 'sha256') -> Optional[str]:
        """íŒŒì¼ í•´ì‹œ ê³„ì‚°"""
        try:
            hash_obj = hashlib.new(algorithm)
            
            with open(file_path, 'rb') as f:
                # ëŒ€ìš©ëŸ‰ íŒŒì¼ì„ ìœ„í•œ ì²­í¬ ë‹¨ìœ„ ì½ê¸°
                chunk_size = 65536  # 64KB
                while chunk := f.read(chunk_size):
                    hash_obj.update(chunk)
            
            return hash_obj.hexdigest()
            
        except Exception as e:
            self.logger.error(f"íŒŒì¼ í•´ì‹œ ê³„ì‚° ì‹¤íŒ¨ ({file_path}): {e}")
            return None
    
    def verify_file_integrity(self, file_path: Path) -> Dict[str, Any]:
        """íŒŒì¼ ë¬´ê²°ì„± ê²€ì¦"""
        result = {
            'path': str(file_path),
            'exists': file_path.exists(),
            'readable': False,
            'size': 0,
            'sha256': None,
            'crc32': None,
            'integrity_ok': False
        }
        
        if not result['exists']:
            return result
        
        try:
            # íŒŒì¼ ì ‘ê·¼ ê°€ëŠ¥ì„± í™•ì¸
            result['readable'] = os.access(file_path, os.R_OK)
            if not result['readable']:
                return result
            
            # íŒŒì¼ í¬ê¸°
            result['size'] = file_path.stat().st_size
            
            # í•´ì‹œ ê³„ì‚°
            result['sha256'] = self.calculate_file_hash(file_path, 'sha256')
            
            # CRC32 ê³„ì‚° (ë¹ ë¥¸ ê²€ì¦ìš©)
            with open(file_path, 'rb') as f:
                crc32_hash = 0
                chunk_size = 65536
                while chunk := f.read(chunk_size):
                    crc32_hash = zlib.crc32(chunk, crc32_hash)
                result['crc32'] = format(crc32_hash & 0xffffffff, '08x')
            
            # ìºì‹œëœ í•´ì‹œì™€ ë¹„êµ (ì´ì „ì— ê³„ì‚°í•œ ì ì´ ìˆë‹¤ë©´)
            cache_key = str(file_path)
            if cache_key in self.checksum_cache:
                cached = self.checksum_cache[cache_key]
                result['integrity_ok'] = (
                    cached['sha256'] == result['sha256'] and
                    cached['size'] == result['size']
                )
            else:
                # ì²« ë²ˆì§¸ ê³„ì‚°ì´ë¯€ë¡œ OKë¡œ ê°„ì£¼
                result['integrity_ok'] = True
                self.checksum_cache[cache_key] = {
                    'sha256': result['sha256'],
                    'crc32': result['crc32'],
                    'size': result['size'],
                    'timestamp': time.time()
                }
            
        except Exception as e:
            self.logger.error(f"íŒŒì¼ ë¬´ê²°ì„± ê²€ì¦ ì‹¤íŒ¨ ({file_path}): {e}")
        
        return result
    
    def batch_verify_integrity(self, file_paths: List[Path]) -> Dict[str, Any]:
        """ë‹¤ì¤‘ íŒŒì¼ ë¬´ê²°ì„± ì¼ê´„ ê²€ì¦"""
        results = {
            'total_files': len(file_paths),
            'verified_files': 0,
            'corrupted_files': 0,
            'inaccessible_files': 0,
            'details': []
        }
        
        for file_path in file_paths:
            verification = self.verify_file_integrity(file_path)
            results['details'].append(verification)
            
            if not verification['exists'] or not verification['readable']:
                results['inaccessible_files'] += 1
            elif verification['integrity_ok']:
                results['verified_files'] += 1
            else:
                results['corrupted_files'] += 1
        
        return results
    
    def create_backup(self, source_path: Path, backup_name: Optional[str] = None) -> Optional[Path]:
        """íŒŒì¼/í´ë” ë°±ì—… ìƒì„±"""
        try:
            if backup_name is None:
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                backup_name = f"{source_path.name}_{timestamp}"
            
            backup_path = self.backup_dir / backup_name
            
            if source_path.is_file():
                # íŒŒì¼ ë°±ì—…
                backup_path.parent.mkdir(parents=True, exist_ok=True)
                shutil.copy2(source_path, backup_path)
            elif source_path.is_dir():
                # í´ë” ë°±ì—…
                shutil.copytree(source_path, backup_path)
            
            # ë°±ì—… íŒŒì¼ ë¬´ê²°ì„± ê²€ì¦
            if backup_path.exists():
                verification = self.verify_file_integrity(backup_path)
                if verification['integrity_ok']:
                    self.logger.info(f"ë°±ì—… ìƒì„± ì™„ë£Œ: {backup_path}")
                    return backup_path
                else:
                    self.logger.error(f"ë°±ì—… íŒŒì¼ ë¬´ê²°ì„± ê²€ì¦ ì‹¤íŒ¨: {backup_path}")
                    return None
            
        except Exception as e:
            self.logger.error(f"ë°±ì—… ìƒì„± ì‹¤íŒ¨ ({source_path}): {e}")
        
        return None
    
    def restore_from_backup(self, backup_path: Path, restore_path: Path) -> bool:
        """ë°±ì—…ì—ì„œ íŒŒì¼ ë³µì›"""
        try:
            if not backup_path.exists():
                self.logger.error(f"ë°±ì—… íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {backup_path}")
                return False
            
            # ë°±ì—… íŒŒì¼ ë¬´ê²°ì„± ê²€ì¦
            verification = self.verify_file_integrity(backup_path)
            if not verification['integrity_ok']:
                self.logger.error(f"ë°±ì—… íŒŒì¼ì´ ì†ìƒë˜ì—ˆìŠµë‹ˆë‹¤: {backup_path}")
                return False
            
            # ë³µì› ëŒ€ìƒ ê²½ë¡œ ì¤€ë¹„
            restore_path.parent.mkdir(parents=True, exist_ok=True)
            
            # íŒŒì¼ ë³µì‚¬
            shutil.copy2(backup_path, restore_path)
            
            # ë³µì›ëœ íŒŒì¼ ê²€ì¦
            restored_verification = self.verify_file_integrity(restore_path)
            if restored_verification['integrity_ok']:
                self.logger.info(f"íŒŒì¼ ë³µì› ì™„ë£Œ: {restore_path}")
                return True
            else:
                self.logger.error(f"ë³µì›ëœ íŒŒì¼ ë¬´ê²°ì„± ê²€ì¦ ì‹¤íŒ¨: {restore_path}")
                return False
                
        except Exception as e:
            self.logger.error(f"íŒŒì¼ ë³µì› ì‹¤íŒ¨ ({backup_path} -> {restore_path}): {e}")
            return False
    
    def save_checksum_cache(self, cache_file: Path):
        """ì²´í¬ì„¬ ìºì‹œ ì €ì¥"""
        try:
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.checksum_cache, f, indent=2, ensure_ascii=False)
            self.logger.debug(f"ì²´í¬ì„¬ ìºì‹œ ì €ì¥ ì™„ë£Œ: {cache_file}")
        except Exception as e:
            self.logger.error(f"ì²´í¬ì„¬ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def load_checksum_cache(self, cache_file: Path):
        """ì²´í¬ì„¬ ìºì‹œ ë¡œë“œ"""
        try:
            if cache_file.exists():
                with open(cache_file, 'r', encoding='utf-8') as f:
                    self.checksum_cache = json.load(f)
                self.logger.debug(f"ì²´í¬ì„¬ ìºì‹œ ë¡œë“œ ì™„ë£Œ: {cache_file}")
        except Exception as e:
            self.logger.error(f"ì²´í¬ì„¬ ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”„ ì„¤ì • ë°±ì—… ë° ë³µì› ì‹œìŠ¤í…œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ConfigurationManager:
    """
    ì‚¬ìš©ì ì„¤ì • ìë™ ì €ì¥ ë° ë³µì› ì‹œìŠ¤í…œ
    - ë²„ì „ ê´€ë¦¬ ê¸°ëŠ¥
    - ì„¤ì • ë³€ê²½ ì´ë ¥ ì¶”ì 
    - ìë™ ë°±ì—… ë° ë³µì›
    """
    
    def __init__(self, logger: AdvancedLogger, config_dir: str = "configs"):
        self.logger = logger
        self.config_dir = Path(config_dir)
        self.config_dir.mkdir(exist_ok=True)
        
        self.config_file = self.config_dir / "system_config.json"
        self.backup_dir = self.config_dir / "backups"
        self.backup_dir.mkdir(exist_ok=True)
        
        # í˜„ì¬ ì„¤ì •
        self.current_config = SystemConfig()
        
        # ì„¤ì • ë³€ê²½ ì´ë ¥
        self.config_history = []
    
    def load_config(self) -> SystemConfig:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ - ë©”íƒ€ë°ì´í„° ì²˜ë¦¬ ê°œì„ """
        try:
            if self.config_file.exists():
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    config_data = json.load(f)
                
                # ë©”íƒ€ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë¡œê·¸ì— ê¸°ë¡í•˜ê³  ì œê±°
                if '_metadata' in config_data:
                    metadata = config_data.pop('_metadata')
                    self.logger.info(f"ì„¤ì • íŒŒì¼ ë©”íƒ€ë°ì´í„°: {metadata.get('saved_at', 'Unknown')}")
                
                # SystemConfig ìƒì„±
                self.current_config = SystemConfig.from_dict(config_data)
                self.logger.info("ì„¤ì • íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
            else:
                # ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì´ˆê¸° íŒŒì¼ ìƒì„±
                self.current_config = SystemConfig()
                self.save_config()
                self.logger.info("ê¸°ë³¸ ì„¤ì • íŒŒì¼ ìƒì„±")
                
        except Exception as e:
            self.logger.error(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.current_config = SystemConfig()  # ê¸°ë³¸ ì„¤ì • ì‚¬ìš©
        
        return self.current_config

    def save_config(self, backup: bool = True) -> bool:
        """ì„¤ì • íŒŒì¼ ì €ì¥ - ì•ˆì „í•œ ë©”íƒ€ë°ì´í„° ì²˜ë¦¬"""
        try:
            # ê¸°ì¡´ ì„¤ì • ë°±ì—…
            if backup and self.config_file.exists():
                self.create_config_backup()
            
            # í˜„ì¬ ì„¤ì •ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            config_data = self.current_config.to_dict()
            
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€ (ë³„ë„ í‚¤ë¡œ ì €ì¥)
            config_data['_metadata'] = {
                'version': SystemConstants.VERSION,
                'saved_at': datetime.now().isoformat(),
                'system_info': {
                    'platform': platform.system(),
                    'python_version': platform.python_version()
                }
            }
            
            # ì„ì‹œ íŒŒì¼ì— ë¨¼ì € ì €ì¥ (ì›ìì  ì“°ê¸°)
            temp_file = self.config_file.with_suffix('.tmp')
            with open(temp_file, 'w', encoding='utf-8') as f:
                json.dump(config_data, f, indent=2, ensure_ascii=False)
            
            # ì„±ê³µí•˜ë©´ ì›ë³¸ íŒŒì¼ë¡œ ì´ë™
            temp_file.replace(self.config_file)
            
            self.logger.info("ì„¤ì • íŒŒì¼ ì €ì¥ ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"ì„¤ì • íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            # ì„ì‹œ íŒŒì¼ì´ ìˆìœ¼ë©´ ì‚­ì œ
            temp_file = self.config_file.with_suffix('.tmp')
            if temp_file.exists():
                try:
                    temp_file.unlink()
                except:
                    pass
            return False
    
    def create_config_backup(self) -> Optional[Path]:
        """ì„¤ì • ë°±ì—… ìƒì„±"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_file = self.backup_dir / f"config_backup_{timestamp}.json"
            
            shutil.copy2(self.config_file, backup_file)
            
            # ë°±ì—… ì´ë ¥ì— ì¶”ê°€
            self.config_history.append({
                'backup_file': str(backup_file),
                'timestamp': timestamp,
                'config_snapshot': self.current_config.to_dict()
            })
            
            # ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬ (ìµœê·¼ 10ê°œë§Œ ìœ ì§€)
            self._cleanup_old_backups()
            
            self.logger.info(f"ì„¤ì • ë°±ì—… ìƒì„±: {backup_file}")
            return backup_file
            
        except Exception as e:
            self.logger.error(f"ì„¤ì • ë°±ì—… ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def restore_config_backup(self, backup_file: Path) -> bool:
        """ë°±ì—…ì—ì„œ ì„¤ì • ë³µì›"""
        try:
            if not backup_file.exists():
                self.logger.error(f"ë°±ì—… íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {backup_file}")
                return False
            
            # í˜„ì¬ ì„¤ì • ë°±ì—… (ë³µì› ì‹¤íŒ¨ì‹œ ë¡¤ë°±ìš©)
            rollback_backup = self.create_config_backup()
            
            try:
                # ë°±ì—…ì—ì„œ ë³µì›
                shutil.copy2(backup_file, self.config_file)
                
                # ì„¤ì • ë‹¤ì‹œ ë¡œë“œ
                self.load_config()
                
                self.logger.info(f"ì„¤ì • ë³µì› ì™„ë£Œ: {backup_file}")
                return True
                
            except Exception as restore_error:
                # ë³µì› ì‹¤íŒ¨ì‹œ ë¡¤ë°±
                if rollback_backup and rollback_backup.exists():
                    shutil.copy2(rollback_backup, self.config_file)
                    self.load_config()
                    self.logger.error(f"ì„¤ì • ë³µì› ì‹¤íŒ¨, ë¡¤ë°± ì™„ë£Œ: {restore_error}")
                
                return False
                
        except Exception as e:
            self.logger.error(f"ì„¤ì • ë³µì› ì‹¤íŒ¨: {e}")
            return False
    
    def _cleanup_old_backups(self):
        """ì˜¤ë˜ëœ ë°±ì—… íŒŒì¼ ì •ë¦¬"""
        try:
            backup_files = list(self.backup_dir.glob("config_backup_*.json"))
            backup_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
            
            # ìµœê·¼ 10ê°œë¥¼ ì œì™¸í•˜ê³  ì‚­ì œ
            for old_backup in backup_files[10:]:
                old_backup.unlink()
                self.logger.debug(f"ì˜¤ë˜ëœ ë°±ì—… ì‚­ì œ: {old_backup}")
                
        except Exception as e:
            self.logger.warning(f"ë°±ì—… ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def update_config(self, **kwargs) -> bool:
        """ì„¤ì • ì—…ë°ì´íŠ¸"""
        try:
            # ë³€ê²½ ì‚¬í•­ ì ìš©
            for key, value in kwargs.items():
                if hasattr(self.current_config, key):
                    setattr(self.current_config, key, value)
                    self.logger.info(f"ì„¤ì • ì—…ë°ì´íŠ¸: {key} = {value}")
            
            # ì„¤ì • ì €ì¥
            return self.save_config()
            
        except Exception as e:
            self.logger.error(f"ì„¤ì • ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def get_config_history(self) -> List[Dict[str, Any]]:
        """ì„¤ì • ë³€ê²½ ì´ë ¥ ë°˜í™˜"""
        return self.config_history.copy()

# Part 2ì—ì„œ ì´ì–´ì§‘ë‹ˆë‹¤...

import zlib
import re
import fnmatch
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor #as_completed

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§  AI ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ë°ì´í„°ì…‹ ê²€ìƒ‰ ì‹œìŠ¤í…œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class SmartDatasetFinder:
    """
    AI í‚¤ì›Œë“œ ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ë°ì´í„°ì…‹ ìë™ ê²€ìƒ‰ ì‹œìŠ¤í…œ
    - ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì ìˆ˜ ì‹œìŠ¤í…œ
    - ì••ì¶•íŒŒì¼ ìš°ì„  ê²€ìƒ‰
    - ì‚¬ìš©ì í•™ìŠµ íŒ¨í„´ ë°˜ì˜
    """
    
    def __init__(self, logger: AdvancedLogger, security_manager: SecurityManager):
        self.logger = logger
        self.security_manager = security_manager
        
        # AI ê²€ìƒ‰ íŒ¨í„´ ì •ì˜
        self.dataset_patterns = {
            'computer_vision': [
                r'.*dataset.*', r'.*data.*', r'.*images?.*', r'.*vision.*',
                r'.*object.*detection.*', r'.*classification.*', r'.*segmentation.*',
                r'.*yolo.*', r'.*coco.*', r'.*imagenet.*', r'.*mnist.*'
            ],
            'nlp': [
                r'.*text.*', r'.*nlp.*', r'.*language.*', r'.*corpus.*',
                r'.*bert.*', r'.*gpt.*', r'.*transformer.*'
            ],
            'general': [
                r'.*train.*', r'.*test.*', r'.*valid.*', r'.*dataset.*',
                r'.*data.*', r'.*ml.*', r'.*ai.*', r'.*model.*'
            ]
        }
        
        # íŒŒì¼ í™•ì¥ìë³„ ê°€ì¤‘ì¹˜
        self.extension_weights = {
            '.zip': 1.0,
            '.rar': 0.9,
            '.7z': 0.8,
            '.tar': 0.7,
            '.tar.gz': 0.7,
            '.tar.bz2': 0.6
        }
        
        # ê²½ë¡œ ìš°ì„ ìˆœìœ„ ê°€ì¤‘ì¹˜
        self.path_weights = {
            'desktop': 1.0,
            'downloads': 0.9,
            'documents': 0.8,
            'pictures': 0.7,
            'videos': 0.6,
            'dataset': 1.2,
            'data': 1.1,
            'train': 1.1
        }
        
        # ì‚¬ìš©ì ì„ íƒ í•™ìŠµ ë°ì´í„°
        self.user_preferences = {}
        
        # ê²€ìƒ‰ ê²°ê³¼ ìºì‹œ
        self.search_cache = {}
    
    def find_datasets(self, search_paths: List[Path], 
                     search_query: str = "", 
                     max_results: int = 20) -> List[Dict[str, Any]]:
        """
        AI ê¸°ë°˜ ë°ì´í„°ì…‹ ê²€ìƒ‰
        Args:
            search_paths: ê²€ìƒ‰í•  ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            search_query: ê²€ìƒ‰ ì¿¼ë¦¬ (ì„ íƒì )
            max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜
        """
        self.logger.info(f"AI ë°ì´í„°ì…‹ ê²€ìƒ‰ ì‹œì‘: {len(search_paths)}ê°œ ê²½ë¡œ")
        
        # ìºì‹œ í™•ì¸
        cache_key = self._generate_cache_key(search_paths, search_query)
        if cache_key in self.search_cache:
            self.logger.debug("ìºì‹œì—ì„œ ê²€ìƒ‰ ê²°ê³¼ ë°˜í™˜")
            return self.search_cache[cache_key]
        
        all_candidates = []
        
        # ë©€í‹°ìŠ¤ë ˆë”©ìœ¼ë¡œ ë³‘ë ¬ ê²€ìƒ‰
        with ThreadPoolExecutor(max_workers=4) as executor:
            future_to_path = {
                executor.submit(self._search_path, path, search_query): path 
                for path in search_paths
            }
            
            for future in as_completed(future_to_path):
                path = future_to_path[future]
                try:
                    candidates = future.result()
                    all_candidates.extend(candidates)
                    self.logger.debug(f"ê²½ë¡œ {path}: {len(candidates)}ê°œ í›„ë³´ ë°œê²¬")
                except Exception as e:
                    self.logger.error(f"ê²½ë¡œ ê²€ìƒ‰ ì‹¤íŒ¨ ({path}): {e}")
        
        # AI ê¸°ë°˜ ì ìˆ˜ ê³„ì‚° ë° ì •ë ¬
        scored_datasets = self._calculate_ai_scores(all_candidates, search_query)
        
        # ìƒìœ„ ê²°ê³¼ ì„ íƒ
        top_results = scored_datasets[:max_results]
        
        # ìºì‹œì— ì €ì¥
        self.search_cache[cache_key] = top_results
        
        self.logger.info(f"AI ê²€ìƒ‰ ì™„ë£Œ: {len(top_results)}ê°œ ë°ì´í„°ì…‹ í›„ë³´ ë°œê²¬")
        return top_results
    
    def _search_path(self, search_path: Path, query: str) -> List[Dict[str, Any]]:
        """ë‹¨ì¼ ê²½ë¡œì—ì„œ ë°ì´í„°ì…‹ ê²€ìƒ‰"""
        candidates = []
        
        try:
            if not search_path.exists():
                return candidates
            
            # ë³´ì•ˆ ê²€ì¦
            is_safe, safe_path = self.security_manager.validate_path(search_path)
            if not is_safe:
                self.logger.warning(f"ì•ˆì „í•˜ì§€ ì•Šì€ ê²½ë¡œ ê±´ë„ˆëœ€: {search_path}")
                return candidates
            
            # ì¬ê·€ ê²€ìƒ‰ (ìµœëŒ€ ê¹Šì´ ì œí•œ)
            for root, dirs, files in os.walk(safe_path):
                # ê¹Šì´ ì œí•œ (ì„±ëŠ¥ ìµœì í™”)
                level = root.count(os.sep) - str(safe_path).count(os.sep)
                if level > 5:  # ìµœëŒ€ 5ë‹¨ê³„ ê¹Šì´
                    dirs.clear()
                    continue
                
                # ìˆ¨ê¹€ í´ë” ë° ì‹œìŠ¤í…œ í´ë” ì œì™¸
                dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['__pycache__', 'node_modules']]
                
                for file in files:
                    file_path = Path(root) / file
                    
                    # ì••ì¶• íŒŒì¼ë§Œ ê²€ìƒ‰
                    if any(file.lower().endswith(ext) for ext in SystemConstants.ARCHIVE_EXTENSIONS):
                        candidate = self._analyze_file_candidate(file_path, query)
                        if candidate:
                            candidates.append(candidate)
        
        except PermissionError:
            self.logger.warning(f"ê²½ë¡œ ì ‘ê·¼ ê¶Œí•œ ì—†ìŒ: {search_path}")
        except Exception as e:
            self.logger.error(f"ê²½ë¡œ ê²€ìƒ‰ ì˜¤ë¥˜ ({search_path}): {e}")
        
        return candidates
    
    def _analyze_file_candidate(self, file_path: Path, query: str) -> Optional[Dict[str, Any]]:
        """íŒŒì¼ í›„ë³´ ë¶„ì„"""
        try:
            # ê¸°ë³¸ ì •ë³´
            file_stat = file_path.stat()
            candidate = {
                'path': str(file_path),
                'name': file_path.name,
                'size': file_stat.st_size,
                'modified_time': file_stat.st_mtime,
                'extension': file_path.suffix.lower(),
                'directory': str(file_path.parent),
                'scores': {}
            }
            
            # ì••ì¶•íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°
            preview_info = self._preview_archive(file_path)
            candidate.update(preview_info)
            
            return candidate
            
        except Exception as e:
            self.logger.debug(f"íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨ ({file_path}): {e}")
            return None
    
    def _preview_archive(self, archive_path: Path) -> Dict[str, Any]:
        """ì••ì¶• íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° - ë‚´ë¶€ ì´ë¯¸ì§€ ìˆ˜ íŒŒì•…"""
        preview = {
            'archive_type': '',
            'total_files': 0,
            'image_files': 0,
            'folder_structure': [],
            'estimated_dataset': False
        }
        
        try:
            extension = archive_path.suffix.lower()
            
            if extension == '.zip':
                preview['archive_type'] = 'ZIP'
                with zipfile.ZipFile(archive_path, 'r') as zf:
                    file_list = zf.namelist()
                    preview = self._analyze_archive_contents(file_list, preview)
            
            elif extension == '.rar' and rarfile:
                preview['archive_type'] = 'RAR'
                try:
                    with rarfile.RarFile(archive_path, 'r') as rf:
                        file_list = rf.namelist()
                        preview = self._analyze_archive_contents(file_list, preview)
                except Exception as e:
                    self.logger.debug(f"RAR íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° ì‹¤íŒ¨: {e}")
            
            elif extension in ['.tar', '.tar.gz', '.tar.bz2']:
                preview['archive_type'] = 'TAR'
                with tarfile.open(archive_path, 'r') as tf:
                    file_list = tf.getnames()
                    preview = self._analyze_archive_contents(file_list, preview)
            
        except Exception as e:
            self.logger.debug(f"ì••ì¶•íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° ì‹¤íŒ¨ ({archive_path}): {e}")
        
        return preview
    
    def _analyze_archive_contents(self, file_list: List[str], preview: Dict[str, Any]) -> Dict[str, Any]:
        """ì••ì¶•íŒŒì¼ ë‚´ìš© ë¶„ì„"""
        preview['total_files'] = len(file_list)
        
        image_count = 0
        folder_set = set()
        
        for file_path in file_list:
            # í´ë” êµ¬ì¡° íŒŒì•…
            if '/' in file_path or '\\' in file_path:
                folder_parts = file_path.replace('\\', '/').split('/')
                if len(folder_parts) > 1:
                    folder_set.add(folder_parts[0])
            
            # ì´ë¯¸ì§€ íŒŒì¼ ì¹´ìš´íŠ¸
            file_ext = Path(file_path).suffix.lower()
            if file_ext in SystemConstants.IMAGE_EXTENSIONS:
                image_count += 1
        
        preview['image_files'] = image_count
        preview['folder_structure'] = list(folder_set)[:10]  # ìƒìœ„ 10ê°œ í´ë”ë§Œ
        
        # ë°ì´í„°ì…‹ ì¶”ì • (ì´ë¯¸ì§€ê°€ 100ê°œ ì´ìƒì´ê³  í´ë” êµ¬ì¡°ê°€ ìˆìœ¼ë©´)
        preview['estimated_dataset'] = (
            image_count >= 100 and 
            len(folder_set) >= 2 and
            any(keyword in str(file_list).lower() 
                for keyword in ['train', 'test', 'valid', 'class', 'label'])
        )
        
        return preview
    
    def _calculate_ai_scores(self, candidates: List[Dict[str, Any]], query: str) -> List[Dict[str, Any]]:
        """AI ê¸°ë°˜ ì ìˆ˜ ê³„ì‚° ì‹œìŠ¤í…œ"""
        
        for candidate in candidates:
            total_score = 0.0
            scores = {}
            
            # 1. íŒŒì¼ëª… ë§¤ì¹­ ì ìˆ˜
            filename_score = self._calculate_filename_score(candidate['name'], query)
            scores['filename'] = filename_score
            total_score += filename_score * SystemConstants.AI_SEARCH_WEIGHTS['filename_match']
            
            # 2. í™•ì¥ì ì ìˆ˜
            ext_score = self.extension_weights.get(candidate['extension'], 0.1)
            scores['extension'] = ext_score
            total_score += ext_score * SystemConstants.AI_SEARCH_WEIGHTS['extension_match']
            
            # 3. ê²½ë¡œ ìš°ì„ ìˆœìœ„ ì ìˆ˜
            path_score = self._calculate_path_score(candidate['directory'])
            scores['path'] = path_score
            total_score += path_score * SystemConstants.AI_SEARCH_WEIGHTS['path_priority']
            
            # 4. íŒŒì¼ í¬ê¸° ì ìˆ˜ (ì ë‹¹í•œ í¬ê¸° ì„ í˜¸)
            size_score = self._calculate_size_score(candidate['size'])
            scores['size'] = size_score
            total_score += size_score * SystemConstants.AI_SEARCH_WEIGHTS['file_size']
            
            # 5. ìƒì„±ì¼ ì ìˆ˜ (ìµœê·¼ íŒŒì¼ ì„ í˜¸)
            date_score = self._calculate_date_score(candidate['modified_time'])
            scores['date'] = date_score
            total_score += date_score * SystemConstants.AI_SEARCH_WEIGHTS['creation_date']
            
            # 6. ë°ì´í„°ì…‹ ì¶”ì • ì ìˆ˜ (ë³´ë„ˆìŠ¤)
            if candidate.get('estimated_dataset', False):
                total_score += 0.5
                scores['dataset_bonus'] = 0.5
            
            # 7. ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜ ì ìˆ˜
            if candidate.get('image_files', 0) > 0:
                image_score = min(candidate['image_files'] / 1000, 1.0)
                scores['image_count'] = image_score
                total_score += image_score * 0.3
            
            candidate['scores'] = scores
            candidate['total_score'] = round(total_score, 3)
        
        # ì ìˆ˜ìˆœ ì •ë ¬
        return sorted(candidates, key=lambda x: x['total_score'], reverse=True)
    
    def _calculate_filename_score(self, filename: str, query: str) -> float:
        """íŒŒì¼ëª… ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
        filename_lower = filename.lower()
        score = 0.0
        
        # ì¿¼ë¦¬ì™€ì˜ ì§ì ‘ ë§¤ì¹­
        if query and query.lower() in filename_lower:
            score += 0.8
        
        # AI/ML ê´€ë ¨ í‚¤ì›Œë“œ ë§¤ì¹­
        ai_keywords = [
            'dataset', 'data', 'train', 'test', 'valid', 'model',
            'yolo', 'coco', 'imagenet', 'mnist', 'cifar',
            'detection', 'classification', 'segmentation',
            'vision', 'cv', 'ml', 'ai', 'deep', 'neural'
        ]
        
        for keyword in ai_keywords:
            if keyword in filename_lower:
                score += 0.1
        
        return min(score, 1.0)
    
    def _calculate_path_score(self, directory: str) -> float:
        """ê²½ë¡œ ìš°ì„ ìˆœìœ„ ì ìˆ˜ ê³„ì‚°"""
        dir_lower = directory.lower()
        score = 0.1  # ê¸°ë³¸ ì ìˆ˜
        
        for path_keyword, weight in self.path_weights.items():
            if path_keyword in dir_lower:
                score = max(score, weight)
        
        return score
    
    def _calculate_size_score(self, file_size: int) -> float:
        """íŒŒì¼ í¬ê¸° ì ìˆ˜ ê³„ì‚° (ì ë‹¹í•œ í¬ê¸° ì„ í˜¸)"""
        # MB ë‹¨ìœ„ë¡œ ë³€í™˜
        size_mb = file_size / (1024 * 1024)
        
        if 10 <= size_mb <= 1000:  # 10MB ~ 1GB
            return 1.0
        elif 1 <= size_mb <= 5000:  # 1MB ~ 5GB
            return 0.8
        elif size_mb < 1:  # 1MB ë¯¸ë§Œ
            return 0.3
        else:  # 5GB ì´ˆê³¼
            return 0.6
    
    def _calculate_date_score(self, modified_time: float) -> float:
        """ìƒì„±ì¼ ì ìˆ˜ ê³„ì‚° (ìµœê·¼ íŒŒì¼ ì„ í˜¸)"""
        current_time = time.time()
        days_ago = (current_time - modified_time) / (24 * 3600)
        
        if days_ago <= 30:  # 30ì¼ ì´ë‚´
            return 1.0
        elif days_ago <= 90:  # 3ê°œì›” ì´ë‚´
            return 0.8
        elif days_ago <= 365:  # 1ë…„ ì´ë‚´
            return 0.6
        else:  # 1ë…„ ì´ˆê³¼
            return 0.4
    
    def _generate_cache_key(self, search_paths: List[Path], query: str) -> str:
        """ê²€ìƒ‰ ìºì‹œ í‚¤ ìƒì„±"""
        path_str = "|".join(str(p) for p in search_paths)
        return hashlib.md5(f"{path_str}:{query}".encode()).hexdigest()
    
    def learn_user_preference(self, selected_dataset: Dict[str, Any]):
        """ì‚¬ìš©ì ì„ íƒ íŒ¨í„´ í•™ìŠµ"""
        try:
            # ì„ íƒëœ ë°ì´í„°ì…‹ì˜ íŠ¹ì„± ì¶”ì¶œ
            features = {
                'extension': selected_dataset.get('extension', ''),
                'size_range': self._get_size_range(selected_dataset.get('size', 0)),
                'path_keywords': self._extract_path_keywords(selected_dataset.get('directory', '')),
                'filename_keywords': self._extract_filename_keywords(selected_dataset.get('name', ''))
            }
            
            # í•™ìŠµ ë°ì´í„°ì— ì¶”ê°€
            for key, value in features.items():
                if key not in self.user_preferences:
                    self.user_preferences[key] = defaultdict(int)
                
                if isinstance(value, list):
                    for item in value:
                        self.user_preferences[key][item] += 1
                else:
                    self.user_preferences[key][value] += 1
            
            self.logger.info(f"ì‚¬ìš©ì ì„ íƒ íŒ¨í„´ í•™ìŠµ ì™„ë£Œ: {selected_dataset.get('name', 'Unknown')}")
            
        except Exception as e:
            self.logger.error(f"ì‚¬ìš©ì ì„ íƒ íŒ¨í„´ í•™ìŠµ ì‹¤íŒ¨: {e}")
    
    def _get_size_range(self, size: int) -> str:
        """íŒŒì¼ í¬ê¸° ë²”ìœ„ ë¶„ë¥˜"""
        size_mb = size / (1024 * 1024)
        
        if size_mb < 10:
            return 'small'
        elif size_mb < 100:
            return 'medium'
        elif size_mb < 1000:
            return 'large'
        else:
            return 'very_large'
    
    def _extract_path_keywords(self, directory: str) -> List[str]:
        """ê²½ë¡œì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords = []
        dir_lower = directory.lower()
        
        for keyword in ['desktop', 'downloads', 'documents', 'pictures', 'dataset', 'data', 'train']:
            if keyword in dir_lower:
                keywords.append(keyword)
        
        return keywords
    
    def _extract_filename_keywords(self, filename: str) -> List[str]:
        """íŒŒì¼ëª…ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords = []
        filename_lower = filename.lower()
        
        ai_keywords = ['dataset', 'data', 'train', 'test', 'yolo', 'coco', 'vision', 'cv']
        
        for keyword in ai_keywords:
            if keyword in filename_lower:
                keywords.append(keyword)
        
        return keywords

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“¦ ê³ ê¸‰ ì••ì¶•íŒŒì¼ ì²˜ë¦¬ ì‹œìŠ¤í…œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AdvancedArchiveProcessor:
    """
    ì••ì¶•íŒŒì¼ ì²˜ë¦¬ ì „ë¬¸ ì‹œìŠ¤í…œ
    - ë‹¤ì–‘í•œ ì••ì¶• í˜•ì‹ ì§€ì› (ZIP, RAR, 7Z, TAR)
    - ì§„í–‰ë¥  í‘œì‹œ ë° ì˜¤ë¥˜ ë³µêµ¬
    - ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬
    """
    
    def __init__(self, logger: AdvancedLogger, integrity_manager: DataIntegrityManager):
        self.logger = logger
        self.integrity_manager = integrity_manager
        
        # ì§€ì›ë˜ëŠ” ì••ì¶• í˜•ì‹
        self.supported_formats = {
            '.zip': self._extract_zip,
            '.rar': self._extract_rar,
            '.7z': self._extract_7z,
            '.tar': self._extract_tar,
            '.tar.gz': self._extract_tar,
            '.tar.bz2': self._extract_tar
        }
        
        # ì••ì¶• í•´ì œ í†µê³„
        self.extraction_stats = {}
    
    def extract_archive(self, archive_path: Path, extract_to: Path, 
                       password: Optional[str] = None) -> Dict[str, Any]:
        """
        ì••ì¶• íŒŒì¼ ì¶”ì¶œ
        Args:
            archive_path: ì••ì¶• íŒŒì¼ ê²½ë¡œ
            extract_to: ì¶”ì¶œ ëŒ€ìƒ ê²½ë¡œ
            password: ì•”í˜¸ (ì„ íƒì )
        """
        self.logger.info(f"ì••ì¶• í•´ì œ ì‹œì‘: {archive_path}")
        
        result = {
            'success': False,
            'extracted_files': 0,
            'total_size': 0,
            'extraction_time': 0,
            'error_message': None,
            'extracted_path': None
        }
        
        start_time = time.time()
        
        try:
            # íŒŒì¼ ë¬´ê²°ì„± ê²€ì¦
            integrity_check = self.integrity_manager.verify_file_integrity(archive_path)
            if not integrity_check['integrity_ok']:
                result['error_message'] = "ì••ì¶• íŒŒì¼ì´ ì†ìƒë˜ì—ˆìŠµë‹ˆë‹¤."
                return result
            
            # ì¶”ì¶œ ê²½ë¡œ ì¤€ë¹„
            extract_to.mkdir(parents=True, exist_ok=True)
            
            # ì••ì¶• í˜•ì‹ í™•ì¸
            extension = archive_path.suffix.lower()
            if archive_path.name.endswith('.tar.gz'):
                extension = '.tar.gz'
            elif archive_path.name.endswith('.tar.bz2'):
                extension = '.tar.bz2'
            
            if extension not in self.supported_formats:
                result['error_message'] = f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì••ì¶• í˜•ì‹: {extension}"
                return result
            
            # ì••ì¶• í•´ì œ ì‹¤í–‰
            extractor = self.supported_formats[extension]
            extraction_result = extractor(archive_path, extract_to, password)
            
            result.update(extraction_result)
            result['extraction_time'] = time.time() - start_time
            
            if result['success']:
                self.logger.info(f"ì••ì¶• í•´ì œ ì™„ë£Œ: {result['extracted_files']}ê°œ íŒŒì¼, "
                               f"{result['extraction_time']:.2f}ì´ˆ")
            else:
                self.logger.error(f"ì••ì¶• í•´ì œ ì‹¤íŒ¨: {result['error_message']}")
            
        except Exception as e:
            result['error_message'] = str(e)
            result['extraction_time'] = time.time() - start_time
            self.logger.error(f"ì••ì¶• í•´ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        return result
    
    def _extract_zip(self, archive_path: Path, extract_to: Path, 
                     password: Optional[str] = None) -> Dict[str, Any]:
        """ZIP íŒŒì¼ ì¶”ì¶œ"""
        result = {'success': False, 'extracted_files': 0, 'total_size': 0}
        
        try:
            with zipfile.ZipFile(archive_path, 'r') as zf:
                # íŒŒì¼ ëª©ë¡ í™•ì¸
                file_list = zf.namelist()
                total_files = len(file_list)
                
                # ì§„í–‰ë¥  í‘œì‹œë¥¼ ìœ„í•œ Rich Progress
                if RICH_AVAILABLE:
                    from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn
                    
                    with Progress(
                        SpinnerColumn(),
                        TextColumn("[progress.description]{task.description}"),
                        BarColumn(),
                        TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
                    ) as progress:
                        task = progress.add_task("ZIP ì¶”ì¶œ ì¤‘...", total=total_files)
                        
                        for i, file_info in enumerate(zf.infolist()):
                            # ì•ˆì „í•œ ê²½ë¡œ í™•ì¸
                            if self._is_safe_path(file_info.filename):
                                try:
                                    if password:
                                        zf.extract(file_info, extract_to, pwd=password.encode())
                                    else:
                                        zf.extract(file_info, extract_to)
                                    
                                    result['extracted_files'] += 1
                                    result['total_size'] += file_info.file_size
                                    
                                except Exception as e:
                                    self.logger.warning(f"íŒŒì¼ ì¶”ì¶œ ì‹¤íŒ¨ ({file_info.filename}): {e}")
                            
                            progress.update(task, advance=1)
                else:
                    # Richê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì¶”ì¶œ
                    for file_info in zf.infolist():
                        if self._is_safe_path(file_info.filename):
                            try:
                                if password:
                                    zf.extract(file_info, extract_to, pwd=password.encode())
                                else:
                                    zf.extract(file_info, extract_to)
                                
                                result['extracted_files'] += 1
                                result['total_size'] += file_info.file_size
                                
                            except Exception as e:
                                self.logger.warning(f"íŒŒì¼ ì¶”ì¶œ ì‹¤íŒ¨ ({file_info.filename}): {e}")
                
                result['success'] = True
                result['extracted_path'] = extract_to
                
        except zipfile.BadZipFile:
            result['error_message'] = "ì†ìƒëœ ZIP íŒŒì¼ì…ë‹ˆë‹¤."
        except Exception as e:
            result['error_message'] = str(e)
        
        return result
    
    def _extract_rar(self, archive_path: Path, extract_to: Path, 
                     password: Optional[str] = None) -> Dict[str, Any]:
        """RAR íŒŒì¼ ì¶”ì¶œ"""
        result = {'success': False, 'extracted_files': 0, 'total_size': 0}
        
        if not rarfile:
            result['error_message'] = "rarfile ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. pip install rarfile"
            return result
        
        try:
            with rarfile.RarFile(archive_path, 'r') as rf:
                file_list = rf.namelist()
                total_files = len(file_list)
                
                if RICH_AVAILABLE:
                    from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn
                    
                    with Progress(
                        SpinnerColumn(),
                        TextColumn("[progress.description]{task.description}"),
                        BarColumn(),
                        TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
                    ) as progress:
                        task = progress.add_task("RAR ì¶”ì¶œ ì¤‘...", total=total_files)
                        
                        for i, filename in enumerate(file_list):
                            if self._is_safe_path(filename):
                                try:
                                    if password:
                                        rf.extract(filename, extract_to, pwd=password)
                                    else:
                                        rf.extract(filename, extract_to)
                                    
                                    result['extracted_files'] += 1
                                    
                                    # íŒŒì¼ í¬ê¸° ê³„ì‚°
                                    extracted_file = extract_to / filename
                                    if extracted_file.exists():
                                        result['total_size'] += extracted_file.stat().st_size
                                    
                                except Exception as e:
                                    self.logger.warning(f"íŒŒì¼ ì¶”ì¶œ ì‹¤íŒ¨ ({filename}): {e}")
                            
                            progress.update(task, advance=1)
                else:
                    for filename in file_list:
                        if self._is_safe_path(filename):
                            try:
                                if password:
                                    rf.extract(filename, extract_to, pwd=password)
                                else:
                                    rf.extract(filename, extract_to)
                                
                                result['extracted_files'] += 1
                                
                                extracted_file = extract_to / filename
                                if extracted_file.exists():
                                    result['total_size'] += extracted_file.stat().st_size
                                
                            except Exception as e:
                                self.logger.warning(f"íŒŒì¼ ì¶”ì¶œ ì‹¤íŒ¨ ({filename}): {e}")
                
                result['success'] = True
                result['extracted_path'] = extract_to
                
        except Exception as e:
            result['error_message'] = str(e)
        
        return result
    
    def _extract_tar(self, archive_path: Path, extract_to: Path, 
                     password: Optional[str] = None) -> Dict[str, Any]:
        """TAR íŒŒì¼ ì¶”ì¶œ (tar, tar.gz, tar.bz2)"""
        result = {'success': False, 'extracted_files': 0, 'total_size': 0}
        
        try:
            with tarfile.open(archive_path, 'r') as tf:
                members = tf.getmembers()
                total_files = len(members)
                
                if RICH_AVAILABLE:
                    from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn
                    
                    with Progress(
                        SpinnerColumn(),
                        TextColumn("[progress.description]{task.description}"),
                        BarColumn(),
                        TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
                    ) as progress:
                        task = progress.add_task("TAR ì¶”ì¶œ ì¤‘...", total=total_files)
                        
                        for member in members:
                            if self._is_safe_path(member.name) and member.isfile():
                                try:
                                    tf.extract(member, extract_to)
                                    result['extracted_files'] += 1
                                    result['total_size'] += member.size
                                except Exception as e:
                                    self.logger.warning(f"íŒŒì¼ ì¶”ì¶œ ì‹¤íŒ¨ ({member.name}): {e}")
                            
                            progress.update(task, advance=1)
                else:
                    for member in members:
                        if self._is_safe_path(member.name) and member.isfile():
                            try:
                                tf.extract(member, extract_to)
                                result['extracted_files'] += 1
                                result['total_size'] += member.size
                            except Exception as e:
                                self.logger.warning(f"íŒŒì¼ ì¶”ì¶œ ì‹¤íŒ¨ ({member.name}): {e}")
                
                result['success'] = True
                result['extracted_path'] = extract_to
                
        except Exception as e:
            result['error_message'] = str(e)
        
        return result
    
    def _extract_7z(self, archive_path: Path, extract_to: Path, 
                    password: Optional[str] = None) -> Dict[str, Any]:
        """7Z íŒŒì¼ ì¶”ì¶œ (ì™¸ë¶€ ë„êµ¬ í•„ìš”)"""
        result = {'success': False, 'extracted_files': 0, 'total_size': 0}
        
        try:
            # 7z ëª…ë ¹ì–´ í™•ì¸
            if not shutil.which('7z'):
                result['error_message'] = "7z ëª…ë ¹ì–´ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                return result
            
            # 7z ëª…ë ¹ì–´ë¡œ ì¶”ì¶œ
            cmd = ['7z', 'x', str(archive_path), f'-o{extract_to}', '-y']
            if password:
                cmd.append(f'-p{password}')
            
            process = subprocess.run(cmd, capture_output=True, text=True)
            
            if process.returncode == 0:
                # ì¶”ì¶œëœ íŒŒì¼ ìˆ˜ ê³„ì‚°
                extracted_files = list(extract_to.rglob('*'))
                result['extracted_files'] = len([f for f in extracted_files if f.is_file()])
                result['total_size'] = sum(f.stat().st_size for f in extracted_files if f.is_file())
                result['success'] = True
                result['extracted_path'] = extract_to
            else:
                result['error_message'] = process.stderr
                
        except Exception as e:
            result['error_message'] = str(e)
        
        return result
    
    def _is_safe_path(self, path: str) -> bool:
        """ì•ˆì „í•œ ê²½ë¡œì¸ì§€ í™•ì¸ (ê²½ë¡œ íƒìƒ‰ ê³µê²© ë°©ì§€)"""
        # ì ˆëŒ€ ê²½ë¡œë‚˜ ìƒìœ„ ë””ë ‰í† ë¦¬ ì°¸ì¡° ì°¨ë‹¨
        if os.path.isabs(path) or '..' in path:
            return False
        
        # ìœ„í—˜í•œ íŒŒì¼ëª… íŒ¨í„´ ì°¨ë‹¨
        dangerous_patterns = ['../', '..\\', '/etc/', 'C:\\Windows\\']
        for pattern in dangerous_patterns:
            if pattern in path:
                return False
        
        return True
    
    def get_archive_info(self, archive_path: Path) -> Dict[str, Any]:
        """ì••ì¶• íŒŒì¼ ì •ë³´ ì¡°íšŒ"""
        info = {
            'path': str(archive_path),
            'size': 0,
            'type': 'unknown',
            'file_count': 0,
            'compressed_size': 0,
            'compression_ratio': 0
        }
        
        try:
            if not archive_path.exists():
                return info
            
            info['size'] = archive_path.stat().st_size
            extension = archive_path.suffix.lower()
            
            if extension == '.zip':
                info = self._get_zip_info(archive_path, info)
            elif extension == '.rar' and rarfile:
                info = self._get_rar_info(archive_path, info)
            elif extension in ['.tar', '.tar.gz', '.tar.bz2']:
                info = self._get_tar_info(archive_path, info)
            
        except Exception as e:
            self.logger.error(f"ì••ì¶• íŒŒì¼ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        return info
    
    def _get_zip_info(self, archive_path: Path, info: Dict[str, Any]) -> Dict[str, Any]:
        """ZIP íŒŒì¼ ì •ë³´"""
        try:
            with zipfile.ZipFile(archive_path, 'r') as zf:
                info['type'] = 'ZIP'
                info['file_count'] = len(zf.filelist)
                
                total_size = sum(file_info.file_size for file_info in zf.filelist)
                compressed_size = sum(file_info.compress_size for file_info in zf.filelist)
                
                info['compressed_size'] = total_size
                if total_size > 0:
                    info['compression_ratio'] = round((1 - compressed_size / total_size) * 100, 2)
        except Exception as e:
            self.logger.debug(f"ZIP ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        return info
    
    def _get_rar_info(self, archive_path: Path, info: Dict[str, Any]) -> Dict[str, Any]:
        """RAR íŒŒì¼ ì •ë³´"""
        try:
            with rarfile.RarFile(archive_path, 'r') as rf:
                info['type'] = 'RAR'
                info['file_count'] = len(rf.namelist())
        except Exception as e:
            self.logger.debug(f"RAR ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        return info
    
    def _get_tar_info(self, archive_path: Path, info: Dict[str, Any]) -> Dict[str, Any]:
        """TAR íŒŒì¼ ì •ë³´"""
        try:
            with tarfile.open(archive_path, 'r') as tf:
                members = tf.getmembers()
                info['type'] = 'TAR'
                info['file_count'] = len(members)
                info['compressed_size'] = sum(member.size for member in members if member.isfile())
        except Exception as e:
            self.logger.debug(f"TAR ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        return info

# Part 3ì—ì„œ ì´ì–´ì§‘ë‹ˆë‹¤...

import textwrap
import webbrowser
from urllib.parse import quote
from typing import Callable, Optional
from contextlib import contextmanager

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¨ Rich ê¸°ë°˜ ê³ ê¸‰ UI ì‹œìŠ¤í…œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AdvancedUI:
    """
    Rich ë¼ì´ë¸ŒëŸ¬ë¦¬ ê¸°ë°˜ ê³ ê¸‰ í„°ë¯¸ë„ UI ì‹œìŠ¤í…œ
    - ë°˜ì‘í˜• ë ˆì´ì•„ì›ƒ
    - ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ
    - ì¸í„°ë™í‹°ë¸Œ ë©”ë‰´ ì‹œìŠ¤í…œ
    - ë‹¤êµ­ì–´ ì§€ì›
    """
    
    def __init__(self, language_manager: LanguageManager, logger: AdvancedLogger):
        self.lang = language_manager
        self.logger = logger
        
        # Rich ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        if RICH_AVAILABLE:
            self.console = Console()
            self.layout = Layout()
            self._setup_layout()
        else:
            self.console = None
            self.layout = None
            self.logger.warning("Rich UIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í„°ë¯¸ë„ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
    
    def _setup_layout(self):
        """ë ˆì´ì•„ì›ƒ ì´ˆê¸° ì„¤ì •"""
        if not RICH_AVAILABLE:
            return
        
        # ë©”ì¸ ë ˆì´ì•„ì›ƒ êµ¬ì„±
        self.layout.split_column(
            Layout(name="header", size=3),
            Layout(name="main", ratio=1),
            Layout(name="footer", size=3)
        )
        
        # ë©”ì¸ ì˜ì—­ ë¶„í• 
        self.layout["main"].split_row(
            Layout(name="sidebar", size=40),
            Layout(name="content", ratio=1)
        )
    
    def show_welcome_screen(self):
        """í™˜ì˜ í™”ë©´ í‘œì‹œ"""
        if not RICH_AVAILABLE:
            print("="*80)
            print("ğŸ¤– AI í›ˆë ¨ ì‹œìŠ¤í…œ v3.0")
            print("="*80)
            return
        
        # í—¤ë” íŒ¨ë„
        header_text = Text.assemble(
            ("ğŸ¤– AI í›ˆë ¨ ì‹œìŠ¤í…œ ", "bold cyan"),
            ("v3.0", "bold yellow"),
            (" - ì°¨ì„¸ëŒ€ í†µí•© ìë™í™” í”Œë«í¼", "cyan")
        )
        
        header_panel = Panel(
            header_text,
            title="Welcome",
            title_align="left",
            border_style="bright_blue"
        )
        
        # ê¸°ëŠ¥ ì†Œê°œ íŒ¨ë„
        features_text = Text()
        features_text.append("ğŸ”¥ v2.2 â†’ v3.0 ì£¼ìš” ì—…ê·¸ë ˆì´ë“œ\n\n", style="bold red")
        features_text.append("âœ¨ ì™„ì „íˆ ì¬ì„¤ê³„ëœ ëª¨ë“ˆí™” ì•„í‚¤í…ì²˜\n", style="green")
        features_text.append("ğŸ›¡ï¸ ê²¬ê³ í•œ ê²½ë¡œ ê²€ì¦ ë° ë³´ì•ˆ ì‹œìŠ¤í…œ\n", style="green")
        features_text.append("ğŸ“Š ì‹¤ì‹œê°„ í•˜ë“œì›¨ì–´ ëª¨ë‹ˆí„°ë§ (CPU/GPU/NPU)\n", style="green")
        features_text.append("ğŸ¨ Rich ê¸°ë°˜ ê³ ê¸‰ UI ì‹œìŠ¤í…œ\n", style="green")
        features_text.append("ğŸ¤– AI ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ì˜¤ë¥˜ í•´ê²°\n", style="green")
        features_text.append("ğŸ’¾ ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ ì‹œìŠ¤í…œ\n", style="green")
        features_text.append("ğŸŒ ë‹¤êµ­ì–´ ì§€ì› (í•œêµ­ì–´/ì˜ì–´)\n", style="green")
        features_text.append("âš¡ ì••ì¶•íŒŒì¼ AI ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ ê°•í™”\n", style="green")
        features_text.append("ğŸ“ˆ ì˜ˆì¸¡ ë¶„ì„ ê¸°ë°˜ ì„±ëŠ¥ ìµœì í™”\n", style="green")
        features_text.append("ğŸ”„ ì„¤ì • ë°±ì—…/ë³µì› ì‹œìŠ¤í…œ\n", style="green")
        
        features_panel = Panel(
            features_text,
            title="ğŸ†• ìƒˆë¡œìš´ ê¸°ëŠ¥",
            title_align="left",
            border_style="green"
        )
        
        # ì‹œìŠ¤í…œ ì •ë³´ íŒ¨ë„
        system_info = self._get_system_info_text()
        system_panel = Panel(
            system_info,
            title="ğŸ–¥ï¸ ì‹œìŠ¤í…œ ì •ë³´",
            title_align="left",
            border_style="yellow"
        )
        
        # ë„ì›€ë§ íŒ¨ë„
        help_text = Text()
        help_text.append("ğŸ’¡ ì‚¬ìš© íŒ\n\n", style="bold blue")
        help_text.append("â€¢ ", style="blue")
        help_text.append("ì–¸ì œë“ ì§€ ", style="white")
        help_text.append("!help", style="bold cyan")
        help_text.append("ë¥¼ ì…ë ¥í•˜ë©´ ë„ì›€ë§ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤\n", style="white")
        help_text.append("â€¢ ", style="blue")
        help_text.append("ESC í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì´ì „ ë‹¨ê³„ë¡œ ëŒì•„ê°‘ë‹ˆë‹¤\n", style="white")
        help_text.append("â€¢ ", style="blue")
        help_text.append("Ctrl+Cë¥¼ ëˆ„ë¥´ë©´ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤\n", style="white")
        
        help_panel = Panel(
            help_text,
            title="â“ ë„ì›€ë§",
            title_align="left",
            border_style="blue"
        )
        
        # íŒ¨ë„ë“¤ì„ ì—´ë¡œ ë°°ì¹˜
        columns = Columns(
            [features_panel, system_panel, help_panel],
            equal=True,
            expand=True
        )
        
        # í™”ë©´ ì¶œë ¥
        self.console.clear()
        self.console.print(header_panel)
        self.console.print()
        self.console.print(columns)
        self.console.print()
    
    def _get_system_info_text(self) -> Text:
        """ì‹œìŠ¤í…œ ì •ë³´ í…ìŠ¤íŠ¸ ìƒì„±"""
        text = Text()
        
        # í”Œë«í¼ ì •ë³´
        text.append(f"ğŸ–¥ï¸  ìš´ì˜ì²´ì œ: ", style="cyan")
        text.append(f"{platform.system()} {platform.release()}\n", style="white")
        
        text.append(f"ğŸ  Python: ", style="cyan")
        text.append(f"{platform.python_version()}\n", style="white")
        
        # í•˜ë“œì›¨ì–´ ì •ë³´
        text.append(f"ğŸ§   CPU: ", style="cyan")
        text.append(f"{psutil.cpu_count()}ì½”ì–´\n", style="white")
        
        memory = psutil.virtual_memory()
        text.append(f"ğŸ’¾  ë©”ëª¨ë¦¬: ", style="cyan")
        text.append(f"{round(memory.total / (1024**3), 1)}GB\n", style="white")
        
        # GPU ì •ë³´
        try:
            gpus = GPUtil.getGPUs()
            if gpus:
                text.append(f"ğŸ®  GPU: ", style="cyan")
                text.append(f"{gpus[0].name}\n", style="white")
        except:
            pass
        
        # PyTorch ì •ë³´
        if TORCH_AVAILABLE:
            text.append(f"ğŸ”¥  PyTorch: ", style="cyan")
            text.append(f"{torch.__version__}\n", style="white")
            
            if torch.cuda.is_available():
                text.append(f"âš¡  CUDA: ", style="cyan")
                text.append(f"ì‚¬ìš© ê°€ëŠ¥ ({torch.version.cuda})\n", style="green")
        
        return text
    
    def show_workflow_menu(self) -> str:
        """ì›Œí¬í”Œë¡œìš° ì„ íƒ ë©”ë‰´"""
        if not RICH_AVAILABLE:
            print("\n" + "="*50)
            print("ì›Œí¬í”Œë¡œìš° ì„ íƒ")
            print("="*50)
            print("1. ì™„ì „ ìë™ ëª¨ë“œ (ëª¨ë“  ê²ƒì„ AIê°€ ìë™ìœ¼ë¡œ ì²˜ë¦¬)")
            print("2. ë°˜ìë™ ëª¨ë“œ (ì¤‘ìš”í•œ ì„ íƒë§Œ ì‚¬ìš©ìê°€ ê²°ì •)")
            print("3. ìˆ˜ë™ ëª¨ë“œ (ëª¨ë“  ë‹¨ê³„ë¥¼ ì‚¬ìš©ìê°€ ì§ì ‘ ì œì–´)")
            
            while True:
                choice = input("\nì„ íƒí•˜ì„¸ìš” (1-3): ").strip()
                if choice in ['1', '2', '3']:
                    return ['auto', 'semi_auto', 'manual'][int(choice) - 1]
                print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. 1, 2, 3 ì¤‘ í•˜ë‚˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        
        # Rich ë©”ë‰´
        options = [
            ("ğŸ¤– ì™„ì „ ìë™ ëª¨ë“œ", "auto", "ëª¨ë“  ì„¤ì •ì„ AIê°€ ìë™ìœ¼ë¡œ ìµœì í™”í•©ë‹ˆë‹¤"),
            ("âš–ï¸ ë°˜ìë™ ëª¨ë“œ", "semi_auto", "ì¤‘ìš”í•œ ê²°ì •ë§Œ ì‚¬ìš©ìê°€ ì§ì ‘ ì„ íƒí•©ë‹ˆë‹¤"),  
            ("ğŸ›ï¸ ìˆ˜ë™ ëª¨ë“œ", "manual", "ëª¨ë“  ì„¤ì •ì„ ì‚¬ìš©ìê°€ ì§ì ‘ ì œì–´í•©ë‹ˆë‹¤")
        ]
        
        # ë©”ë‰´ íŒ¨ë„ ìƒì„±
        menu_table = Table(title="ğŸš€ ì›Œí¬í”Œë¡œìš° ì„ íƒ", show_header=False, box=None)
        menu_table.add_column("ë²ˆí˜¸", width=4, style="bold cyan")
        menu_table.add_column("ì˜µì…˜", width=20, style="bold")
        menu_table.add_column("ì„¤ëª…", style="dim")
        
        for i, (name, value, desc) in enumerate(options, 1):
            menu_table.add_row(f"[{i}]", name, desc)
        
        menu_panel = Panel(
            menu_table,
            title="ì›Œí¬í”Œë¡œìš° ì„ íƒ",
            title_align="left",
            border_style="bright_blue"
        )
        
        self.console.print(menu_panel)
        
        # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
        while True:
            try:
                choice = Prompt.ask(
                    "\n[bold cyan]ì„ íƒí•˜ì„¸ìš”[/bold cyan]",
                    choices=["1", "2", "3", "!help"],
                    show_choices=True
                )
                
                if choice == "!help":
                    self.show_workflow_help()
                    continue
                
                return options[int(choice) - 1][1]
                
            except KeyboardInterrupt:
                self.console.print("\n[red]í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.[/red]")
                sys.exit(0)
            except Exception as e:
                self.console.print(f"[red]ì…ë ¥ ì˜¤ë¥˜: {e}[/red]")
    
    def show_workflow_help(self):
        """ì›Œí¬í”Œë¡œìš° ë„ì›€ë§"""
        if not RICH_AVAILABLE:
            print("\nì›Œí¬í”Œë¡œìš° ë„ì›€ë§:")
            print("- ì™„ì „ ìë™: AIê°€ ëª¨ë“  ì„¤ì •ì„ ìë™ìœ¼ë¡œ ê²°ì •")
            print("- ë°˜ìë™: ì¤‘ìš”í•œ ì„ íƒë§Œ ì‚¬ìš©ìê°€ ê²°ì •")
            print("- ìˆ˜ë™: ëª¨ë“  ì„¤ì •ì„ ì‚¬ìš©ìê°€ ì§ì ‘ ì œì–´")
            return
        
        help_text = Text()
        help_text.append("ğŸ¤– ì™„ì „ ìë™ ëª¨ë“œ\n", style="bold green")
        help_text.append("   â€¢ AIê°€ í•˜ë“œì›¨ì–´ë¥¼ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ì„¤ì •ì„ ìë™ ì„ íƒ\n", style="green")
        help_text.append("   â€¢ ë°ì´í„°ì…‹ ìë™ ê²€ìƒ‰ ë° ì„ íƒ\n", style="green")
        help_text.append("   â€¢ ëª¨ë¸ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™ ìµœì í™”\n", style="green")
        help_text.append("   â€¢ ì´ˆë³´ìì—ê²Œ ê¶Œì¥\n\n", style="green")
        
        help_text.append("âš–ï¸ ë°˜ìë™ ëª¨ë“œ\n", style="bold yellow")
        help_text.append("   â€¢ AIê°€ ì¶”ì²œí•œ ì˜µì…˜ ì¤‘ì—ì„œ ì‚¬ìš©ìê°€ ì„ íƒ\n", style="yellow")
        help_text.append("   â€¢ ë°ì´í„°ì…‹ í›„ë³´êµ°ì„ ì œì‹œí•˜ì—¬ ì‚¬ìš©ìê°€ ìµœì¢… ì„ íƒ\n", style="yellow")
        help_text.append("   â€¢ ì£¼ìš” ì„¤ì •ì€ ì‚¬ìš©ìê°€ ê²€í†  í›„ ìŠ¹ì¸\n", style="yellow")
        help_text.append("   â€¢ ì ë‹¹í•œ ì œì–´ê¶Œì„ ì›í•˜ëŠ” ì‚¬ìš©ìì—ê²Œ ê¶Œì¥\n\n", style="yellow")
        
        help_text.append("ğŸ›ï¸ ìˆ˜ë™ ëª¨ë“œ\n", style="bold red")
        help_text.append("   â€¢ ëª¨ë“  ì„¤ì •ì„ ì‚¬ìš©ìê°€ ì§ì ‘ ì…ë ¥\n", style="red")
        help_text.append("   â€¢ ì„¸ë°€í•œ íŠœë‹ ë° ì‹¤í—˜ì  ì„¤ì • ê°€ëŠ¥\n", style="red")
        help_text.append("   â€¢ ê³ ê¸‰ ì‚¬ìš©ì ë° ì—°êµ¬ ëª©ì ì— ì í•©\n", style="red")
        help_text.append("   â€¢ ë¨¸ì‹ ëŸ¬ë‹ ê²½í—˜ì´ í’ë¶€í•œ ì‚¬ìš©ìì—ê²Œ ê¶Œì¥\n", style="red")
        
        help_panel = Panel(
            help_text,
            title="ğŸ’¡ ì›Œí¬í”Œë¡œìš° ìƒì„¸ ì„¤ëª…",
            title_align="left",
            border_style="blue"
        )
        
        self.console.print(help_panel)
    
    def show_dataset_selection(self, datasets: List[Dict[str, Any]]) -> List[int]:
        """ë°ì´í„°ì…‹ ì„ íƒ UI"""
        if not datasets:
            if RICH_AVAILABLE:
                self.console.print("[red]ê²€ìƒ‰ëœ ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤.[/red]")
            else:
                print("ê²€ìƒ‰ëœ ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        if not RICH_AVAILABLE:
            print(f"\në°œê²¬ëœ ë°ì´í„°ì…‹: {len(datasets)}ê°œ")
            print("="*60)
            for i, dataset in enumerate(datasets):
                print(f"{i+1:2d}. {dataset['name']}")
                print(f"    ê²½ë¡œ: {dataset['path']}")
                print(f"    í¬ê¸°: {dataset['size'] / (1024*1024):.1f}MB")
                print(f"    ì ìˆ˜: {dataset['total_score']:.3f}")
                print()
            
            selected = input("ì„ íƒí•  ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 1,3,5 ë˜ëŠ” 1-5): ").strip()
            return self._parse_selection(selected, len(datasets))
        
        # Rich í…Œì´ë¸”ë¡œ ë°ì´í„°ì…‹ í‘œì‹œ
        table = Table(title=f"ğŸ” ë°œê²¬ëœ ë°ì´í„°ì…‹ ({len(datasets)}ê°œ)", show_lines=True)
        table.add_column("ë²ˆí˜¸", width=4, style="cyan")
        table.add_column("ì´ë¦„", width=25, style="bold")
        table.add_column("í¬ê¸°", width=10, style="yellow")
        table.add_column("ì´ë¯¸ì§€", width=8, style="green")
        table.add_column("ì ìˆ˜", width=6, style="red")
        table.add_column("ê²½ë¡œ", style="dim")
        
        for i, dataset in enumerate(datasets):
            size_mb = dataset['size'] / (1024 * 1024)
            size_str = f"{size_mb:.1f}MB" if size_mb < 1024 else f"{size_mb/1024:.1f}GB"
            
            table.add_row(
                str(i + 1),
                dataset['name'][:23] + "..." if len(dataset['name']) > 23 else dataset['name'],
                size_str,
                str(dataset.get('image_files', 0)),
                f"{dataset['total_score']:.3f}",
                str(Path(dataset['path']).parent)
            )
        
        self.console.print(table)
        
        # ì„ íƒ í”„ë¡¬í”„íŠ¸
        while True:
            try:
                selection = Prompt.ask(
                    "\n[bold cyan]ì„ íƒí•  ë°ì´í„°ì…‹ ë²ˆí˜¸[/bold cyan]",
                    default="1",
                    show_default=True
                )
                
                if selection == "!help":
                    self.show_dataset_selection_help()
                    continue
                
                selected_indices = self._parse_selection(selection, len(datasets))
                return selected_indices
                
            except KeyboardInterrupt:
                return []
            except Exception as e:
                self.console.print(f"[red]ì„ íƒ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {e}[/red]")
                self.console.print("[yellow]ì˜ˆì‹œ: 1, 1-3, 1,3,5[/yellow]")
    
    def show_dataset_selection_help(self):
        """ë°ì´í„°ì…‹ ì„ íƒ ë„ì›€ë§"""
        if not RICH_AVAILABLE:
            print("\në°ì´í„°ì…‹ ì„ íƒ ë„ì›€ë§:")
            print("- ë‹¨ì¼ ì„ íƒ: 1")
            print("- ì—¬ëŸ¬ ì„ íƒ: 1,3,5")
            print("- ë²”ìœ„ ì„ íƒ: 1-5")
            print("- í˜¼í•© ì„ íƒ: 1,3-5,7")
            return
        
        help_text = Text()
        help_text.append("ğŸ“‹ ì„ íƒ ë°©ë²•\n\n", style="bold blue")
        help_text.append("â€¢ ", style="blue")
        help_text.append("ë‹¨ì¼ ì„ íƒ: ", style="cyan")
        help_text.append("1\n", style="white")
        help_text.append("â€¢ ", style="blue")
        help_text.append("ì—¬ëŸ¬ ì„ íƒ: ", style="cyan")
        help_text.append("1,3,5\n", style="white")
        help_text.append("â€¢ ", style="blue")
        help_text.append("ë²”ìœ„ ì„ íƒ: ", style="cyan")
        help_text.append("1-5\n", style="white")
        help_text.append("â€¢ ", style="blue")
        help_text.append("í˜¼í•© ì„ íƒ: ", style="cyan")
        help_text.append("1,3-5,7\n\n", style="white")
        
        help_text.append("ğŸ“Š ì ìˆ˜ ì˜ë¯¸\n\n", style="bold blue")
        help_text.append("â€¢ ", style="blue")
        help_text.append("ë†’ì€ ì ìˆ˜ì¼ìˆ˜ë¡ ë” ì í•©í•œ ë°ì´í„°ì…‹\n", style="white")
        help_text.append("â€¢ ", style="blue")
        help_text.append("íŒŒì¼ëª…, ê²½ë¡œ, í¬ê¸° ë“±ì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€\n", style="white")
        help_text.append("â€¢ ", style="blue")
        help_text.append("ì´ë¯¸ì§€ ìˆ˜ê°€ ë§ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜\n", style="white")
        
        help_panel = Panel(
            help_text,
            title="ğŸ’¡ ë°ì´í„°ì…‹ ì„ íƒ ë„ì›€ë§",
            title_align="left",
            border_style="blue"
        )
        
        self.console.print(help_panel)
    
    def _parse_selection(self, selection: str, max_count: int) -> List[int]:
        """ì„ íƒ ë¬¸ìì—´ íŒŒì‹±"""
        selected = []
        
        try:
            parts = selection.split(',')
            for part in parts:
                part = part.strip()
                if '-' in part:
                    start, end = map(int, part.split('-'))
                    selected.extend(range(start, end + 1))
                else:
                    selected.append(int(part))
            
            # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
            selected = sorted(set(selected))
            
            # ë²”ìœ„ ê²€ì¦
            valid_selected = [i for i in selected if 1 <= i <= max_count]
            
            # ì¸ë±ìŠ¤ë¥¼ 0ë¶€í„° ì‹œì‘í•˜ë„ë¡ ë³€í™˜
            return [i - 1 for i in valid_selected]
            
        except Exception as e:
            raise ValueError(f"ì„ íƒ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {e}")
    
    @contextmanager
    def show_progress(self, description: str, total: Optional[int] = None):
        """ì§„í–‰ë¥  í‘œì‹œ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
        if not RICH_AVAILABLE:
            print(f"{description}...")
            yield None
            return
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn() if total else "",
            TaskProgressColumn() if total else "",
            TimeRemainingColumn() if total else "",
            console=self.console
        ) as progress:
            task = progress.add_task(description, total=total)
            
            class ProgressUpdater:
                def __init__(self, task_id, progress_obj):
                    self.task_id = task_id
                    self.progress = progress_obj
                
                def update(self, advance: int = 1, description: Optional[str] = None):
                    if description:
                        self.progress.update(self.task_id, advance=advance, description=description)
                    else:
                        self.progress.update(self.task_id, advance=advance)
                
                def complete(self):
                    self.progress.update(self.task_id, completed=self.progress.tasks[self.task_id].total or 100)
            
            yield ProgressUpdater(task, progress)
    
    def show_hardware_dashboard(self, monitor: 'HardwareMonitor') -> None:
        """ì‹¤ì‹œê°„ í•˜ë“œì›¨ì–´ ëŒ€ì‹œë³´ë“œ"""
        if not RICH_AVAILABLE:
            performance = monitor.get_performance_summary()
            current = performance.get('current', {})
        
            print(f"\ní•˜ë“œì›¨ì–´ ìƒíƒœ:")
            print(f"CPU: {current.get('cpu', {}).get('usage_percent', 0):.1f}%")
            print(f"ë©”ëª¨ë¦¬: {current.get('memory', {}).get('used_percent', 0):.1f}%")
        
            for i, gpu in enumerate(current.get('gpu', [])):
                print(f"GPU {i}: {gpu.get('load_percent', 0):.1f}%")
        
            return
        
        def generate_dashboard():
            performance = monitor.get_performance_summary()
            current = performance.get('current', {})
        
            # ë©”ì¸ ë ˆì´ì•„ì›ƒ
            dashboard_layout = Layout()
        
            # CPU íŒ¨ë„
            cpu_info = current.get('cpu', {})
            cpu_panel = Panel(
                self._create_cpu_display(cpu_info),
                title="ğŸ§  CPU",
                border_style="blue"
            )
        
            # ë©”ëª¨ë¦¬ íŒ¨ë„
            memory_info = current.get('memory', {})
            memory_panel = Panel(
                self._create_memory_display(memory_info),
                title="ğŸ’¾ ë©”ëª¨ë¦¬",
                border_style="green"
            )
        
            # GPU íŒ¨ë„ë“¤
            gpu_info = current.get('gpu', [])
            if gpu_info:
                gpu_panels = []
                for i, gpu in enumerate(gpu_info[:2]):  # ìµœëŒ€ 2ê°œ GPUë§Œ í‘œì‹œ
                    gpu_panel = Panel(
                        self._create_gpu_display(gpu),
                        title=f"ğŸ® GPU {i}",
                        border_style="red"
                    )
                    gpu_panels.append(gpu_panel)
            else:
                gpu_panels = [Panel(
                    Text("GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\nCPU ëª¨ë“œë¡œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.", style="yellow"),
                    title="ğŸ® GPU",
                    border_style="dim"
                )]
        
            # NPU íŒ¨ë„
            npu_info = current.get('npu', {})
            if npu_info.get('available'):
                npu_panel = Panel(
                    self._create_npu_display(npu_info),
                    title="âš¡ NPU",
                    border_style="yellow"
                )
            else:
                npu_panel = Panel(
                    Text("NPUê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", style="dim"),
                    title="âš¡ NPU",
                    border_style="dim"
                )
        
            # ì¶”ì²œì‚¬í•­ íŒ¨ë„
            recommendations = performance.get('recommendations', [])
            if recommendations:
                rec_text = Text()
                for i, rec in enumerate(recommendations[:3], 1):
                    rec_text.append(f"{i}. {rec}\n", style="yellow")
            
                rec_panel = Panel(
                    rec_text,
                    title="ğŸ’¡ ìµœì í™” ì¶”ì²œ",
                    border_style="yellow"
                )
            else:
                rec_panel = Panel(
                    Text("í˜„ì¬ ì‹œìŠ¤í…œì´ ìµœì  ìƒíƒœì…ë‹ˆë‹¤.", style="green"),
                    title="ğŸ’¡ ìµœì í™” ì¶”ì²œ",
                    border_style="green"
                )
        
            # ë ˆì´ì•„ì›ƒ êµ¬ì„±
            try:
                # ìƒë‹¨: CPU + ë©”ëª¨ë¦¬
                top_layout = Layout()
                top_layout.split_row(
                    Layout(cpu_panel, name="cpu"),
                    Layout(memory_panel, name="memory")
                )
            
                # ì¤‘ê°„: GPU íŒ¨ë„ë“¤
                if len(gpu_panels) == 1:
                    middle_layout = Layout()
                    middle_layout.split_row(
                        Layout(gpu_panels[0], name="gpu"),
                        Layout(npu_panel, name="npu")
                    )
                else:
                    middle_layout = Layout()
                    middle_layout.split_row(
                        Layout(gpu_panels[0], name="gpu1"),
                        Layout(gpu_panels[1] if len(gpu_panels) > 1 else npu_panel, name="gpu2")
                    )
            
                # ì „ì²´ ë ˆì´ì•„ì›ƒ
                dashboard_layout.split_column(
                    Layout(top_layout, name="top", size=8),
                    Layout(middle_layout, name="middle", size=8),
                    Layout(rec_panel, name="bottom", size=6)
                )
            
            except Exception as e:
                # ë ˆì´ì•„ì›ƒ ì˜¤ë¥˜ ì‹œ ê°„ë‹¨í•œ íŒ¨ë„ë¡œ ëŒ€ì²´
                error_panel = Panel(
                    f"ë ˆì´ì•„ì›ƒ ì˜¤ë¥˜: {e}\ní•˜ë“œì›¨ì–´ ì •ë³´ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    title="âŒ ì˜¤ë¥˜",
                    border_style="red"
                )
                return error_panel
        
            return dashboard_layout
    
        # ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ëŒ€ì‹œë³´ë“œ
        try:
            with Live(generate_dashboard(), console=self.console, refresh_per_second=1) as live:
                self.console.print("[dim]Press Ctrl+C to exit dashboard[/dim]")
                while True:
                    time.sleep(1)
                    try:
                        live.update(generate_dashboard())
                    except Exception as update_error:
                        self.logger.warning(f"ëŒ€ì‹œë³´ë“œ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {update_error}")
                        break
        except KeyboardInterrupt:
            self.console.print("\n[green]ëŒ€ì‹œë³´ë“œë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.[/green]")
        except Exception as e:
            self.console.print(f"\n[red]ëŒ€ì‹œë³´ë“œ ì˜¤ë¥˜: {e}[/red]")
    
    def _create_cpu_display(self, cpu_info: Dict[str, Any]) -> Text:
        """CPU ë””ìŠ¤í”Œë ˆì´ ìƒì„±"""
        text = Text()
        usage = cpu_info.get('usage_percent', 0)
        frequency = cpu_info.get('frequency_mhz', 0)
        cores = cpu_info.get('core_count', 0)
        temp = cpu_info.get('temperature')
        
        # ì‚¬ìš©ë¥  ë°”
        bar_length = 20
        filled = int(usage / 100 * bar_length)
        bar = "â–ˆ" * filled + "â–‘" * (bar_length - filled)
        
        if usage > 80:
            style = "red"
        elif usage > 60:
            style = "yellow"
        else:
            style = "green"
        
        text.append(f"ì‚¬ìš©ë¥ : {usage:5.1f}% ", style="white")
        text.append(bar, style=style)
        text.append(f"\nì£¼íŒŒìˆ˜: {frequency/1000:.1f}GHz\n", style="cyan")
        text.append(f"ì½”ì–´ ìˆ˜: {cores}ê°œ", style="blue")
        
        if temp:
            text.append(f"\nì˜¨ë„: {temp:.1f}Â°C", style="red" if temp > 70 else "green")
        
        return text
    
    def _create_memory_display(self, memory_info: Dict[str, Any]) -> Text:
        """ë©”ëª¨ë¦¬ ë””ìŠ¤í”Œë ˆì´ ìƒì„±"""
        text = Text()
        total = memory_info.get('total_gb', 0)
        available = memory_info.get('available_gb', 0)
        used_percent = memory_info.get('used_percent', 0)
        
        # ì‚¬ìš©ë¥  ë°”
        bar_length = 20
        filled = int(used_percent / 100 * bar_length)
        bar = "â–ˆ" * filled + "â–‘" * (bar_length - filled)
        
        if used_percent > 85:
            style = "red"
        elif used_percent > 70:
            style = "yellow"
        else:
            style = "green"
        
        text.append(f"ì‚¬ìš©ë¥ : {used_percent:5.1f}% ", style="white")
        text.append(bar, style=style)
        text.append(f"\nì´ ìš©ëŸ‰: {total:.1f}GB\n", style="cyan")
        text.append(f"ì‚¬ìš© ê°€ëŠ¥: {available:.1f}GB", style="blue")
        
        return text
    
    def _create_gpu_display(self, gpu_info: Dict[str, Any]) -> Text:
        """GPU ë””ìŠ¤í”Œë ˆì´ ìƒì„±"""
        text = Text()
        name = gpu_info.get('name', 'Unknown GPU')
        load = gpu_info.get('load_percent', 0)
        memory_percent = gpu_info.get('memory_percent', 0)
        memory_used = gpu_info.get('memory_used_mb', 0)
        memory_total = gpu_info.get('memory_total_mb', 0)
        temp = gpu_info.get('temperature', 0)
        
        text.append(f"ëª¨ë¸: {name[:15]}...\n" if len(name) > 15 else f"ëª¨ë¸: {name}\n", style="white")
        
        # GPU ë¡œë“œ ë°”
        bar_length = 15
        filled = int(load / 100 * bar_length)
        bar = "â–ˆ" * filled + "â–‘" * (bar_length - filled)
        
        load_style = "red" if load > 80 else "yellow" if load > 60 else "green"
        text.append(f"ë¡œë“œ: {load:5.1f}% ", style="white")
        text.append(bar, style=load_style)
        
        # ë©”ëª¨ë¦¬ ì •ë³´
        text.append(f"\nVRAM: {memory_used/1024:.1f}/{memory_total/1024:.1f}GB", style="cyan")
        
        if temp > 0:
            temp_style = "red" if temp > 80 else "yellow" if temp > 70 else "green"
            text.append(f"\nì˜¨ë„: {temp}Â°C", style=temp_style)
        
        return text
    
    def _create_npu_display(self, npu_info: Dict[str, Any]) -> Text:
        """NPU ë””ìŠ¤í”Œë ˆì´ ìƒì„±"""
        text = Text()
        
        if npu_info.get('available'):
            usage = npu_info.get('usage_percent', 0)
            power = npu_info.get('power_watts', 0)
            devices = npu_info.get('devices', [])
            
            text.append("ìƒíƒœ: ì‚¬ìš© ê°€ëŠ¥\n", style="green")
            
            if devices:
                text.append(f"ì¥ì¹˜: {', '.join(devices)}\n", style="cyan")
            
            if usage > 0:
                text.append(f"ì‚¬ìš©ë¥ : {usage:.1f}%\n", style="yellow")
            
            if power > 0:
                text.append(f"ì „ë ¥: {power:.1f}W", style="blue")
        else:
            text.append("ìƒíƒœ: ì‚¬ìš© ë¶ˆê°€", style="dim")
        
        return text
    
    def show_error(self, title: str, error_message: str, suggestion: Optional[str] = None):
        """ì˜¤ë¥˜ ë©”ì‹œì§€ í‘œì‹œ"""
        if not RICH_AVAILABLE:
            print(f"\nâŒ {title}")
            print(f"ì˜¤ë¥˜: {error_message}")
            if suggestion:
                print(f"ì œì•ˆ: {suggestion}")
            return
        
        error_text = Text()
        error_text.append(f"{error_message}\n", style="red")
        
        if suggestion:
            error_text.append("\nğŸ’¡ í•´ê²° ë°©ë²•:\n", style="bold yellow")
            error_text.append(suggestion, style="yellow")
        
        error_panel = Panel(
            error_text,
            title=f"âŒ {title}",
            title_align="left",
            border_style="red"
        )
        
        self.console.print(error_panel)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¤– AI ê¸°ë°˜ ì˜¤ë¥˜ í•´ê²° ì‹œìŠ¤í…œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AIErrorSolver:
    """
    AI ê¸°ë°˜ ì§€ëŠ¥í˜• ì˜¤ë¥˜ ë¶„ì„ ë° í•´ê²° ì‹œìŠ¤í…œ
    - íŒ¨í„´ ê¸°ë°˜ ì˜¤ë¥˜ ê°ì§€
    - ChatGPT API ì—°ë™
    - í•´ê²° ì‚¬ë¡€ ë°ì´í„°ë² ì´ìŠ¤
    """
    
    def __init__(self, logger: AdvancedLogger, ui: AdvancedUI):
        self.logger = logger
        self.ui = ui
        
        # ì˜¤ë¥˜ íŒ¨í„´ ë°ì´í„°ë² ì´ìŠ¤
        self.error_patterns = {
            'cuda_error': {
                'patterns': [
                    r'CUDA out of memory',
                    r'CUDA device-side assert',
                    r'CUDA.*not available'
                ],
                'solutions': [
                    "ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì—¬ë³´ì„¸ìš” (ì˜ˆ: batch_size=16 â†’ batch_size=8)",
                    "GPU ë©”ëª¨ë¦¬ë¥¼ ì •ë¦¬í•´ë³´ì„¸ìš” (torch.cuda.empty_cache())",
                    "Mixed precision trainingì„ ì‚¬ìš©í•´ë³´ì„¸ìš” (--fp16)"
                ]
            },
            'memory_error': {
                'patterns': [
                    r'MemoryError',
                    r'out of memory',
                    r'Cannot allocate memory'
                ],
                'solutions': [
                    "ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì—¬ë³´ì„¸ìš”",
                    "ë°ì´í„° ë¡œë”ì˜ num_workersë¥¼ ì¤„ì—¬ë³´ì„¸ìš”",
                    "ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì¤„ì—¬ë³´ì„¸ìš”"
                ]
            },
            'file_error': {
                'patterns': [
                    r'FileNotFoundError',
                    r'No such file or directory',
                    r'Permission denied'
                ],
                'solutions': [
                    "íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ë³´ì„¸ìš”",
                    "íŒŒì¼ ê¶Œí•œì„ í™•ì¸í•´ë³´ì„¸ìš”",
                    "íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”"
                ]
            },
            'model_error': {
                'patterns': [
                    r'RuntimeError.*model',
                    r'dimension mismatch',
                    r'size mismatch'
                ],
                'solutions': [
                    "ëª¨ë¸ ì…ë ¥ ì°¨ì›ì„ í™•ì¸í•´ë³´ì„¸ìš”",
                    "ë°°ì¹˜ í¬ê¸°ì™€ ëª¨ë¸ ì„¤ì •ì„ í™•ì¸í•´ë³´ì„¸ìš”",
                    "ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”"
                ]
            }
        }
        
        # í•´ê²°ëœ ì˜¤ë¥˜ ì‚¬ë¡€ ë°ì´í„°ë² ì´ìŠ¤
        self.solution_database = {}
        self.load_solution_database()
    
    def analyze_error(self, error_message: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        ì˜¤ë¥˜ ë¶„ì„ ë° í•´ê²°ì±… ì œì‹œ
        Args:
            error_message: ì˜¤ë¥˜ ë©”ì‹œì§€
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì •ë³´
        """
        analysis = {
            'error_type': 'unknown',
            'severity': 'medium',
            'automatic_solutions': [],
            'manual_solutions': [],
            'external_search_query': None,
            'similar_cases': []
        }
        
        # íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ì˜¤ë¥˜ ìœ í˜• ë¶„ì„
        detected_type = self._detect_error_type(error_message)
        if detected_type:
            analysis['error_type'] = detected_type
            analysis['automatic_solutions'] = self.error_patterns[detected_type]['solutions']
        
        # ì‹¬ê°ë„ í‰ê°€
        analysis['severity'] = self._assess_severity(error_message)
        
        # ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰
        analysis['similar_cases'] = self._find_similar_cases(error_message)
        
        # ì™¸ë¶€ AI ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
        analysis['external_search_query'] = self._generate_search_query(error_message, context)
        
        return analysis
    
    def _detect_error_type(self, error_message: str) -> Optional[str]:
        """ì˜¤ë¥˜ íŒ¨í„´ ë§¤ì¹­"""
        import re
        
        for error_type, data in self.error_patterns.items():
            for pattern in data['patterns']:
                if re.search(pattern, error_message, re.IGNORECASE):
                    return error_type
        
        return None
    
    def _assess_severity(self, error_message: str) -> str:
        """ì˜¤ë¥˜ ì‹¬ê°ë„ í‰ê°€"""
        critical_keywords = ['fatal', 'critical', 'segmentation fault', 'access violation']
        high_keywords = ['cuda', 'memory', 'allocation']
        
        error_lower = error_message.lower()
        
        if any(keyword in error_lower for keyword in critical_keywords):
            return 'critical'
        elif any(keyword in error_lower for keyword in high_keywords):
            return 'high'
        else:
            return 'medium'
    
    def _find_similar_cases(self, error_message: str) -> List[Dict[str, Any]]:
        """ìœ ì‚¬ ì˜¤ë¥˜ ì‚¬ë¡€ ê²€ìƒ‰"""
        similar_cases = []
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰
        error_keywords = self._extract_keywords(error_message)
        
        for case_id, case_data in self.solution_database.items():
            case_keywords = self._extract_keywords(case_data.get('error', ''))
            
            # í‚¤ì›Œë“œ ìœ ì‚¬ë„ ê³„ì‚°
            similarity = self._calculate_similarity(error_keywords, case_keywords)
            
            if similarity > 0.3:  # 30% ì´ìƒ ìœ ì‚¬
                similar_cases.append({
                    'case_id': case_id,
                    'similarity': similarity,
                    'solution': case_data.get('solution', ''),
                    'success_rate': case_data.get('success_rate', 0)
                })
        
        # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        similar_cases.sort(key=lambda x: x['similarity'], reverse=True)
        return similar_cases[:3]  # ìƒìœ„ 3ê°œë§Œ ë°˜í™˜
    
    def _extract_keywords(self, text: str) -> set:
        """í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        import re
        
        # íŠ¹ìˆ˜ ë¬¸ì ì œê±° ë° ë‹¨ì–´ ë¶„ë¦¬
        words = re.findall(r'\b\w+\b', text.lower())
        
        # ë¶ˆìš©ì–´ ì œê±°
        stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by'}
        keywords = {word for word in words if len(word) > 3 and word not in stop_words}
        
        return keywords
    
    def _calculate_similarity(self, keywords1: set, keywords2: set) -> float:
        """í‚¤ì›Œë“œ ì§‘í•© ê°„ ìœ ì‚¬ë„ ê³„ì‚°"""
        if not keywords1 or not keywords2:
            return 0.0
        
        intersection = keywords1.intersection(keywords2)
        union = keywords1.union(keywords2)
        
        return len(intersection) / len(union) if union else 0.0
    
    def _generate_search_query(self, error_message: str, context: Optional[Dict[str, Any]]) -> str:
        """ì™¸ë¶€ AI ê²€ìƒ‰ì„ ìœ„í•œ ì¿¼ë¦¬ ìƒì„±"""
        query_parts = ["Python machine learning error:"]
        
        # ì˜¤ë¥˜ ë©”ì‹œì§€ì˜ í•µì‹¬ ë¶€ë¶„ ì¶”ì¶œ
        lines = error_message.strip().split('\n')
        if lines:
            # ë§ˆì§€ë§‰ ì¤„ì´ ë³´í†µ í•µì‹¬ ì˜¤ë¥˜ ë©”ì‹œì§€
            main_error = lines[-1].strip()
            query_parts.append(f'"{main_error}"')
        
        # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ê°€
        if context:
            if context.get('framework'):
                query_parts.append(f"in {context['framework']}")
            
            if context.get('operation'):
                query_parts.append(f"during {context['operation']}")
        
        return " ".join(query_parts)
    
    def create_chatgpt_query(self, error_message: str, context: Optional[Dict[str, Any]] = None) -> str:
        """ChatGPTìš© ìƒì„¸ ì§ˆë¬¸ ìƒì„±"""
        query_parts = [
            "I'm encountering an error in my Python machine learning project.",
            f"Error message: {error_message}",
            "",
            "Context:"
        ]
        
        if context:
            if context.get('framework'):
                query_parts.append(f"- Framework: {context['framework']}")
            
            if context.get('operation'):
                query_parts.append(f"- Operation: {context['operation']}")
            
            if context.get('system_info'):
                query_parts.append(f"- System: {context['system_info']}")
            
            if context.get('hardware'):
                query_parts.append(f"- Hardware: {context['hardware']}")
        
        query_parts.extend([
            "",
            "Please provide:",
            "1. Explanation of what's causing this error",
            "2. Step-by-step solution",
            "3. Prevention tips for the future",
            "4. Alternative approaches if the main solution doesn't work"
        ])
        
        return "\n".join(query_parts)
    
    def open_chatgpt_with_query(self, query: str) -> bool:
        """ChatGPT ì›¹í˜ì´ì§€ë¥¼ ì—´ê³  ì¿¼ë¦¬ ì œê³µ"""
        try:
            # URL ì¸ì½”ë”©
            encoded_query = quote(query)
            
            # ChatGPT URL (ì‹¤ì œë¡œëŠ” í´ë¦½ë³´ë“œì— ë³µì‚¬í•˜ê³  URLë§Œ ì—´ê¸°)
            chatgpt_url = "https://chat.openai.com/"
            
            # ì¿¼ë¦¬ë¥¼ í´ë¦½ë³´ë“œì— ë³µì‚¬ ì‹œë„
            try:
                import pyperclip
                pyperclip.copy(query)
                clipboard_success = True
            except ImportError:
                clipboard_success = False
            
            # ì›¹ë¸Œë¼ìš°ì € ì—´ê¸°
            webbrowser.open(chatgpt_url)
            
            if clipboard_success:
                self.ui.console.print("[green]âœ… ChatGPT í˜ì´ì§€ê°€ ì—´ë ¸ê³  ì§ˆë¬¸ì´ í´ë¦½ë³´ë“œì— ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤.[/green]")
                self.ui.console.print("[yellow]ğŸ’¡ ChatGPTì—ì„œ Ctrl+Vë¡œ ë¶™ì—¬ë„£ê¸° í•˜ì„¸ìš”.[/yellow]")
            else:
                self.ui.console.print("[yellow]âš ï¸ ChatGPT í˜ì´ì§€ê°€ ì—´ë ¸ìŠµë‹ˆë‹¤. ì•„ë˜ ì§ˆë¬¸ì„ ë³µì‚¬í•´ì„œ ì‚¬ìš©í•˜ì„¸ìš”:[/yellow]")
                self.ui.console.print(Panel(query, title="ChatGPT ì§ˆë¬¸", border_style="blue"))
            
            return True
            
        except Exception as e:
            self.logger.error(f"ChatGPT í˜ì´ì§€ ì—´ê¸° ì‹¤íŒ¨: {e}")
            return False
    
    def show_error_analysis(self, error_message: str, context: Optional[Dict[str, Any]] = None):
        """ì˜¤ë¥˜ ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
        analysis = self.analyze_error(error_message, context)
        
        if not RICH_AVAILABLE:
            print(f"\nì˜¤ë¥˜ ë¶„ì„ ê²°ê³¼:")
            print(f"ì˜¤ë¥˜ ìœ í˜•: {analysis['error_type']}")
            print(f"ì‹¬ê°ë„: {analysis['severity']}")
            
            if analysis['automatic_solutions']:
                print("\nìë™ í•´ê²° ë°©ë²•:")
                for i, solution in enumerate(analysis['automatic_solutions'], 1):
                    print(f"  {i}. {solution}")
            
            if analysis['similar_cases']:
                print(f"\nìœ ì‚¬ ì‚¬ë¡€: {len(analysis['similar_cases'])}ê°œ ë°œê²¬")
            
            return analysis
        
        # Rich ê¸°ë°˜ ë¶„ì„ ê²°ê³¼ í‘œì‹œ
        layout = Layout()
        layout.split_column(
            Layout(name="error_info", size=6),
            Layout(name="solutions", ratio=1),
            Layout(name="actions", size=4)
        )
        
        # ì˜¤ë¥˜ ì •ë³´ íŒ¨ë„
        error_info = Text()
        error_info.append("ğŸ” ë¶„ì„ ê²°ê³¼\n\n", style="bold blue")
        error_info.append(f"ì˜¤ë¥˜ ìœ í˜•: ", style="white")
        error_info.append(f"{analysis['error_type']}\n", style="cyan")
        error_info.append(f"ì‹¬ê°ë„: ", style="white")
        
        severity_style = {
            'critical': 'bold red',
            'high': 'red', 
            'medium': 'yellow',
            'low': 'green'
        }.get(analysis['severity'], 'white')
        
        error_info.append(f"{analysis['severity']}\n", style=severity_style)
        
        if analysis['similar_cases']:
            error_info.append(f"ìœ ì‚¬ ì‚¬ë¡€: ", style="white")
            error_info.append(f"{len(analysis['similar_cases'])}ê°œ ë°œê²¬", style="green")
        
        layout["error_info"] = Panel(error_info, title="ğŸ“Š ì˜¤ë¥˜ ë¶„ì„", border_style="blue")
        
        # í•´ê²° ë°©ë²• íŒ¨ë„
        solutions_text = Text()
        
        if analysis['automatic_solutions']:
            solutions_text.append("ğŸ”§ ê¶Œì¥ í•´ê²° ë°©ë²•\n\n", style="bold green")
            for i, solution in enumerate(analysis['automatic_solutions'], 1):
                solutions_text.append(f"{i}. ", style="green")
                solutions_text.append(f"{solution}\n", style="white")
        
        if analysis['similar_cases']:
            solutions_text.append("\nğŸ“š ìœ ì‚¬ ì‚¬ë¡€ í•´ê²°ì±…\n\n", style="bold yellow")
            for case in analysis['similar_cases'][:2]:
                solutions_text.append(f"â€¢ ", style="yellow")
                solutions_text.append(f"{case['solution']}\n", style="white")
                solutions_text.append(f"  (ì„±ê³µë¥ : {case['success_rate']*100:.0f}%)\n\n", style="dim")
        
        layout["solutions"] = Panel(solutions_text, title="ğŸ’¡ í•´ê²° ë°©ë²•", border_style="green")
        
        # ì•¡ì…˜ íŒ¨ë„
        actions_text = Text()
        actions_text.append("ğŸ¤– AI ë„ì›€ ë°›ê¸°\n\n", style="bold cyan")
        actions_text.append("1. ChatGPTì—ê²Œ ì§ˆë¬¸í•˜ê¸° (ìë™ìœ¼ë¡œ ì§ˆë¬¸ ìƒì„±)\n", style="cyan")
        actions_text.append("2. í•´ê²° ì‚¬ë¡€ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥\n", style="cyan")
        actions_text.append("3. ì‹œìŠ¤í…œ ë¡œê·¸ ìƒì„¸ ë¶„ì„", style="cyan")
        
        layout["actions"] = Panel(actions_text, title="ğŸš€ ë‹¤ìŒ ë‹¨ê³„", border_style="cyan")
        
        self.console.print(layout)
        
        # ì‚¬ìš©ì ì„ íƒ
        choice = Prompt.ask(
            "\n[bold cyan]ë‹¤ìŒ ì¤‘ ì„ íƒí•˜ì„¸ìš”[/bold cyan]",
            choices=["1", "2", "3", "skip"],
            default="skip"
        )
        
        if choice == "1":
            chatgpt_query = self.create_chatgpt_query(error_message, context)
            self.open_chatgpt_with_query(chatgpt_query)
        elif choice == "2":
            self.save_error_case(error_message, analysis)
        elif choice == "3":
            self.show_detailed_logs()
        
        return analysis
    
    def save_error_case(self, error_message: str, analysis: Dict[str, Any]):
        """ì˜¤ë¥˜ ì‚¬ë¡€ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        case_id = hashlib.md5(error_message.encode()).hexdigest()[:8]
        
        case_data = {
            'error': error_message,
            'timestamp': datetime.now().isoformat(),
            'error_type': analysis['error_type'],
            'severity': analysis['severity'],
            'automatic_solutions': analysis['automatic_solutions'],
            'success_rate': 0.5  # ê¸°ë³¸ê°’
        }
        
        self.solution_database[case_id] = case_data
        self._save_solution_database()
        
        if RICH_AVAILABLE:
            self.ui.console.print(f"[green]âœ… ì˜¤ë¥˜ ì‚¬ë¡€ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤ (ID: {case_id})[/green]")
        else:
            print(f"ì˜¤ë¥˜ ì‚¬ë¡€ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤ (ID: {case_id})")
    
    def load_solution_database(self):
        """í•´ê²° ì‚¬ë¡€ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ"""
        db_file = Path("error_solutions.json")
        try:
            if db_file.exists():
                with open(db_file, 'r', encoding='utf-8') as f:
                    self.solution_database = json.load(f)
                self.logger.debug(f"í•´ê²° ì‚¬ë¡€ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ: {len(self.solution_database)}ê°œ ì‚¬ë¡€")
        except Exception as e:
            self.logger.error(f"í•´ê²° ì‚¬ë¡€ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.solution_database = {}
    
    def _save_solution_database(self):
        """í•´ê²° ì‚¬ë¡€ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥"""
        db_file = Path("error_solutions.json")
        try:
            with open(db_file, 'w', encoding='utf-8') as f:
                json.dump(self.solution_database, f, indent=2, ensure_ascii=False)
        except Exception as e:
            self.logger.error(f"í•´ê²° ì‚¬ë¡€ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def show_detailed_logs(self):
        """ìƒì„¸ ë¡œê·¸ ë¶„ì„ í‘œì‹œ"""
        log_dir = Path("logs")
        
        if not log_dir.exists():
            if RICH_AVAILABLE:
                self.ui.console.print("[red]ë¡œê·¸ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.[/red]")
            else:
                print("ë¡œê·¸ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return
        
        # ìµœê·¼ ë¡œê·¸ íŒŒì¼ ì°¾ê¸°
        log_files = list(log_dir.glob("*.log"))
        if not log_files:
            if RICH_AVAILABLE:
                self.ui.console.print("[red]ë¡œê·¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.[/red]")
            else:
                print("ë¡œê·¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        latest_log = max(log_files, key=lambda f: f.stat().st_mtime)
        
        try:
            with open(latest_log, 'r', encoding='utf-8') as f:
                log_content = f.read()
            
            # ì˜¤ë¥˜ ë¼ì¸ë§Œ ì¶”ì¶œ
            error_lines = [line for line in log_content.split('\n') 
                          if 'ERROR' in line or 'CRITICAL' in line]
            
            if RICH_AVAILABLE:
                if error_lines:
                    log_text = "\n".join(error_lines[-10:])  # ìµœê·¼ 10ê°œ ì˜¤ë¥˜ë§Œ
                    log_panel = Panel(
                        Syntax(log_text, "log", theme="monokai", line_numbers=True),
                        title="ğŸ” ìµœê·¼ ì˜¤ë¥˜ ë¡œê·¸",
                        border_style="red"
                    )
                    self.ui.console.print(log_panel)
                else:
                    self.ui.console.print("[green]ìµœê·¼ ì˜¤ë¥˜ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.[/green]")
            else:
                if error_lines:
                    print("ìµœê·¼ ì˜¤ë¥˜ ë¡œê·¸:")
                    for line in error_lines[-10:]:
                        print(line)
                else:
                    print("ìµœê·¼ ì˜¤ë¥˜ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    
        except Exception as e:
            self.logger.error(f"ë¡œê·¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")

# Part 4ì—ì„œ ì´ì–´ì§‘ë‹ˆë‹¤...

import requests
from typing import Any, Dict, List, Optional, Tuple, Union
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor, as_completed

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¯ í†µí•© ë„ì›€ë§ ì‹œìŠ¤í…œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class HelpSystem:
    """
    í†µí•© ë„ì›€ë§ ì‹œìŠ¤í…œ - ëª¨ë“  ì…ë ¥ í”„ë¡¬í”„íŠ¸ì—ì„œ !help ëª…ë ¹ì–´ ì§€ì›
    - ìƒí™©ë³„ ë„ì›€ë§ ì œê³µ
    - ë‹¨ê³„ë³„ ê°€ì´ë“œ
    - ì˜ˆì œ ë° íŒ ì œê³µ
    """
    
    def __init__(self, language_manager: LanguageManager, ui: AdvancedUI):
        self.lang = language_manager
        self.ui = ui
        
        # ìƒí™©ë³„ ë„ì›€ë§ ë°ì´í„°
        self.help_data = {
            'workflow_selection': {
                'ko': {
                    'title': 'ì›Œí¬í”Œë¡œìš° ì„ íƒ ë„ì›€ë§',
                    'content': [
                        'ğŸ¤– ì™„ì „ ìë™ ëª¨ë“œ: AIê°€ ëª¨ë“  ì„¤ì •ì„ ìë™ìœ¼ë¡œ ìµœì í™”',
                        '   â€¢ ì´ˆë³´ìì—ê²Œ ê¶Œì¥',
                        '   â€¢ í•˜ë“œì›¨ì–´ ìë™ ê°ì§€ ë° ìµœì í™”',
                        '   â€¢ ë°ì´í„°ì…‹ ìë™ ê²€ìƒ‰ ë° ì„ íƒ',
                        '',
                        'âš–ï¸ ë°˜ìë™ ëª¨ë“œ: AI ì¶”ì²œ ì¤‘ ì‚¬ìš©ìê°€ ì„ íƒ',
                        '   â€¢ ì ë‹¹í•œ ì œì–´ê¶Œì„ ì›í•˜ëŠ” ì‚¬ìš©ì ê¶Œì¥',
                        '   â€¢ ë°ì´í„°ì…‹ í›„ë³´êµ° ì¤‘ ì„ íƒ',
                        '   â€¢ ì£¼ìš” ì„¤ì • ê²€í†  í›„ ìŠ¹ì¸',
                        '',
                        'ğŸ›ï¸ ìˆ˜ë™ ëª¨ë“œ: ëª¨ë“  ì„¤ì •ì„ ì‚¬ìš©ìê°€ ì§ì ‘ ì œì–´',
                        '   â€¢ ê³ ê¸‰ ì‚¬ìš©ì ë° ì—°êµ¬ ëª©ì ',
                        '   â€¢ ì„¸ë°€í•œ íŠœë‹ ê°€ëŠ¥',
                        '   â€¢ ì‹¤í—˜ì  ì„¤ì • ì§€ì›'
                    ]
                }
            },
            'dataset_selection': {
                'ko': {
                    'title': 'ë°ì´í„°ì…‹ ì„ íƒ ë„ì›€ë§',
                    'content': [
                        'ğŸ“‹ ì„ íƒ ë°©ë²•:',
                        '   â€¢ ë‹¨ì¼ ì„ íƒ: 1',
                        '   â€¢ ì—¬ëŸ¬ ì„ íƒ: 1,3,5',
                        '   â€¢ ë²”ìœ„ ì„ íƒ: 1-5',
                        '   â€¢ í˜¼í•© ì„ íƒ: 1,3-5,7',
                        '',
                        'ğŸ“Š ì ìˆ˜ ì˜ë¯¸:',
                        '   â€¢ ë†’ì€ ì ìˆ˜ = ë” ì í•©í•œ ë°ì´í„°ì…‹',
                        '   â€¢ íŒŒì¼ëª…, ê²½ë¡œ, í¬ê¸° ë“± ì¢…í•© í‰ê°€',
                        '   â€¢ ì´ë¯¸ì§€ ìˆ˜ê°€ ë§ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜',
                        '',
                        'ğŸ’¡ ì„ íƒ íŒ:',
                        '   â€¢ ì ìˆ˜ê°€ ë†’ì€ ë°ì´í„°ì…‹ ìš°ì„  ì„ íƒ',
                        '   â€¢ ì´ë¯¸ì§€ ìˆ˜ê°€ 100ê°œ ì´ìƒì¸ ê²ƒ ê¶Œì¥',
                        '   â€¢ ì••ì¶• í•´ì œ ì „ ë¯¸ë¦¬ë³´ê¸° ì •ë³´ í™•ì¸'
                    ]
                }
            },
            'model_selection': {
                'ko': {
                    'title': 'ëª¨ë¸ ì„ íƒ ë„ì›€ë§',
                    'content': [
                        'ğŸ¯ ëª¨ë¸ ì¹´í…Œê³ ë¦¬:',
                        '   â€¢ Object Detection: ê°ì²´ ìœ„ì¹˜ì™€ í´ë˜ìŠ¤ ê²€ì¶œ',
                        '   â€¢ Instance Segmentation: ì •í™•í•œ ê°ì²´ ë§ˆìŠ¤í¬ ìƒì„±',
                        '   â€¢ Pose Estimation: ì‚¬ëŒ ê´€ì ˆì  ê²€ì¶œ',
                        '   â€¢ Classification: ì´ë¯¸ì§€ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜',
                        '',
                        'ğŸ“ ëª¨ë¸ í¬ê¸°ë³„ íŠ¹ì„±:',
                        '   â€¢ Nano (n): ê°€ì¥ ë¹ ë¦„, ëª¨ë°”ì¼/ì—£ì§€ ìµœì í™”',
                        '   â€¢ Small (s): ì†ë„ì™€ ì •í™•ë„ì˜ ê· í˜•',
                        '   â€¢ Medium (m): ì¼ë°˜ì  ìš©ë„, ì¢‹ì€ ì„±ëŠ¥',
                        '   â€¢ Large (l): ë†’ì€ ì •í™•ë„, ë” ë§ì€ ë¦¬ì†ŒìŠ¤',
                        '   â€¢ Extra Large (x): ìµœê³  ì •í™•ë„, ì—°êµ¬ìš©',
                        '',
                        'ğŸ”¥ ì¶”ì²œ ëª¨ë¸:',
                        '   â€¢ ì²« ì‚¬ìš©ì: YOLOv8s ë˜ëŠ” YOLOv11s',
                        '   â€¢ ì‹¤ì‹œê°„ ì²˜ë¦¬: Nano ëª¨ë¸',
                        '   â€¢ ìµœê³  ì„±ëŠ¥: Large/XL ëª¨ë¸',
                        '   â€¢ GPU ë©”ëª¨ë¦¬ ë¶€ì¡±: Small ì´í•˜',
                        '',
                        'âš¡ ìµœì‹  ëª¨ë¸:',
                        '   â€¢ YOLOv11: ìµœì‹  ì•„í‚¤í…ì²˜, ê°€ì¥ íš¨ìœ¨ì ',
                        '   â€¢ RT-DETR: íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ ê²€ì¶œê¸°',
                        '   â€¢ SAM2: ìµœì‹  ë¶„í•  ëª¨ë¸',
                        '   â€¢ YOLO-World: ì˜¤í”ˆ ë³´ì¼€ë¸”ëŸ¬ë¦¬ ì§€ì›'
                    ]
                }
            },
            'training_parameters': {
                'ko': {
                    'title': 'í›ˆë ¨ íŒŒë¼ë¯¸í„° ë„ì›€ë§',
                    'content': [
                        'ğŸ”§ ì£¼ìš” íŒŒë¼ë¯¸í„°:',
                        '   â€¢ epochs: í›ˆë ¨ ë°˜ë³µ íšŸìˆ˜ (100-300 ê¶Œì¥)',
                        '   â€¢ batch_size: ë°°ì¹˜ í¬ê¸° (GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •)',
                        '   â€¢ learning_rate: í•™ìŠµë¥  (0.001-0.01)',
                        '   â€¢ img_size: ì´ë¯¸ì§€ í¬ê¸° (640 ê¸°ë³¸ê°’)',
                        '',
                        'ğŸ’¾ ë©”ëª¨ë¦¬ë³„ ë°°ì¹˜ í¬ê¸°:',
                        '   â€¢ 4GB GPU: batch_size=8',
                        '   â€¢ 8GB GPU: batch_size=16',
                        '   â€¢ 16GB+ GPU: batch_size=32+',
                        '',
                        'ğŸ“ˆ ì„±ëŠ¥ ìµœì í™”:',
                        '   â€¢ Mixed precision: ë©”ëª¨ë¦¬ ì ˆì•½',
                        '   â€¢ Data augmentation: ê³¼ì í•© ë°©ì§€',
                        '   â€¢ Early stopping: ìë™ ì¤‘ë‹¨'
                    ]
                }
            },
            'general': {
                'ko': {
                    'title': 'ì¼ë°˜ ë„ì›€ë§',
                    'content': [
                        'ğŸš€ AI í›ˆë ¨ ì‹œìŠ¤í…œ v3.0 ì‚¬ìš©ë²•:',
                        '',
                        'ğŸ“ ê¸°ë³¸ ëª…ë ¹ì–´:',
                        '   â€¢ !help: ìƒí™©ë³„ ë„ì›€ë§ í‘œì‹œ',
                        '   â€¢ ESC: ì´ì „ ë‹¨ê³„ë¡œ ëŒì•„ê°€ê¸°',
                        '   â€¢ Ctrl+C: í”„ë¡œê·¸ë¨ ì¢…ë£Œ',
                        '',
                        'ğŸ”„ ì›Œí¬í”Œë¡œìš°:',
                        '   1. ì›Œí¬í”Œë¡œìš° ì„ íƒ (ìë™/ë°˜ìë™/ìˆ˜ë™)',
                        '   2. ì‹œìŠ¤í…œ í™˜ê²½ ê²€ì‚¬',
                        '   3. ë°ì´í„°ì…‹ ê²€ìƒ‰ ë° ì„ íƒ',
                        '   4. ì••ì¶•íŒŒì¼ ìë™ í•´ì œ',
                        '   5. ëª¨ë¸ ë° íŒŒë¼ë¯¸í„° ì„¤ì •',
                        '   6. í›ˆë ¨ ì‹¤í–‰ ë° ëª¨ë‹ˆí„°ë§',
                        '',
                        'ğŸ’¡ ë¬¸ì œ í•´ê²°:',
                        '   â€¢ ì˜¤ë¥˜ ë°œìƒì‹œ AI ê¸°ë°˜ í•´ê²°ì±… ì œì‹œ',
                        '   â€¢ ChatGPT ì—°ë™ìœ¼ë¡œ ìƒì„¸ ë„ì›€',
                        '   â€¢ ë¡œê·¸ íŒŒì¼ ìë™ ë¶„ì„',
                        '',
                        'ğŸ“Š ëª¨ë‹ˆí„°ë§:',
                        '   â€¢ ì‹¤ì‹œê°„ í•˜ë“œì›¨ì–´ ì‚¬ìš©ë¥ ',
                        '   â€¢ í›ˆë ¨ ì§„í–‰ë¥  ë° ì„±ëŠ¥ ê·¸ë˜í”„',
                        '   â€¢ ìµœì í™” ì¶”ì²œì‚¬í•­'
                    ]
                }
            }
        }
    
    def show_help(self, context: str = 'general'):
        """ìƒí™©ë³„ ë„ì›€ë§ í‘œì‹œ"""
        help_info = self.help_data.get(context, self.help_data['general'])
        lang_help = help_info.get(self.lang.current_language, help_info['ko'])
        
        if not RICH_AVAILABLE:
            print(f"\n{lang_help['title']}")
            print("=" * len(lang_help['title']))
            for line in lang_help['content']:
                print(line)
            print()
            return
        
        # Rich ê¸°ë°˜ ë„ì›€ë§
        help_text = Text()
        for line in lang_help['content']:
            if line.startswith('ğŸ”§') or line.startswith('ğŸ¤–') or line.startswith('ğŸ“‹'):
                help_text.append(line + '\n', style="bold blue")
            elif line.startswith('   â€¢'):
                help_text.append(line + '\n', style="green")
            elif line.startswith('   '):
                help_text.append(line + '\n', style="yellow")
            elif line == '':
                help_text.append('\n')
            else:
                help_text.append(line + '\n', style="cyan")
        
        help_panel = Panel(
            help_text,
            title=f"â“ {lang_help['title']}",
            title_align="left",
            border_style="blue"
        )
        
        self.ui.console.print(help_panel)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸƒâ€â™‚ï¸ í›ˆë ¨ ì‹¤í–‰ ì—”ì§„
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class TrainingConfig:
    """í›ˆë ¨ ì„¤ì • ë°ì´í„° í´ë˜ìŠ¤ - Windows í˜¸í™˜ì„±"""
    model_name: str = "yolov8n.pt"
    dataset_path: str = ""
    epochs: int = 100
    batch_size: int = 4  # Windowsì—ì„œ ì•ˆì „í•œ ê¸°ë³¸ê°’
    img_size: int = 640
    learning_rate: float = 0.01
    device: str = "auto"
    mixed_precision: bool = True
    data_augmentation: bool = True
    early_stopping: bool = True
    save_period: int = 10
    workers: int = 0  # Windows ê¸°ë³¸ê°’
    project_name: str = "yolo_training"
    experiment_name: str = "exp"

class TrainingEngine:
    """
    AI ëª¨ë¸ í›ˆë ¨ ì‹¤í–‰ ì—”ì§„
    - YOLO ëª¨ë¸ í†µí•© ì§€ì›
    - ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
    - ìë™ ìµœì í™”
    """
    
    def __init__(self, logger: AdvancedLogger, ui: AdvancedUI, 
                 hardware_monitor: HardwareMonitor):
        self.logger = logger
        self.ui = ui
        self.hardware_monitor = hardware_monitor
        
        # í›ˆë ¨ ìƒíƒœ
        self.is_training = False
        self.current_config = None
        self.training_stats = {}
        
        # ì§€ì› ëª¨ë¸ ëª©ë¡ (ì „ì²´ Ultralytics ëª¨ë¸)
        self.supported_models = {
            'Object Detection': {
                'YOLOv3': {
                    'tiny': 'yolov3-tiny.pt',
                    'standard': 'yolov3.pt'
                },
                'YOLOv4': {
                    'tiny': 'yolov4-tiny.pt',
                    'standard': 'yolov4.pt'
                },
                'YOLOv5': {
                    'nano': 'yolov5n.pt',
                    'small': 'yolov5s.pt',
                    'medium': 'yolov5m.pt',
                    'large': 'yolov5l.pt',
                    'extra_large': 'yolov5x.pt',
                    'nano6': 'yolov5n6.pt',
                    'small6': 'yolov5s6.pt',
                    'medium6': 'yolov5m6.pt',
                    'large6': 'yolov5l6.pt',
                    'extra_large6': 'yolov5x6.pt'
                },
                'YOLOv6': {
                    'nano': 'yolov6n.pt',
                    'small': 'yolov6s.pt',
                    'medium': 'yolov6m.pt',
                    'large': 'yolov6l.pt',
                    'extra_large': 'yolov6x.pt'
                },
                'YOLOv7': {
                    'tiny': 'yolov7-tiny.pt',
                    'standard': 'yolov7.pt',
                    'x': 'yolov7x.pt',
                    'w6': 'yolov7-w6.pt',
                    'e6': 'yolov7-e6.pt',
                    'd6': 'yolov7-d6.pt',
                    'e6e': 'yolov7-e6e.pt'
                },
                'YOLOv8': {
                    'nano': 'yolov8n.pt',
                    'small': 'yolov8s.pt',
                    'medium': 'yolov8m.pt',
                    'large': 'yolov8l.pt',
                    'extra_large': 'yolov8x.pt'
                },
                'YOLOv9': {
                    'tiny': 'yolov9t.pt',
                    'small': 'yolov9s.pt',
                    'medium': 'yolov9m.pt',
                    'compact': 'yolov9c.pt',
                    'extended': 'yolov9e.pt'
                },
                'YOLOv10': {
                    'nano': 'yolov10n.pt',
                    'small': 'yolov10s.pt',
                    'medium': 'yolov10m.pt',
                    'balanced': 'yolov10b.pt',
                    'large': 'yolov10l.pt',
                    'extra_large': 'yolov10x.pt'
                },
                'YOLOv11': {
                    'nano': 'yolo11n.pt',
                    'small': 'yolo11s.pt',
                    'medium': 'yolo11m.pt',
                    'large': 'yolo11l.pt',
                    'extra_large': 'yolo11x.pt'
                },
                'RT-DETR': {
                    'large': 'rtdetr-l.pt',
                    'extra_large': 'rtdetr-x.pt'
                },
                'YOLO-NAS': {
                    'small': 'yolo_nas_s.pt',
                    'medium': 'yolo_nas_m.pt',
                    'large': 'yolo_nas_l.pt'
                },
                'YOLO-World': {
                    'small': 'yolov8s-world.pt',
                    'medium': 'yolov8m-world.pt',
                    'large': 'yolov8l.pt'
                },
                'YOLOE': {
                    'small': 'yoloe-s.pt',
                    'medium': 'yoloe-m.pt',
                    'large': 'yoloe-l.pt',
                    'extra_large': 'yoloe-x.pt'
                }
            },
            'Instance Segmentation': {
                'YOLOv5-Seg': {
                    'nano': 'yolov5n-seg.pt',
                    'small': 'yolov5s-seg.pt',
                    'medium': 'yolov5m-seg.pt',
                    'large': 'yolov5l-seg.pt',
                    'extra_large': 'yolov5x-seg.pt'
                },
                'YOLOv8-Seg': {
                    'nano': 'yolov8n-seg.pt',
                    'small': 'yolov8s-seg.pt',
                    'medium': 'yolov8m-seg.pt',
                    'large': 'yolov8l-seg.pt',
                    'extra_large': 'yolov8x-seg.pt'
                },
                'YOLOv11-Seg': {
                    'nano': 'yolo11n-seg.pt',
                    'small': 'yolo11s-seg.pt',
                    'medium': 'yolo11m-seg.pt',
                    'large': 'yolo11l-seg.pt',
                    'extra_large': 'yolo11x-seg.pt'
                },
                'FastSAM': {
                    'small': 'FastSAM-s.pt',
                    'extra_large': 'FastSAM-x.pt'
                },
                'SAM': {
                    'base': 'sam_b.pt',
                    'large': 'sam_l.pt',
                    'huge': 'sam_h.pt'
                },
                'SAM2': {
                    'base': 'sam2_b.pt',
                    'large': 'sam2_l.pt',
                    'small': 'sam2_s.pt',
                    'tiny': 'sam2_t.pt'
                },
                'MobileSAM': {
                    'standard': 'mobile_sam.pt'
                }
            },
            'Pose Estimation': {
                'YOLOv8-Pose': {
                    'nano': 'yolov8n-pose.pt',
                    'small': 'yolov8s-pose.pt',
                    'medium': 'yolov8m-pose.pt',
                    'large': 'yolov8l-pose.pt',
                    'extra_large': 'yolov8x-pose.pt'
                },
                'YOLOv11-Pose': {
                    'nano': 'yolo11n-pose.pt',
                    'small': 'yolo11s-pose.pt',
                    'medium': 'yolo11m-pose.pt',
                    'large': 'yolo11l-pose.pt',
                    'extra_large': 'yolo11x-pose.pt'
                }
            },
            'Classification': {
                'YOLOv8-Cls': {
                    'nano': 'yolov8n-cls.pt',
                    'small': 'yolov8s-cls.pt',
                    'medium': 'yolov8m-cls.pt',
                    'large': 'yolov8l-cls.pt',
                    'extra_large': 'yolov8x-cls.pt'
                },
                'YOLOv11-Cls': {
                    'nano': 'yolo11n-cls.pt',
                    'small': 'yolo11s-cls.pt',
                    'medium': 'yolo11m-cls.pt',
                    'large': 'yolo11l-cls.pt',
                    'extra_large': 'yolo11x-cls.pt'
                }
            }
        }
        
        # ëª¨ë¸ë³„ ê¶Œì¥ ì‚¬ìš© ì¼€ì´ìŠ¤
        self.model_recommendations = {
            'yolov8n.pt': 'ğŸš€ ë¹ ë¥¸ ì¶”ë¡ , ëª¨ë°”ì¼/ì—£ì§€ ë””ë°”ì´ìŠ¤',
            'yolov8s.pt': 'âš–ï¸ ì†ë„ì™€ ì •í™•ë„ì˜ ê· í˜•',
            'yolov8m.pt': 'ğŸ¯ ì¼ë°˜ì ì¸ ìš©ë„, ì¢‹ì€ ì„±ëŠ¥',
            'yolov8l.pt': 'ğŸ” ë†’ì€ ì •í™•ë„ ìš”êµ¬',
            'yolov8x.pt': 'ğŸ† ìµœê³  ì •í™•ë„, ì—°êµ¬ìš©',
            'yolo11n.pt': 'âš¡ ìµœì‹  ì•„í‚¤í…ì²˜, ë¹ ë¥¸ ì†ë„',
            'yolo11s.pt': 'ğŸ†• YOLOv11 ì†Œí˜• ëª¨ë¸',
            'yolo11m.pt': 'ğŸ†• YOLOv11 ì¤‘í˜• ëª¨ë¸',
            'yolo11l.pt': 'ğŸ†• YOLOv11 ëŒ€í˜• ëª¨ë¸',
            'yolo11x.pt': 'ğŸ†• YOLOv11 ìµœëŒ€ ëª¨ë¸',
            'rtdetr-l.pt': 'ğŸ”„ Real-Time DETR, íŠ¸ëœìŠ¤í¬ë¨¸',
            'yolo_nas_s.pt': 'ğŸ§  Neural Architecture Search',
            'yolov8s-world.pt': 'ğŸŒ YOLO-World, ì˜¤í”ˆ ë³´ì¼€ë¸”ëŸ¬ë¦¬',
            'FastSAM-s.pt': 'âš¡ ë¹ ë¥¸ ì„¸ê·¸ë©˜í…Œì´ì…˜',
            'sam_b.pt': 'ğŸ­ SAM ê¸°ë³¸ ëª¨ë¸',
            'yolov8n-pose.pt': 'ğŸ¤¸ í¬ì¦ˆ ì¶”ì •',
            'yolov8n-cls.pt': 'ğŸ“Š ì´ë¯¸ì§€ ë¶„ë¥˜'
        }
    
    def auto_configure_training(self, dataset_path: Path, 
                          workflow_mode: str, 
                          selected_model: str) -> TrainingConfig:
        """
        AI ê¸°ë°˜ í›ˆë ¨ ì„¤ì • ìë™ ìµœì í™” (Windows DataLoader ë¬¸ì œ í•´ê²°)
        Args:
            dataset_path: ë°ì´í„°ì…‹ ê²½ë¡œ
            workflow_mode: ì›Œí¬í”Œë¡œìš° ëª¨ë“œ (auto/semi_auto/manual)
            selected_model: ì‚¬ìš©ìê°€ ì„ íƒí•œ ëª¨ë¸
        """
        config = TrainingConfig()
        config.dataset_path = str(dataset_path)
        config.model_name = selected_model  # ì‚¬ìš©ì ì„ íƒ ëª¨ë¸ ì ìš©
        
        # í•˜ë“œì›¨ì–´ ë¶„ì„
        hardware_info = self.hardware_monitor.get_performance_summary()
        current_hw = hardware_info.get('current', {})
        
        # Windowsì—ì„œ DataLoader ì›Œì»¤ ìˆ˜ ì¡°ì •
        if platform.system() == "Windows":
            config.workers = 0  # Windowsì—ì„œëŠ” ë©€í‹°í”„ë¡œì„¸ì‹± ë¹„í™œì„±í™”
            self.logger.info("Windows í™˜ê²½ ê°ì§€: DataLoader workersë¥¼ 0ìœ¼ë¡œ ì„¤ì •")
        else:
            # Linux/macOSì—ì„œë§Œ ë©€í‹°í”„ë¡œì„¸ì‹± ì‚¬ìš©
            cpu_info = current_hw.get('cpu', {})
            cpu_cores = cpu_info.get('core_count', 4)
            config.workers = min(cpu_cores // 2, 4)  # ì ˆë°˜ë§Œ ì‚¬ìš©
        
        # GPU ë©”ëª¨ë¦¬ ê¸°ë°˜ ë°°ì¹˜ í¬ê¸° ìë™ ì„¤ì • (ëª¨ë¸ í¬ê¸° ê³ ë ¤)
        gpu_info = current_hw.get('gpu', [])
        if gpu_info:
            gpu_memory = gpu_info[0].get('memory_total_mb', 0) / 1024  # GB
            
            # ëª¨ë¸ë³„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì •
            model_memory_factor = self._get_model_memory_factor(selected_model)
            
            if gpu_memory <= 4:
                config.batch_size = max(1, int(8 / model_memory_factor))
            elif gpu_memory <= 8:
                config.batch_size = max(2, int(16 / model_memory_factor))
            elif gpu_memory <= 16:
                config.batch_size = max(4, int(32 / model_memory_factor))
            else:
                config.batch_size = max(8, int(64 / model_memory_factor))
        else:
            # CPU ëª¨ë“œ - ì‘ì€ ë°°ì¹˜ ì‚¬ìš©
            config.batch_size = 2
            config.workers = 0  # CPU ëª¨ë“œì—ì„œë„ ì›Œì»¤ ë¹„í™œì„±í™”
        
        # ë°ì´í„°ì…‹ ë¶„ì„ ê¸°ë°˜ ì„¤ì •
        dataset_info = self._analyze_dataset(dataset_path)
        
        if dataset_info['image_count'] < 1000:
            config.epochs = 200  # ì ì€ ë°ì´í„°ì˜ ê²½ìš° ë” ë§ì€ epochs
        elif dataset_info['image_count'] > 10000:
            config.epochs = 50   # ë§ì€ ë°ì´í„°ì˜ ê²½ìš° ì ì€ epochs
        
        # ì´ë¯¸ì§€ í¬ê¸° ë¶„ì„
        avg_size = dataset_info.get('avg_image_size', 640)
        config.img_size = self._round_to_valid_size(avg_size)
        
        self.logger.info(f"ìë™ ì„¤ì • ì™„ë£Œ: {config.model_name}, "
                        f"batch_size={config.batch_size}, "
                        f"workers={config.workers}, "
                        f"epochs={config.epochs}")
        
        return config
    
    def _get_model_memory_factor(self, model_name: str) -> float:
        """ëª¨ë¸ë³„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì • ê³„ìˆ˜"""
        memory_factors = {
            # Nano models
            'yolov8n.pt': 1.0, 'yolo11n.pt': 1.0, 'yolov5n.pt': 1.0,
            # Small models
            'yolov8s.pt': 1.5, 'yolo11s.pt': 1.5, 'yolov5s.pt': 1.5,
            # Medium models
            'yolov8m.pt': 2.5, 'yolo11m.pt': 2.5, 'yolov5m.pt': 2.5,
            # Large models
            'yolov8l.pt': 4.0, 'yolo11l.pt': 4.0, 'yolov5l.pt': 4.0,
            # Extra large models
            'yolov8x.pt': 6.0, 'yolo11x.pt': 6.0, 'yolov5x.pt': 6.0,
            # Segmentation models (ë” ë§ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©)
            'yolov8n-seg.pt': 1.5, 'yolo11n-seg.pt': 1.5,
            'yolov8s-seg.pt': 2.0, 'yolo11s-seg.pt': 2.0,
            'yolov8m-seg.pt': 3.0, 'yolo11m-seg.pt': 3.0,
            # RT-DETR (íŠ¸ëœìŠ¤í¬ë¨¸, ë” ë§ì€ ë©”ëª¨ë¦¬)
            'rtdetr-l.pt': 5.0, 'rtdetr-x.pt': 7.0,
            # SAM models (ë§¤ìš° í° ë©”ëª¨ë¦¬ ì‚¬ìš©)
            'sam_b.pt': 8.0, 'sam_l.pt': 12.0, 'sam_h.pt': 20.0,
            'sam2_t.pt': 3.0, 'sam2_s.pt': 5.0, 'sam2_b.pt': 8.0, 'sam2_l.pt': 12.0
        }
        return memory_factors.get(model_name, 2.0)  # ê¸°ë³¸ê°’ 2.0
    
    def _analyze_dataset(self, dataset_path: Path) -> Dict[str, Any]:
        """ë°ì´í„°ì…‹ ë¶„ì„"""
        analysis = {
            'image_count': 0,
            'class_count': 0,
            'avg_image_size': 640,
            'image_formats': set(),
            'has_labels': False
        }
        
        try:
            if not dataset_path.exists():
                return analysis
            
            # ì´ë¯¸ì§€ íŒŒì¼ ê²€ìƒ‰
            image_files = []
            for ext in SystemConstants.IMAGE_EXTENSIONS:
                image_files.extend(dataset_path.rglob(f"*{ext}"))
                image_files.extend(dataset_path.rglob(f"*{ext.upper()}"))
            
            analysis['image_count'] = len(image_files)
            
            # ìƒ˜í”Œ ì´ë¯¸ì§€ë“¤ë¡œ í‰ê·  í¬ê¸° ê³„ì‚°
            if image_files and PIL_AVAILABLE:
                sample_size = min(10, len(image_files))
                sample_files = image_files[:sample_size]
                
                sizes = []
                for img_file in sample_files:
                    try:
                        with Image.open(img_file) as img:
                            sizes.append(max(img.size))
                            analysis['image_formats'].add(img.format)
                    except Exception:
                        continue
                
                if sizes:
                    analysis['avg_image_size'] = sum(sizes) // len(sizes)
            
            # í´ë˜ìŠ¤ ìˆ˜ ì¶”ì • (í´ë” êµ¬ì¡° ê¸°ë°˜)
            class_dirs = [d for d in dataset_path.iterdir() 
                         if d.is_dir() and not d.name.startswith('.')]
            analysis['class_count'] = len(class_dirs)
            
            # ë¼ë²¨ íŒŒì¼ í™•ì¸
            label_files = list(dataset_path.rglob("*.txt"))
            analysis['has_labels'] = len(label_files) > 0
            
        except Exception as e:
            self.logger.error(f"ë°ì´í„°ì…‹ ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        return analysis
    
    def _round_to_valid_size(self, size: int) -> int:
        """YOLOì— ìœ íš¨í•œ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë°˜ì˜¬ë¦¼"""
        valid_sizes = [320, 416, 512, 608, 640, 736, 832, 896, 960, 1024, 1280]
        return min(valid_sizes, key=lambda x: abs(x - size))
    
    def analyze_trained_model_classes(self, model_path: str = None) -> Dict[str, Any]:
        """í›ˆë ¨ëœ ëª¨ë¸ì˜ í´ë˜ìŠ¤ ì •ë³´ ë¶„ì„"""
        
        if not model_path and self.current_config:
            # ìµœê·¼ í›ˆë ¨ ê²°ê³¼ì—ì„œ best.pt ì‚¬ìš©
            results_dir = Path(self.current_config.project_name) / self.current_config.experiment_name
            model_path = results_dir / "best.pt"
        
        if not model_path or not Path(model_path).exists():
            self.logger.warning("ë¶„ì„í•  ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return {}
        
        try:
            # í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ
            model = YOLO(model_path)
            
            # ëª¨ë¸ ì •ë³´ ì¶”ì¶œ
            class_info = {
                'model_path': str(model_path),
                'model_type': self._detect_model_type(model_path),
                'num_classes': 0,
                'class_names': {},
                'class_list': [],
                'dataset_info': {}
            }
            
            # ëª¨ë¸ì—ì„œ í´ë˜ìŠ¤ ì •ë³´ ì¶”ì¶œ
            if hasattr(model.model, 'names'):
                names = model.model.names
                if isinstance(names, dict):
                    class_info['class_names'] = names
                    class_info['num_classes'] = len(names)
                    class_info['class_list'] = [names[i] for i in sorted(names.keys())]
                elif isinstance(names, list):
                    class_info['class_names'] = {i: name for i, name in enumerate(names)}
                    class_info['num_classes'] = len(names)
                    class_info['class_list'] = names
            
            # YAML íŒŒì¼ì—ì„œ ì¶”ê°€ ì •ë³´
            if self.current_config and self.current_config.dataset_path:
                yaml_path = Path(self.current_config.dataset_path)
                if yaml_path.exists():
                    try:
                        with open(yaml_path, 'r', encoding='utf-8') as f:
                            yaml_data = yaml.safe_load(f)
                        
                        if yaml_data:
                            class_info['dataset_info'] = {
                                'dataset_path': yaml_data.get('path', ''),
                                'train_path': yaml_data.get('train', ''),
                                'val_path': yaml_data.get('val', ''),
                                'yaml_classes': yaml_data.get('names', {})
                            }
                    except Exception as e:
                        self.logger.debug(f"YAML íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
            
            self.logger.info(f"í´ë˜ìŠ¤ ì •ë³´ ë¶„ì„ ì™„ë£Œ: {class_info['num_classes']}ê°œ í´ë˜ìŠ¤")
            return class_info
            
        except Exception as e:
            self.logger.error(f"ëª¨ë¸ í´ë˜ìŠ¤ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}

    def _detect_model_type(self, model_path: str) -> str:
        """ëª¨ë¸ íƒ€ì… ê°ì§€"""
        model_name = Path(model_path).name.lower()
        
        if 'seg' in model_name:
            return 'Instance Segmentation'
        elif 'pose' in model_name:
            return 'Pose Estimation'
        elif 'cls' in model_name:
            return 'Classification'
        elif 'obb' in model_name:
            return 'Oriented Bounding Box'
        else:
            return 'Object Detection'

    def show_class_detection_results(self, model_path: str = None):
        """í´ë˜ìŠ¤ íƒì§€ ê²°ê³¼ í‘œì‹œ"""
        
        class_info = self.analyze_trained_model_classes(model_path)
        
        if not class_info:
            if RICH_AVAILABLE:
                self.ui.console.print("[red]âŒ í´ë˜ìŠ¤ ì •ë³´ë¥¼ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.[/red]")
            else:
                print("âŒ í´ë˜ìŠ¤ ì •ë³´ë¥¼ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        if not RICH_AVAILABLE:
            self._show_class_info_text(class_info)
        else:
            self._show_class_info_rich(class_info)

    def _show_class_info_text(self, class_info: Dict[str, Any]):
        """í…ìŠ¤íŠ¸ ê¸°ë°˜ í´ë˜ìŠ¤ ì •ë³´ í‘œì‹œ"""
        print("\n" + "="*60)
        print("ğŸ·ï¸ ëª¨ë¸ í´ë˜ìŠ¤ ì •ë³´")
        print("="*60)
        
        print(f"ğŸ“ ëª¨ë¸ íŒŒì¼: {Path(class_info['model_path']).name}")
        print(f"ğŸ¯ ëª¨ë¸ íƒ€ì…: {class_info['model_type']}")
        print(f"ğŸ“Š í´ë˜ìŠ¤ ìˆ˜: {class_info['num_classes']}ê°œ")
        
        if class_info['class_list']:
            print(f"\nğŸ·ï¸ ê°ì§€ ê°€ëŠ¥í•œ í´ë˜ìŠ¤:")
            for i, class_name in enumerate(class_info['class_list']):
                print(f"  {i:2d}. {class_name}")
        
        # ë°ì´í„°ì…‹ ì •ë³´
        dataset_info = class_info.get('dataset_info', {})
        if dataset_info.get('dataset_path'):
            print(f"\nğŸ“‚ í›ˆë ¨ ë°ì´í„°ì…‹: {dataset_info['dataset_path']}")
        
        print("="*60)

    def _show_class_info_rich(self, class_info: Dict[str, Any]):
        """Rich ê¸°ë°˜ í´ë˜ìŠ¤ ì •ë³´ í‘œì‹œ"""
        
        # ë©”ì¸ ì •ë³´ íŒ¨ë„
        info_text = Text()
        info_text.append("ğŸ·ï¸ ëª¨ë¸ í´ë˜ìŠ¤ ë¶„ì„ ê²°ê³¼\n\n", style="bold blue")
        
        info_text.append("ğŸ“ ëª¨ë¸ íŒŒì¼: ", style="cyan")
        info_text.append(f"{Path(class_info['model_path']).name}\n", style="white")
        
        info_text.append("ğŸ¯ ëª¨ë¸ íƒ€ì…: ", style="cyan")
        info_text.append(f"{class_info['model_type']}\n", style="green")
        
        info_text.append("ğŸ“Š í´ë˜ìŠ¤ ìˆ˜: ", style="cyan")
        info_text.append(f"{class_info['num_classes']}ê°œ", style="bold yellow")
        
        info_panel = Panel(
            info_text,
            title="ğŸ“‹ ëª¨ë¸ ì •ë³´",
            border_style="blue"
        )
        
        # í´ë˜ìŠ¤ ëª©ë¡ í…Œì´ë¸”
        if class_info['class_list']:
            class_table = Table(title="ğŸ·ï¸ ê°ì§€ ê°€ëŠ¥í•œ í´ë˜ìŠ¤", show_header=True)
            class_table.add_column("ID", width=4, style="cyan", justify="center")
            class_table.add_column("í´ë˜ìŠ¤ ì´ë¦„", style="bold white")
            class_table.add_column("íƒ€ì…", width=10, style="green")
            
            for i, class_name in enumerate(class_info['class_list']):
                # í´ë˜ìŠ¤ íƒ€ì… ì¶”ì¸¡
                class_type = self._guess_class_type(class_name)
                class_table.add_row(str(i), class_name, class_type)
        
        # ë°ì´í„°ì…‹ ì •ë³´ íŒ¨ë„
        dataset_info = class_info.get('dataset_info', {})
        if dataset_info.get('dataset_path'):
            dataset_text = Text()
            dataset_text.append("ğŸ“‚ ë°ì´í„°ì…‹ ê²½ë¡œ\n", style="bold green")
            dataset_text.append(f"{dataset_info['dataset_path']}\n\n", style="cyan")
            
            if dataset_info.get('train_path'):
                dataset_text.append("ğŸ”¥ í›ˆë ¨ ë°ì´í„°: ", style="yellow")
                dataset_text.append(f"{dataset_info['train_path']}\n", style="white")
            
            if dataset_info.get('val_path'):
                dataset_text.append("âœ… ê²€ì¦ ë°ì´í„°: ", style="yellow")
                dataset_text.append(f"{dataset_info['val_path']}", style="white")
            
            dataset_panel = Panel(
                dataset_text,
                title="ğŸ“ ë°ì´í„°ì…‹ ì •ë³´",
                border_style="green"
            )
        
        # ì‚¬ìš©ë²• ì•ˆë‚´ íŒ¨ë„
        usage_text = Text()
        usage_text.append("ğŸ’¡ ëª¨ë¸ ì‚¬ìš© ë°©ë²•\n\n", style="bold blue")
        usage_text.append("1. ì¶”ë¡  ì‹¤í–‰:\n", style="green")
        usage_text.append(f"   yolo predict model={Path(class_info['model_path']).name} source=ì´ë¯¸ì§€ê²½ë¡œ\n\n", style="dim")
        usage_text.append("2. ê²€ì¦ ì‹¤í–‰:\n", style="green")
        usage_text.append(f"   yolo val model={Path(class_info['model_path']).name} data=dataset.yaml\n\n", style="dim")
        usage_text.append("3. ëª¨ë¸ ë‚´ë³´ë‚´ê¸°:\n", style="green")
        usage_text.append(f"   yolo export model={Path(class_info['model_path']).name} format=onnx", style="dim")
        
        usage_panel = Panel(
            usage_text,
            title="ğŸš€ ì‚¬ìš© ê°€ì´ë“œ",
            border_style="yellow"
        )
        
        # ëª¨ë“  íŒ¨ë„ ì¶œë ¥
        self.ui.console.print("\n")
        self.ui.console.print(info_panel)
        self.ui.console.print("\n")
        
        if class_info['class_list']:
            self.ui.console.print(class_table)
            self.ui.console.print("\n")
        
        if dataset_info.get('dataset_path'):
            self.ui.console.print(dataset_panel)
            self.ui.console.print("\n")
        
        self.ui.console.print(usage_panel)

    def _guess_class_type(self, class_name: str) -> str:
        """í´ë˜ìŠ¤ ì´ë¦„ìœ¼ë¡œë¶€í„° íƒ€ì… ì¶”ì¸¡"""
        class_name_lower = class_name.lower()
        
        # ì‚¬ëŒ ê´€ë ¨
        if any(word in class_name_lower for word in ['person', 'people', 'human', 'ì‚¬ëŒ', 'ì¸ê°„']):
            return "ğŸ‘¤ ì‚¬ëŒ"
        
        # ë™ë¬¼ ê´€ë ¨
        elif any(word in class_name_lower for word in ['dog', 'cat', 'bird', 'animal', 'ê°•ì•„ì§€', 'ê³ ì–‘ì´', 'ìƒˆ']):
            return "ğŸ¾ ë™ë¬¼"
        
        # ì°¨ëŸ‰ ê´€ë ¨
        elif any(word in class_name_lower for word in ['car', 'truck', 'bus', 'vehicle', 'ìë™ì°¨', 'íŠ¸ëŸ­', 'ë²„ìŠ¤']):
            return "ğŸš— ì°¨ëŸ‰"
        
        # ìŒì‹ ê´€ë ¨
        elif any(word in class_name_lower for word in ['food', 'fruit', 'cake', 'ìŒì‹', 'ê³¼ì¼', 'ì¼€ì´í¬']):
            return "ğŸ ìŒì‹"
        
        # ë¬¼ì²´ ê´€ë ¨
        elif any(word in class_name_lower for word in ['bottle', 'chair', 'table', 'ë³‘', 'ì˜ì', 'í…Œì´ë¸”']):
            return "ğŸ“¦ ë¬¼ì²´"
        
        else:
            return "ğŸ·ï¸ ê¸°íƒ€"

    def quick_class_summary(self, model_path: str = None) -> str:
        """í´ë˜ìŠ¤ ì •ë³´ í•œ ì¤„ ìš”ì•½"""
        class_info = self.analyze_trained_model_classes(model_path)
        
        if not class_info or not class_info['class_list']:
            return "âŒ í´ë˜ìŠ¤ ì •ë³´ ì—†ìŒ"
        
        num_classes = class_info['num_classes']
        class_preview = ', '.join(class_info['class_list'][:3])
        
        if num_classes > 3:
            class_preview += f" ì™¸ {num_classes-3}ê°œ"
        
        return f"ğŸ·ï¸ {num_classes}ê°œ í´ë˜ìŠ¤: {class_preview}"
    
    def show_model_selection(self, workflow_mode: str) -> str:
        """ëª¨ë¸ ì„ íƒ UI - ëª¨ë“  ì›Œí¬í”Œë¡œìš°ì—ì„œ ì‚¬ìš©ì ì„ íƒ"""
        
        if not RICH_AVAILABLE:
            return self._show_text_model_selection()
        
        # Rich ê¸°ë°˜ ëª¨ë¸ ì„ íƒ
        return self._show_rich_model_selection()
    
    def _show_text_model_selection(self) -> str:
        """í…ìŠ¤íŠ¸ ê¸°ë°˜ ëª¨ë¸ ì„ íƒ"""
        print("\n" + "="*80)
        print("ğŸ¯ AI ëª¨ë¸ ì„ íƒ")
        print("="*80)
        
        # í”Œë« ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ ìƒì„±
        models = []
        model_counter = 1
        
        for category, model_dict in self.supported_models.items():
            print(f"\nğŸ“‚ {category}:")
            for series, variants in model_dict.items():
                for variant, filename in variants.items():
                    description = self.model_recommendations.get(filename, "AI ëª¨ë¸")
                    print(f"  {model_counter:2d}. {series} {variant} ({filename})")
                    print(f"      {description}")
                    models.append(filename)
                    model_counter += 1
        
        while True:
            try:
                print(f"\nì„ íƒ ê°€ëŠ¥í•œ ëª¨ë¸: 1-{len(models)}")
                choice = input("ëª¨ë¸ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš” (ë˜ëŠ” !help): ").strip()
                
                if choice == "!help":
                    self._show_model_help()
                    continue
                
                choice_num = int(choice)
                if 1 <= choice_num <= len(models):
                    selected_model = models[choice_num - 1]
                    print(f"\nâœ… ì„ íƒëœ ëª¨ë¸: {selected_model}")
                    return selected_model
                else:
                    print(f"âŒ 1ë¶€í„° {len(models)} ì‚¬ì´ì˜ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
                    
            except ValueError:
                print("âŒ ì˜¬ë°”ë¥¸ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            except KeyboardInterrupt:
                print("\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                sys.exit(0)
    
    def _show_rich_model_selection(self) -> str:
        """Rich ê¸°ë°˜ ëª¨ë¸ ì„ íƒ"""
        
        # ì¹´í…Œê³ ë¦¬ ì„ íƒ
        categories = list(self.supported_models.keys())
        
        # ì¹´í…Œê³ ë¦¬ ì„ íƒ í…Œì´ë¸”
        category_table = Table(title="ğŸ¯ AI ëª¨ë¸ ì¹´í…Œê³ ë¦¬ ì„ íƒ", show_header=True)
        category_table.add_column("ë²ˆí˜¸", width=4, style="cyan")
        category_table.add_column("ì¹´í…Œê³ ë¦¬", width=25, style="bold")
        category_table.add_column("ì„¤ëª…", style="blue")
        
        category_descriptions = {
            'Object Detection': 'ê°ì²´ ê²€ì¶œ - ì´ë¯¸ì§€ì—ì„œ ê°ì²´ ìœ„ì¹˜ì™€ í´ë˜ìŠ¤ ì‹ë³„',
            'Instance Segmentation': 'ì¸ìŠ¤í„´ìŠ¤ ë¶„í•  - ê°ì²´ì˜ ì •í™•í•œ ë§ˆìŠ¤í¬ ìƒì„±',
            'Pose Estimation': 'í¬ì¦ˆ ì¶”ì • - ì‚¬ëŒì˜ ê´€ì ˆì  ìœ„ì¹˜ ê²€ì¶œ',
            'Classification': 'ì´ë¯¸ì§€ ë¶„ë¥˜ - ì´ë¯¸ì§€ë¥¼ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜'
        }
        
        for i, category in enumerate(categories, 1):
            description = category_descriptions.get(category, "AI ëª¨ë¸ ì¹´í…Œê³ ë¦¬")
            category_table.add_row(str(i), category, description)
        
        self.ui.console.print(category_table)
        
        while True:
            try:
                category_choice = Prompt.ask(
                    "\n[bold cyan]ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”[/bold cyan]",
                    choices=[str(i) for i in range(1, len(categories) + 1)] + ["!help"],
                    default="1"
                )
                
                if category_choice == "!help":
                    self._show_category_help()
                    continue
                
                selected_category = categories[int(category_choice) - 1]
                break
                
            except (ValueError, IndexError):
                self.ui.console.print("[red]ì˜¬ë°”ë¥¸ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš”.[/red]")
        
        # ì„ íƒëœ ì¹´í…Œê³ ë¦¬ì˜ ëª¨ë¸ë“¤ í‘œì‹œ
        models = self.supported_models[selected_category]
        
        # ëª¨ë¸ ì„ íƒ í…Œì´ë¸”
        model_table = Table(title=f"ğŸ¤– {selected_category} ëª¨ë¸ ì„ íƒ", show_header=True, show_lines=True)
        model_table.add_column("ë²ˆí˜¸", width=4, style="cyan")
        model_table.add_column("ì‹œë¦¬ì¦ˆ", width=15, style="bold")
        model_table.add_column("í¬ê¸°", width=12, style="yellow")
        model_table.add_column("ëª¨ë¸ íŒŒì¼", width=20, style="green")
        model_table.add_column("ê¶Œì¥ ìš©ë„", style="blue")
        
        flat_models = []
        model_counter = 1
        
        for series, variants in models.items():
            for variant, filename in variants.items():
                recommendation = self.model_recommendations.get(filename, "ë²”ìš© AI ëª¨ë¸")
                model_table.add_row(
                    str(model_counter),
                    series,
                    variant.capitalize(),
                    filename,
                    recommendation
                )
                flat_models.append(filename)
                model_counter += 1
        
        self.ui.console.print(model_table)
        
        # í•˜ë“œì›¨ì–´ ê¸°ë°˜ ì¶”ì²œ
        self._show_hardware_recommendations()
        
        while True:
            try:
                model_choice = Prompt.ask(
                    "\n[bold cyan]ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”[/bold cyan]",
                    choices=[str(i) for i in range(1, len(flat_models) + 1)] + ["!help", "back"],
                    default="1"
                )
                
                if model_choice == "!help":
                    self._show_model_help()
                    continue
                elif model_choice == "back":
                    return self._show_rich_model_selection()  # ì¹´í…Œê³ ë¦¬ ì„ íƒìœ¼ë¡œ ëŒì•„ê°€ê¸°
                
                selected_model = flat_models[int(model_choice) - 1]
                
                # ì„ íƒ í™•ì¸
                self.ui.console.print(f"\n[green]âœ… ì„ íƒëœ ëª¨ë¸: {selected_model}[/green]")
                if Confirm.ask("ì´ ëª¨ë¸ë¡œ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?", default=True):
                    return selected_model
                
            except (ValueError, IndexError):
                self.ui.console.print("[red]ì˜¬ë°”ë¥¸ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš”.[/red]")

    def _show_hardware_recommendations(self):
        """í•˜ë“œì›¨ì–´ ê¸°ë°˜ ëª¨ë¸ ì¶”ì²œ"""
        hardware_info = self.hardware_monitor.get_performance_summary()
        current_hw = hardware_info.get('current', {})
        
        # GPU ì •ë³´ ê¸°ë°˜ ì¶”ì²œ
        gpu_info = current_hw.get('gpu', [])
        
        rec_text = Text()
        rec_text.append("ğŸ’¡ í•˜ë“œì›¨ì–´ ê¸°ë°˜ ì¶”ì²œ\n\n", style="bold blue")
        
        if gpu_info:
            gpu_memory = gpu_info[0].get('memory_total_mb', 0) / 1024  # GB
            gpu_name = gpu_info[0].get('name', 'Unknown GPU')
            
            rec_text.append(f"ğŸ® GPU: {gpu_name} ({gpu_memory:.1f}GB)\n", style="cyan")
            
            if gpu_memory <= 4:
                rec_text.append("ì¶”ì²œ: Nano ëª¨ë¸ (n) - ë©”ëª¨ë¦¬ ì ˆì•½\n", style="green")
            elif gpu_memory <= 8:
                rec_text.append("ì¶”ì²œ: Small ëª¨ë¸ (s) - ê· í˜•ì¡íŒ ì„±ëŠ¥\n", style="green")
            elif gpu_memory <= 16:
                rec_text.append("ì¶”ì²œ: Medium ëª¨ë¸ (m) - ì¢‹ì€ ì„±ëŠ¥\n", style="green")
            else:
                rec_text.append("ì¶”ì²œ: Large/XL ëª¨ë¸ (l/x) - ìµœê³  ì„±ëŠ¥\n", style="green")
        else:
            rec_text.append("ğŸ–¥ï¸ CPU ëª¨ë“œ\n", style="yellow")
            rec_text.append("ì¶”ì²œ: Nano/Small ëª¨ë¸ - CPU ìµœì í™”\n", style="green")
        
        # ë©”ëª¨ë¦¬ ì •ë³´
        memory_info = current_hw.get('memory', {})
        memory_total = memory_info.get('total_gb', 0)
        rec_text.append(f"ğŸ’¾ RAM: {memory_total:.1f}GB\n", style="cyan")
        
        if memory_total < 8:
            rec_text.append("âš ï¸ ë©”ëª¨ë¦¬ ë¶€ì¡± - ì‘ì€ ë°°ì¹˜ í¬ê¸° ì‚¬ìš© ì˜ˆì •\n", style="yellow")
        
        rec_panel = Panel(
            rec_text,
            title="ğŸ¯ í•˜ë“œì›¨ì–´ ì¶”ì²œ",
            title_align="left",
            border_style="blue"
        )
        
        self.ui.console.print(rec_panel)
    
    def _show_category_help(self):
        """ì¹´í…Œê³ ë¦¬ ë„ì›€ë§"""
        help_text = Text()
        help_text.append("ğŸ“‚ ëª¨ë¸ ì¹´í…Œê³ ë¦¬ ì„¤ëª…\n\n", style="bold blue")
        
        help_text.append("ğŸ¯ Object Detection\n", style="bold green")
        help_text.append("   â€¢ ì´ë¯¸ì§€ì—ì„œ ê°ì²´ì˜ ìœ„ì¹˜(ë°”ìš´ë”© ë°•ìŠ¤)ì™€ í´ë˜ìŠ¤ë¥¼ ê²€ì¶œ\n", style="green")
        help_text.append("   â€¢ ê°€ì¥ ì¼ë°˜ì ì¸ ì»´í“¨í„° ë¹„ì „ ì‘ì—…\n", style="green")
        help_text.append("   â€¢ ì˜ˆ: ì‚¬ëŒ, ìë™ì°¨, ë™ë¬¼ ë“±ì„ ì°¾ê³  ë¶„ë¥˜\n\n", style="green")
        
        help_text.append("ğŸ­ Instance Segmentation\n", style="bold yellow")
        help_text.append("   â€¢ ê°ì²´ì˜ ì •í™•í•œ í”½ì…€ ë‹¨ìœ„ ë§ˆìŠ¤í¬ë¥¼ ìƒì„±\n", style="yellow")
        help_text.append("   â€¢ Object Detectionë³´ë‹¤ ë” ì •ë°€í•œ ìœ„ì¹˜ ì •ë³´\n", style="yellow")
        help_text.append("   â€¢ ì˜ë£Œ ì´ë¯¸ì§•, ììœ¨ì£¼í–‰ ë“±ì— í™œìš©\n\n", style="yellow")
        
        help_text.append("ğŸ¤¸ Pose Estimation\n", style="bold red")
        help_text.append("   â€¢ ì‚¬ëŒì˜ ê´€ì ˆì (í‚¤í¬ì¸íŠ¸) ìœ„ì¹˜ë¥¼ ê²€ì¶œ\n", style="red")
        help_text.append("   â€¢ ìŠ¤í¬ì¸  ë¶„ì„, í”¼íŠ¸ë‹ˆìŠ¤, AR/VR ë“±ì— í™œìš©\n", style="red")
        help_text.append("   â€¢ 17ê°œ ì£¼ìš” ê´€ì ˆì  ì¢Œí‘œ ì œê³µ\n\n", style="red")
        
        help_text.append("ğŸ“Š Classification\n", style="bold blue")
        help_text.append("   â€¢ ì´ë¯¸ì§€ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ í´ë˜ìŠ¤ë¡œ ë¶„ë¥˜\n", style="blue")
        help_text.append("   â€¢ ìœ„ì¹˜ ì •ë³´ ì—†ì´ 'ë¬´ì—‡ì¸ê°€'ë§Œ ì‹ë³„\n", style="blue")
        help_text.append("   â€¢ í’ˆì§ˆ ê²€ì‚¬, ì˜ë£Œ ì§„ë‹¨ ë“±ì— í™œìš©\n", style="blue")
        
        help_panel = Panel(
            help_text,
            title="â“ ì¹´í…Œê³ ë¦¬ ë„ì›€ë§",
            title_align="left",
            border_style="blue"
        )
        
        self.ui.console.print(help_panel)
    
    def _show_model_help(self):
        """ëª¨ë¸ ì„ íƒ ë„ì›€ë§"""
        help_text = Text()
        help_text.append("ğŸ¤– ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ\n\n", style="bold blue")
        
        help_text.append("ğŸ“ ëª¨ë¸ í¬ê¸°ë³„ íŠ¹ì„±\n\n", style="bold green")
        help_text.append("â€¢ ", style="green")
        help_text.append("Nano (n): ", style="bold green")
        help_text.append("ê°€ì¥ ë¹ ë¦„, ëª¨ë°”ì¼/ì—£ì§€ ìµœì í™”\n", style="white")
        help_text.append("â€¢ ", style="green")
        help_text.append("Small (s): ", style="bold green")
        help_text.append("ì†ë„ì™€ ì •í™•ë„ì˜ ê· í˜•\n", style="white")
        help_text.append("â€¢ ", style="green")
        help_text.append("Medium (m): ", style="bold green")
        help_text.append("ì¼ë°˜ì ì¸ ìš©ë„, ì¢‹ì€ ì„±ëŠ¥\n", style="white")
        help_text.append("â€¢ ", style="green")
        help_text.append("Large (l): ", style="bold green")
        help_text.append("ë†’ì€ ì •í™•ë„, ë” ë§ì€ ë¦¬ì†ŒìŠ¤ í•„ìš”\n", style="white")
        help_text.append("â€¢ ", style="green")
        help_text.append("Extra Large (x): ", style="bold green")
        help_text.append("ìµœê³  ì •í™•ë„, ì—°êµ¬/ì„œë²„ìš©\n\n", style="white")
        
        help_text.append("ğŸ”¥ ë²„ì „ë³„ íŠ¹ì§•\n\n", style="bold yellow")
        help_text.append("â€¢ ", style="yellow")
        help_text.append("YOLOv11: ", style="bold yellow")
        help_text.append("ìµœì‹ , ê°€ì¥ íš¨ìœ¨ì \n", style="white")
        help_text.append("â€¢ ", style="yellow")
        help_text.append("YOLOv8: ", style="bold yellow")
        help_text.append("ì•ˆì •ì , ë„ë¦¬ ì‚¬ìš©ë¨\n", style="white")
        help_text.append("â€¢ ", style="yellow")
        help_text.append("RT-DETR: ", style="bold yellow")
        help_text.append("íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜, ë†’ì€ ì •í™•ë„\n", style="white")
        help_text.append("â€¢ ", style="yellow")
        help_text.append("SAM/SAM2: ", style="bold yellow")
        help_text.append("ë¶„í•  ì „ë¬¸, ë²”ìš©ì„± ìš°ìˆ˜\n", style="white")
        help_text.append("â€¢ ", style="yellow")
        help_text.append("YOLO-World: ", style="bold yellow")
        help_text.append("ì˜¤í”ˆ ë³´ì¼€ë¸”ëŸ¬ë¦¬, ìƒˆë¡œìš´ í´ë˜ìŠ¤ ê°ì§€\n\n", style="white")
        
        help_text.append("ğŸ’¡ ì„ íƒ íŒ\n\n", style="bold blue")
        help_text.append("â€¢ ì²˜ìŒ ì‚¬ìš©: YOLOv8s ë˜ëŠ” YOLOv11s ì¶”ì²œ\n", style="blue")
        help_text.append("â€¢ ì‹¤ì‹œê°„ ì¶”ë¡ : Nano ëª¨ë¸\n", style="blue")
        help_text.append("â€¢ ìµœê³  ì •í™•ë„: Large ë˜ëŠ” XL ëª¨ë¸\n", style="blue")
        help_text.append("â€¢ ë©”ëª¨ë¦¬ ë¶€ì¡±: Small ì´í•˜ ëª¨ë¸\n", style="blue")
        
        help_panel = Panel(
            help_text,
            title="ğŸ’¡ ëª¨ë¸ ì„ íƒ ë„ì›€ë§",
            title_align="left",
            border_style="blue"
        )
        
        self.ui.console.print(help_panel)
    
    def setup_training_environment(self, config: TrainingConfig) -> bool:
        """í›ˆë ¨ í™˜ê²½ ì„¤ì •"""
        try:
            self.logger.info("í›ˆë ¨ í™˜ê²½ ì„¤ì • ì¤‘...")
        
            # í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
            project_dir = Path(config.project_name)
            project_dir.mkdir(exist_ok=True)
        
            # ì‹¤í–‰ ë””ë ‰í† ë¦¬ ìƒì„±
            run_dir = project_dir / config.experiment_name
            run_counter = 1
            while run_dir.exists():
                run_dir = project_dir / f"{config.experiment_name}{run_counter}"
                run_counter += 1
        
            run_dir.mkdir(parents=True)
            config.experiment_name = run_dir.name
        
            # ì›ë³¸ ë°ì´í„°ì…‹ ê²½ë¡œ ì €ì¥
            original_dataset_path = config.dataset_path
        
            # YAML ì„¤ì • íŒŒì¼ ìƒì„±
            yaml_config = self._create_dataset_yaml(config)
            yaml_path = run_dir / "dataset.yaml"
        
            # YAML íŒŒì¼ ì €ì¥
            with open(yaml_path, 'w', encoding='utf-8') as f:
                yaml.dump(yaml_config, f, default_flow_style=False, allow_unicode=True)
        
            # ìƒì„±ëœ YAML ë‚´ìš© ë¡œê·¸
            self.logger.info(f"YAML íŒŒì¼ ìƒì„±: {yaml_path}")
            self.logger.info(f"YAML ë‚´ìš©: {yaml_config}")
        
            # configì˜ dataset_pathë¥¼ yaml íŒŒì¼ ê²½ë¡œë¡œ ì—…ë°ì´íŠ¸
            config.dataset_path = str(yaml_path)
        
            # YAML íŒŒì¼ ê²€ì¦
            if not self._verify_yaml_file(yaml_path):
                self.logger.error("ìƒì„±ëœ YAML íŒŒì¼ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
                return False
        
            self.logger.info(f"í›ˆë ¨ í™˜ê²½ ì„¤ì • ì™„ë£Œ: {run_dir}")
            return True
        
        except Exception as e:
            self.logger.error(f"í›ˆë ¨ í™˜ê²½ ì„¤ì • ì‹¤íŒ¨: {e}")
            return False

    def _verify_yaml_file(self, yaml_path: Path) -> bool:
        """YAML íŒŒì¼ ìœ íš¨ì„± ê²€ì¦"""
        try:
            # YAML íŒŒì¼ ì½ê¸° í…ŒìŠ¤íŠ¸
            with open(yaml_path, 'r', encoding='utf-8') as f:
                yaml_data = yaml.safe_load(f)
            
            if not yaml_data:
                self.logger.error("YAML íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
                return False
            
            # í•„ìˆ˜ í‚¤ í™•ì¸
            required_keys = ['path', 'train', 'names']
            for key in required_keys:
                if key not in yaml_data:
                    self.logger.error(f"YAML íŒŒì¼ì— í•„ìˆ˜ í‚¤ '{key}'ê°€ ì—†ìŠµë‹ˆë‹¤")
                    return False
            
            # ê²½ë¡œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            dataset_root = Path(yaml_data['path'])
            train_path = dataset_root / yaml_data['train']
            
            if not train_path.exists():
                self.logger.error(f"í›ˆë ¨ ë°ì´í„° ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {train_path}")
                return False
            
            # ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸
            image_files = []
            for ext in SystemConstants.IMAGE_EXTENSIONS:
                image_files.extend(list(train_path.rglob(f"*{ext}")))
                image_files.extend(list(train_path.rglob(f"*{ext.upper()}")))
            
            if not image_files:
                self.logger.error(f"í›ˆë ¨ ê²½ë¡œì— ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {train_path}")
                return False
            
            self.logger.info(f"YAML ê²€ì¦ ì„±ê³µ: {len(image_files)}ê°œ ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸")
            return True
            
        except Exception as e:
            self.logger.error(f"YAML íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False
        
    def show_dataset_structure(self, dataset_path: Path):
        """ë°ì´í„°ì…‹ êµ¬ì¡° ë””ë²„ê¹… ì •ë³´ í‘œì‹œ"""
        if not RICH_AVAILABLE:
            print(f"\në°ì´í„°ì…‹ êµ¬ì¡° ë¶„ì„: {dataset_path}")
            return
        
        tree = Tree(f"ğŸ“ {dataset_path.name}")
        
        try:
            def add_directory(parent_tree, directory, max_depth=3, current_depth=0):
                if current_depth >= max_depth:
                    return
                
                items = list(directory.iterdir())[:20]  # ìµœëŒ€ 20ê°œ í•­ëª©ë§Œ
                
                for item in items:
                    if item.is_dir():
                        dir_node = parent_tree.add(f"ğŸ“ {item.name}")
                        add_directory(dir_node, item, max_depth, current_depth + 1)
                    elif item.suffix.lower() in SystemConstants.IMAGE_EXTENSIONS:
                        parent_tree.add(f"ğŸ–¼ï¸ {item.name}")
                    elif item.suffix.lower() == '.txt':
                        parent_tree.add(f"ğŸ“ {item.name}")
                    else:
                        parent_tree.add(f"ğŸ“„ {item.name}")
            
            add_directory(tree, dataset_path)
            
            self.ui.console.print("\n")
            self.ui.console.print(Panel(tree, title="ğŸ” ë°ì´í„°ì…‹ êµ¬ì¡°", border_style="blue"))
            
        except Exception as e:
            self.logger.error(f"ë°ì´í„°ì…‹ êµ¬ì¡° í‘œì‹œ ì‹¤íŒ¨: {e}")

    
    def _create_dataset_yaml(self, config: TrainingConfig) -> Dict[str, Any]:
        """ë°ì´í„°ì…‹ YAML ì„¤ì • ìƒì„± - ê²½ë¡œ ë¬¸ì œ í•´ê²°"""
        dataset_path = Path(config.dataset_path).resolve()  # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
    
        self.logger.info(f"ë°ì´í„°ì…‹ ê²½ë¡œ ë¶„ì„ ì¤‘: {dataset_path}")
    
        # ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ êµ¬ì¡° íŒ¨í„´ í™•ì¸
        train_path = None
        val_path = None
        test_path = None
    
        # íŒ¨í„´ 1: train/val/test í´ë” êµ¬ì¡°
        if (dataset_path / "train").exists():
            train_path = dataset_path / "train"
            val_path = dataset_path / "val" if (dataset_path / "val").exists() else train_path
            if (dataset_path / "test").exists():
                test_path = dataset_path / "test"
    
        # íŒ¨í„´ 2: images/labels í´ë” êµ¬ì¡°
        elif (dataset_path / "images").exists():
            images_dir = dataset_path / "images"
        
            # images í•˜ìœ„ì— train/val í™•ì¸
            if (images_dir / "train").exists():
                train_path = images_dir / "train"
                val_path = images_dir / "val" if (images_dir / "val").exists() else train_path
                if (images_dir / "test").exists():
                    test_path = images_dir / "test"
            else:
                # images í´ë” ìì²´ë¥¼ trainìœ¼ë¡œ ì‚¬ìš©
                train_path = images_dir
                val_path = images_dir
    
        # íŒ¨í„´ 3: ì§ì ‘ ì´ë¯¸ì§€ íŒŒì¼ë“¤ì´ ìˆëŠ” ê²½ìš°
        else:
            # ë°ì´í„°ì…‹ ë£¨íŠ¸ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
            image_files = []
            for ext in SystemConstants.IMAGE_EXTENSIONS:
                image_files.extend(list(dataset_path.rglob(f"*{ext}")))
                image_files.extend(list(dataset_path.rglob(f"*{ext.upper()}")))
        
            if image_files:
                # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬ë¥¼ ì°¾ê¸°
                first_image_dir = image_files[0].parent
                train_path = first_image_dir
                val_path = first_image_dir
            
                self.logger.info(f"ì´ë¯¸ì§€ íŒŒì¼ {len(image_files)}ê°œë¥¼ {first_image_dir}ì—ì„œ ë°œê²¬")
    
        # ê²½ë¡œê°€ ë°œê²¬ë˜ì§€ ì•Šì€ ê²½ìš°
        if not train_path:
            # ê°•ì œë¡œ ë°ì´í„°ì…‹ ë£¨íŠ¸ë¥¼ trainìœ¼ë¡œ ì‚¬ìš©
            train_path = dataset_path
            val_path = dataset_path
            self.logger.warning(f"í‘œì¤€ êµ¬ì¡°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì‚¬ìš©: {dataset_path}")
    
        # ìƒëŒ€ ê²½ë¡œ ê³„ì‚° (YOLOê°€ ìƒëŒ€ ê²½ë¡œë¥¼ ì„ í˜¸í•¨)
        try:
            train_rel = os.path.relpath(train_path, dataset_path)
            val_rel = os.path.relpath(val_path, dataset_path)
        except ValueError:
            # ì„œë¡œ ë‹¤ë¥¸ ë“œë¼ì´ë¸Œì— ìˆëŠ” ê²½ìš° ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
            train_rel = str(train_path)
            val_rel = str(val_path)
    
        # í´ë˜ìŠ¤ ì •ë³´ ìë™ ê°ì§€
        classes = self._detect_classes(dataset_path, train_path)
    
        yaml_config = {
            'path': str(dataset_path),  # ë°ì´í„°ì…‹ ë£¨íŠ¸ ê²½ë¡œ
            'train': train_rel,         # í›ˆë ¨ ì´ë¯¸ì§€ ê²½ë¡œ
            'val': val_rel,            # ê²€ì¦ ì´ë¯¸ì§€ ê²½ë¡œ
            'names': classes           # í´ë˜ìŠ¤ ì •ë³´
        }
    
        # í…ŒìŠ¤íŠ¸ ê²½ë¡œê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if test_path:
            try:
                test_rel = os.path.relpath(test_path, dataset_path)
                yaml_config['test'] = test_rel
            except ValueError:
                yaml_config['test'] = str(test_path)
    
        # ìƒì„±ëœ ê²½ë¡œ ê²€ì¦
        self._validate_dataset_paths(dataset_path, yaml_config)
    
        self.logger.info(f"YAML ì„¤ì • ìƒì„± ì™„ë£Œ: train={train_rel}, val={val_rel}, classes={len(classes)}")
    
        return yaml_config

    def _validate_dataset_paths(self, dataset_root: Path, yaml_config: Dict[str, Any]):
        """ìƒì„±ëœ ë°ì´í„°ì…‹ ê²½ë¡œ ê²€ì¦"""
        issues = []
    
        # í›ˆë ¨ ê²½ë¡œ ê²€ì¦
        train_path = dataset_root / yaml_config['train']
        if not train_path.exists():
            issues.append(f"í›ˆë ¨ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {train_path}")
        else:
            # ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸
            image_count = len([f for f in train_path.rglob("*") 
                            if f.suffix.lower() in SystemConstants.IMAGE_EXTENSIONS])
            if image_count == 0:
                issues.append(f"í›ˆë ¨ ê²½ë¡œì— ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŒ: {train_path}")
            else:
                self.logger.info(f"í›ˆë ¨ ì´ë¯¸ì§€ {image_count}ê°œ ë°œê²¬")
    
        # ê²€ì¦ ê²½ë¡œ í™•ì¸
        val_path = dataset_root / yaml_config['val']
        if not val_path.exists():
            issues.append(f"ê²€ì¦ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {val_path}")
    
        # ë¬¸ì œê°€ ìˆìœ¼ë©´ ê²½ê³ 
        if issues:
            self.logger.warning("ë°ì´í„°ì…‹ ê²½ë¡œ ë¬¸ì œ ë°œê²¬:")
            for issue in issues:
                self.logger.warning(f"  - {issue}")

    def _detect_classes(self, dataset_path: Path, train_path: Path = None) -> Dict[int, str]:
        """í´ë˜ìŠ¤ ìë™ ê°ì§€ - ê°œì„ ëœ ë²„ì „"""
        classes = {}
    
        try:
            # ë°©ë²• 1: classes.txt ë˜ëŠ” names.txt íŒŒì¼ ì°¾ê¸°
            class_files = []
            for filename in ['classes.txt', 'names.txt', 'class_names.txt']:
                class_files.extend(list(dataset_path.rglob(filename)))
        
            if class_files:
                class_file = class_files[0]
                self.logger.info(f"í´ë˜ìŠ¤ íŒŒì¼ ë°œê²¬: {class_file}")
            
                with open(class_file, 'r', encoding='utf-8') as f:
                    for i, line in enumerate(f):
                        class_name = line.strip()
                        if class_name:  # ë¹ˆ ì¤„ ì œì™¸
                            classes[i] = class_name
            
                if classes:
                    self.logger.info(f"í´ë˜ìŠ¤ íŒŒì¼ì—ì„œ {len(classes)}ê°œ í´ë˜ìŠ¤ ë¡œë“œ")
                    return classes
        
            # ë°©ë²• 2: data.yaml íŒŒì¼ì—ì„œ í´ë˜ìŠ¤ ì •ë³´ ì¶”ì¶œ
            yaml_files = list(dataset_path.rglob("data.yaml")) + list(dataset_path.rglob("dataset.yaml"))
            for yaml_file in yaml_files:
                try:
                    with open(yaml_file, 'r', encoding='utf-8') as f:
                        existing_yaml = yaml.safe_load(f)
                        if existing_yaml and 'names' in existing_yaml:
                            names = existing_yaml['names']
                            if isinstance(names, dict):
                                classes = {int(k): v for k, v in names.items()}
                            elif isinstance(names, list):
                                classes = {i: name for i, name in enumerate(names)}
                        
                            if classes:
                                self.logger.info(f"ê¸°ì¡´ YAMLì—ì„œ {len(classes)}ê°œ í´ë˜ìŠ¤ ë¡œë“œ")
                                return classes
                except Exception as e:
                    self.logger.debug(f"YAML íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ ({yaml_file}): {e}")
        
            # ë°©ë²• 3: í´ë” êµ¬ì¡°ë¡œ í´ë˜ìŠ¤ ì¶”ì • (train ê²½ë¡œ ìš°ì„ )
            search_paths = [train_path, dataset_path] if train_path else [dataset_path]
        
            for search_path in search_paths:
                if not search_path or not search_path.exists():
                    continue
                
                # í•˜ìœ„ ë””ë ‰í† ë¦¬ë“¤ì„ í´ë˜ìŠ¤ë¡œ ê°„ì£¼
                class_dirs = [d for d in search_path.iterdir() 
                            if d.is_dir() and not d.name.startswith('.') 
                            and d.name not in ['images', 'labels', 'train', 'val', 'test']]
            
                if class_dirs:
                    # ê° ë””ë ‰í† ë¦¬ì— ì´ë¯¸ì§€ê°€ ìˆëŠ”ì§€ í™•ì¸
                    valid_class_dirs = []
                    for class_dir in class_dirs:
                        image_count = len([f for f in class_dir.rglob("*") 
                                        if f.suffix.lower() in SystemConstants.IMAGE_EXTENSIONS])
                        if image_count > 0:
                            valid_class_dirs.append(class_dir.name)
                
                    if valid_class_dirs:
                        classes = {i: name for i, name in enumerate(sorted(valid_class_dirs))}
                        self.logger.info(f"í´ë” êµ¬ì¡°ì—ì„œ {len(classes)}ê°œ í´ë˜ìŠ¤ ê°ì§€: {list(classes.values())}")
                        return classes
        
            # ë°©ë²• 4: ë¼ë²¨ íŒŒì¼ì—ì„œ í´ë˜ìŠ¤ ID ì¶”ì¶œ
            label_files = list(dataset_path.rglob("*.txt"))
            class_ids = set()
        
            for label_file in label_files[:50]:  # ìµœëŒ€ 50ê°œ íŒŒì¼ë§Œ í™•ì¸
                try:
                    with open(label_file, 'r') as f:
                        for line in f:
                            parts = line.strip().split()
                            if parts and parts[0].isdigit():
                                class_ids.add(int(parts[0]))
                except Exception:
                    continue
        
            if class_ids:
                max_class_id = max(class_ids)
                classes = {i: f"class_{i}" for i in range(max_class_id + 1)}
                self.logger.info(f"ë¼ë²¨ íŒŒì¼ì—ì„œ {len(classes)}ê°œ í´ë˜ìŠ¤ ê°ì§€ (class_0 ~ class_{max_class_id})")
                return classes
                
        except Exception as e:
            self.logger.warning(f"í´ë˜ìŠ¤ ê°ì§€ ì¤‘ ì˜¤ë¥˜: {e}")
    
        # ê¸°ë³¸ê°’: ë‹¨ì¼ í´ë˜ìŠ¤
        classes = {0: "object"}
        self.logger.info("ê¸°ë³¸ í´ë˜ìŠ¤ ì‚¬ìš©: object")
    
        return classes
    
    def start_training(self, config: TrainingConfig) -> bool:
        """í›ˆë ¨ ì‹œì‘ - ëª¨ë‹ˆí„°ë§ ì¸í„°í˜ì´ìŠ¤ ê°œì„ """
        if not ULTRALYTICS_AVAILABLE:
            self.ui.show_error("YOLO ë¼ì´ë¸ŒëŸ¬ë¦¬ ì˜¤ë¥˜", 
                            "Ultralytics ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                            "pip install ultralyticsë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
            return False
        
        try:
            self.is_training = True
            self.current_config = config
            
            # ëª¨ë¸ ë¡œë“œ
            model = YOLO(config.model_name)
            
            # Windows í™˜ê²½ íŠ¹ë³„ ì„¤ì •
            if platform.system() == "Windows":
                self._setup_windows_compatibility()
            
            # YOLO ìœ íš¨ í›ˆë ¨ íŒŒë¼ë¯¸í„°ë§Œ ì„¤ì •
            train_args = {
                'data': config.dataset_path,
                'epochs': config.epochs,
                'batch': config.batch_size,
                'imgsz': config.img_size,
                'lr0': config.learning_rate,
                'device': config.device,
                'project': config.project_name,
                'name': config.experiment_name,
                'save_period': config.save_period,
                'workers': config.workers,
                'amp': config.mixed_precision,
                'augment': config.data_augmentation,
                'verbose': False,  # YOLO ìì²´ ì¶œë ¥ ìµœì†Œí™”
                'exist_ok': True
            }
            
            # Early stopping ì„¤ì •
            if config.early_stopping:
                train_args['patience'] = 50
            
            # ëª¨ë¸ë³„ íŠ¹í™” ì„¤ì • ì¶”ê°€
            self._add_model_specific_args(train_args, config.model_name)
            
            self.logger.info(f"ğŸš€ í›ˆë ¨ ì‹œì‘: {config.model_name}")
            self.logger.info(f"ğŸ“Š ì„¤ì •: epochs={config.epochs}, batch={config.batch_size}")
            
            # í•˜ë“œì›¨ì–´ ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ì €ë¹ˆë„)
            self.hardware_monitor.start_monitoring()
            
            # í›ˆë ¨ ì‹¤í–‰ - ê°„ì†Œí™”ëœ ëª¨ë‹ˆí„°ë§
            try:
                if RICH_AVAILABLE:
                    # Rich ê¸°ë°˜ ê°„ë‹¨í•œ ëª¨ë‹ˆí„°ë§
                    self._train_with_rich_monitoring(model, train_args, config)
                else:
                    # í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°„ë‹¨í•œ ëª¨ë‹ˆí„°ë§
                    self._train_with_text_monitoring(model, train_args, config)
                
                # í›ˆë ¨ ì™„ë£Œ
                self.training_stats['success'] = True
                self.is_training = False
                
                self.logger.info("ğŸ‰ í›ˆë ¨ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ!")
                return True
                
            except Exception as training_error:
                error_msg = str(training_error)
                self.logger.error(f"âŒ í›ˆë ¨ ì¤‘ ì˜¤ë¥˜: {error_msg}")
                self.training_stats['error'] = error_msg
                self.training_stats['success'] = False
                self.is_training = False
                
                self._suggest_training_solutions(error_msg)
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ í›ˆë ¨ ì‹œì‘ ì‹¤íŒ¨: {e}")
            self.is_training = False
            return False
        finally:
            self.hardware_monitor.stop_monitoring()

    def _train_with_rich_monitoring(self, model, train_args: Dict, config: TrainingConfig):
        """Rich ê¸°ë°˜ ê°„ì†Œí™”ëœ í›ˆë ¨ ëª¨ë‹ˆí„°ë§"""
        
        # ì´ˆê¸° ìƒíƒœ í‘œì‹œ
        self.ui.console.print("\n" + "="*80)
        self.ui.console.print(f"ğŸš€ [bold blue]{config.model_name}[/bold blue] í›ˆë ¨ ì‹œì‘")
        self.ui.console.print("="*80)
        
        # ì„¤ì • ì •ë³´ í‘œì‹œ (í•œ ë²ˆë§Œ)
        info_table = Table(show_header=False, box=None)
        info_table.add_column("í•­ëª©", width=15, style="cyan")
        info_table.add_column("ê°’", style="white")
        
        info_table.add_row("ğŸ“Š ì—í­", str(config.epochs))
        info_table.add_row("ğŸ“¦ ë°°ì¹˜ í¬ê¸°", str(config.batch_size))
        info_table.add_row("ğŸ–¼ï¸ ì´ë¯¸ì§€ í¬ê¸°", str(config.img_size))
        info_table.add_row("ğŸ“ˆ í•™ìŠµë¥ ", str(config.learning_rate))
        info_table.add_row("âš™ï¸ ì›Œì»¤", str(config.workers))
        
        self.ui.console.print(info_table)
        self.ui.console.print("\nğŸ’¡ [dim]í›ˆë ¨ì´ ì§„í–‰ë©ë‹ˆë‹¤. ì™„ë£Œê¹Œì§€ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...[/dim]\n")
        
        # YOLO í›ˆë ¨ ì‹œì‘ (ì¶œë ¥ ìµœì†Œí™”)
        import sys
        from contextlib import redirect_stdout, redirect_stderr
        from io import StringIO
        
        # YOLO ì¶œë ¥ì„ ìº¡ì²˜í•˜ì—¬ ì£¼ìš” ì •ë³´ë§Œ í‘œì‹œ
        captured_output = StringIO()
        
        try:
            # YOLO í›ˆë ¨ ì‹¤í–‰ (ì¶œë ¥ ìº¡ì²˜)
            with redirect_stdout(captured_output):
                results = model.train(**train_args)
            
            self.training_stats['results'] = results
            
        except Exception as e:
            # ì¶œë ¥ ë³µì›í•˜ê³  ì—ëŸ¬ ì „íŒŒ
            raise e

    def _train_with_text_monitoring(self, model, train_args: Dict, config: TrainingConfig):
        """í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°„ì†Œí™”ëœ í›ˆë ¨ ëª¨ë‹ˆí„°ë§"""
        
        print("\n" + "="*60)
        print(f"ğŸš€ {config.model_name} í›ˆë ¨ ì‹œì‘")
        print("="*60)
        print(f"ì—í­: {config.epochs}, ë°°ì¹˜: {config.batch_size}")
        print(f"ì´ë¯¸ì§€ í¬ê¸°: {config.img_size}")
        print("ğŸ’¡ í›ˆë ¨ì´ ì§„í–‰ë©ë‹ˆë‹¤. ì™„ë£Œê¹Œì§€ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
        print("="*60)
        
        # ê°„ë‹¨í•œ ì§„í–‰ë¥  í‘œì‹œ
        start_time = time.time()
        
        try:
            results = model.train(**train_args)
            self.training_stats['results'] = results
            
            elapsed = int(time.time() - start_time)
            mins, secs = divmod(elapsed, 60)
            print(f"\nğŸ‰ í›ˆë ¨ ì™„ë£Œ! ì†Œìš”ì‹œê°„: {mins}ë¶„ {secs}ì´ˆ")
            
        except Exception as e:
            raise e

    def _add_model_specific_args(self, train_args: Dict, model_name: str):
        """ëª¨ë¸ë³„ íŠ¹í™” ì„¤ì • ì¶”ê°€"""
        model_name_lower = model_name.lower()
        
        # ê³µí†µ ìµœì í™” ì„¤ì •
        train_args.update({
            'optimizer': 'auto',
            'close_mosaic': 10,
            'cos_lr': False,
            'warmup_epochs': 3,
            'warmup_momentum': 0.8,
            'warmup_bias_lr': 0.1,
            'box': 7.5,
            'cls': 0.5,
            'dfl': 1.5,
            'plots': True,
            'save_json': False,
            'cache': False
        })
        
        if 'seg' in model_name_lower:
            # Segmentation ëª¨ë¸
            train_args.update({
                'mask_ratio': 4,
                'overlap_mask': True
            })
        elif 'pose' in model_name_lower:
            # Pose ëª¨ë¸
            train_args.update({
                'pose': 12.0,
                'kobj': 1.0
            })
        elif 'cls' in model_name_lower:
            # Classification ëª¨ë¸
            train_args.update({
                'dropout': 0.2
            })

    def _suggest_training_solutions(self, error_msg: str):
        """í›ˆë ¨ ì˜¤ë¥˜ì— ëŒ€í•œ êµ¬ì²´ì ì¸ í•´ê²°ì±… ì œì‹œ"""
        error_lower = error_msg.lower()
        
        if not RICH_AVAILABLE:
            print("\ní•´ê²° ë°©ë²•:")
            if 'argument' in error_lower or 'parameter' in error_lower:
                print("1. YOLO íŒŒë¼ë¯¸í„° ì˜¤ë¥˜ - ìµœì‹  Ultralytics ë²„ì „ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”")
                print("   pip install --upgrade ultralytics")
            elif 'memory' in error_lower or 'cuda' in error_lower:
                print("1. GPU ë©”ëª¨ë¦¬ ë¶€ì¡± - ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì—¬ë³´ì„¸ìš”")
                print("2. Mixed precision (AMP) í™œì„±í™” í™•ì¸")
            elif 'dataloader' in error_lower or 'worker' in error_lower:
                print("1. Workers=0ìœ¼ë¡œ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸")
                print("2. ë°°ì¹˜ í¬ê¸°ë¥¼ ë” ì¤„ì—¬ë³´ì„¸ìš”")
            return
        
        # Rich ê¸°ë°˜ í•´ê²°ì±… í‘œì‹œ
        suggestions = []
        
        if 'argument' in error_lower or 'parameter' in error_lower:
            suggestions.extend([
                "ğŸ”§ YOLO íŒŒë¼ë¯¸í„° ì˜¤ë¥˜ í•´ê²°:",
                "1. Ultralytics ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ìµœì‹  ë²„ì „ìœ¼ë¡œ ì—…ë°ì´íŠ¸",
                "   pip install --upgrade ultralytics",
                "2. ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒë¼ë¯¸í„° ì œê±° ì™„ë£Œ",
                "3. ëª¨ë¸ ë²„ì „ê³¼ íŒŒë¼ë¯¸í„° í˜¸í™˜ì„± í™•ì¸"
            ])
        
        if 'memory' in error_lower or 'cuda' in error_lower:
            suggestions.extend([
                "ğŸ’¾ ë©”ëª¨ë¦¬ ë¬¸ì œ í•´ê²°:",
                f"1. í˜„ì¬ ë°°ì¹˜ í¬ê¸° {self.current_config.batch_size} â†’ ë” ì‘ê²Œ",
                "2. ì´ë¯¸ì§€ í¬ê¸° ì¤„ì´ê¸° (640 â†’ 416 ë˜ëŠ” 320)",
                "3. Mixed precision (AMP) í™œì„±í™” í™•ì¸",
                "4. GPU ë©”ëª¨ë¦¬ ì •ë¦¬: torch.cuda.empty_cache()"
            ])
        
        if 'dataloader' in error_lower or 'worker' in error_lower:
            suggestions.extend([
                "âš™ï¸ DataLoader ë¬¸ì œ í•´ê²°:",
                "1. Workers=0 ì„¤ì • í™•ì¸ (Windows í•„ìˆ˜)",
                "2. ë°°ì¹˜ í¬ê¸°ë¥¼ 1 ë˜ëŠ” 2ë¡œ ì¤„ì´ê¸°",
                "3. ë°ì´í„°ì…‹ ê²½ë¡œì— íŠ¹ìˆ˜ë¬¸ì/í•œê¸€ í™•ì¸"
            ])
        
        if 'yaml' in error_lower or 'dataset' in error_lower:
            suggestions.extend([
                "ğŸ“ ë°ì´í„°ì…‹ ë¬¸ì œ í•´ê²°:",
                "1. dataset.yaml íŒŒì¼ ê²½ë¡œ í™•ì¸",
                "2. ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸",
                "3. í´ë˜ìŠ¤ ì •ì˜ ì˜¬ë°”ë¥¸ì§€ í™•ì¸"
            ])
        
        if not suggestions:
            suggestions = [
                "ğŸ” ì¼ë°˜ì ì¸ í•´ê²° ë°©ë²•:",
                "1. ë°°ì¹˜ í¬ê¸°ë¥¼ ì ˆë°˜ìœ¼ë¡œ ì¤„ì´ê¸°",
                "2. ì´ë¯¸ì§€ í¬ê¸° ì¤„ì´ê¸° (640 â†’ 416)",
                "3. Workers=0ìœ¼ë¡œ ì„¤ì •",
                "4. Ultralytics ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—…ë°ì´íŠ¸"
            ]
        
        suggestion_text = Text()
        for suggestion in suggestions:
            if suggestion.endswith(':'):
                suggestion_text.append(f"\n{suggestion}\n", style="bold yellow")
            elif suggestion.startswith(('1.', '2.', '3.', '4.')):
                suggestion_text.append(f"   {suggestion}\n", style="green")
            else:
                suggestion_text.append(f"   {suggestion}\n", style="cyan")
        
        suggestion_panel = Panel(
            suggestion_text,
            title="ğŸ’¡ í•´ê²° ë°©ë²•",
            border_style="yellow"
        )
        
        self.ui.console.print(suggestion_panel)

    def _get_valid_yolo_params(self) -> set:
        """YOLOì—ì„œ ì§€ì›í•˜ëŠ” ìœ íš¨í•œ íŒŒë¼ë¯¸í„° ëª©ë¡"""
        return {
            # ê¸°ë³¸ í›ˆë ¨ íŒŒë¼ë¯¸í„°
            'data', 'epochs', 'batch', 'imgsz', 'lr0', 'device', 'project', 'name',
            'save_period', 'workers', 'amp', 'augment', 'verbose', 'exist_ok',
            'patience', 'optimizer', 'close_mosaic', 'resume', 'single_cls',
            
            # í•™ìŠµë¥  ë° ì •ê·œí™”
            'cos_lr', 'dropout', 'weight_decay', 'warmup_epochs', 'warmup_momentum',
            'warmup_bias_lr', 'momentum', 'lr1', 'lrf',
            
            # ì†ì‹¤ í•¨ìˆ˜ ê°€ì¤‘ì¹˜
            'box', 'cls', 'dfl', 'pose', 'kobj', 'label_smoothing',
            
            # ë°°ì¹˜ ë° ì´ë¯¸ì§€ ì²˜ë¦¬
            'nbs', 'overlap_mask', 'mask_ratio', 'rect', 'cache',
            
            # ì¶œë ¥ ë° ì €ì¥
            'plots', 'save_json', 'save_hybrid', 'save_txt', 'save_conf',
            
            # ì¶”ë¡  ì„¤ì •
            'conf', 'iou', 'max_det', 'half', 'dnn',
            
            # ë°ì´í„° ì¦ê°•
            'hsv_h', 'hsv_s', 'hsv_v', 'degrees', 'translate', 'scale',
            'shear', 'perspective', 'flipud', 'fliplr', 'mosaic', 'mixup', 'copy_paste'
        }

    def _validate_train_args(self, train_args: Dict[str, Any]) -> Dict[str, Any]:
        """í›ˆë ¨ íŒŒë¼ë¯¸í„° ìœ íš¨ì„± ê²€ì‚¬ ë° í•„í„°ë§"""
        valid_params = self._get_valid_yolo_params()
        
        # ìœ íš¨í•œ íŒŒë¼ë¯¸í„°ë§Œ í•„í„°ë§
        filtered_args = {k: v for k, v in train_args.items() if k in valid_params}
        
        # ì œê±°ëœ íŒŒë¼ë¯¸í„° ë¡œê¹…
        removed_params = set(train_args.keys()) - set(filtered_args.keys())
        if removed_params:
            self.logger.info(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒë¼ë¯¸í„° ì œê±°: {removed_params}")
        
        return filtered_args

    def _setup_windows_compatibility(self):
        """Windows í™˜ê²½ì—ì„œì˜ í˜¸í™˜ì„± ì„¤ì •"""
        if platform.system() != "Windows":
            return
        
        try:
            # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
            os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
            os.environ['OMP_NUM_THREADS'] = '1'
            os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
            
            # ë©€í‹°í”„ë¡œì„¸ì‹± ì„¤ì •
            import multiprocessing
            try:
                multiprocessing.set_start_method('spawn', force=True)
                self.logger.info("ë©€í‹°í”„ë¡œì„¸ì‹± ì‹œì‘ ë°©ë²•ì„ 'spawn'ìœ¼ë¡œ ì„¤ì •")
            except RuntimeError:
                # ì´ë¯¸ ì„¤ì •ëœ ê²½ìš°
                pass
            
            # PyTorch ì„¤ì •
            if TORCH_AVAILABLE:
                torch.set_num_threads(1)
                if torch.cuda.is_available():
                    torch.backends.cudnn.benchmark = False
                    torch.backends.cudnn.deterministic = True
            
            self.logger.info("Windows í˜¸í™˜ì„± ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"Windows í˜¸í™˜ì„± ì„¤ì • ì‹¤íŒ¨: {e}")

    def _training_worker(self, model, train_args):
        """í›ˆë ¨ ì›Œì»¤ ìŠ¤ë ˆë“œ"""
        try:
            results = model.train(**train_args)
            self.training_stats['results'] = results
            self.training_stats['success'] = True
        except Exception as e:
            self.training_stats['error'] = str(e)
            self.training_stats['success'] = False
        finally:
            self.is_training = False
    
    def _monitor_training(self, training_thread):
        """í›ˆë ¨ ëª¨ë‹ˆí„°ë§"""
        if not RICH_AVAILABLE:
            print("í›ˆë ¨ ì¤‘... ì™„ë£Œê¹Œì§€ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.")
            training_thread.join()
            return
    
        # Rich ê¸°ë°˜ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
        def create_training_layout():
            # ë©”ì¸ ë ˆì´ì•„ì›ƒ ìƒì„±
            main_layout = Layout()
        
            # ìƒë‹¨ ë ˆì´ì•„ì›ƒ (í—¤ë”)
            header_panel = Panel(
                f"ğŸš€ AI ëª¨ë¸ í›ˆë ¨ ì¤‘ - {self.current_config.model_name}",
                style="bold blue"
            )
        
            # ì¢Œì¸¡ íŒ¨ë„ (í›ˆë ¨ í†µê³„)
            stats_text = Text()
            stats_text.append("ğŸ“Š í›ˆë ¨ ì„¤ì •\n\n", style="bold green")
            stats_text.append(f"ëª¨ë¸: {self.current_config.model_name}\n", style="cyan")
            stats_text.append(f"ì—í­: {self.current_config.epochs}\n", style="cyan")
            stats_text.append(f"ë°°ì¹˜ í¬ê¸°: {self.current_config.batch_size}\n", style="cyan")
            stats_text.append(f"ì´ë¯¸ì§€ í¬ê¸°: {self.current_config.img_size}\n", style="cyan")
            stats_text.append(f"í•™ìŠµë¥ : {self.current_config.learning_rate}\n", style="cyan")
        
            stats_text.append("\nğŸ“ˆ ì§„í–‰ ìƒí™©\n\n", style="bold yellow")
            if self.is_training:
                stats_text.append("ìƒíƒœ: í›ˆë ¨ ì¤‘...\n", style="green")
            else:
                if self.training_stats.get('success'):
                    stats_text.append("ìƒíƒœ: í›ˆë ¨ ì™„ë£Œ!\n", style="green")
                else:
                    stats_text.append("ìƒíƒœ: í›ˆë ¨ ì‹¤íŒ¨\n", style="red")
        
            stats_panel = Panel(stats_text, title="ğŸ“Š í›ˆë ¨ ì •ë³´", border_style="green")
        
            # ìš°ì¸¡ íŒ¨ë„ (í•˜ë“œì›¨ì–´ ëª¨ë‹ˆí„°ë§)
            hardware_info = self.hardware_monitor.get_performance_summary()
            current = hardware_info.get('current', {})
        
            hw_text = Text()
            hw_text.append("ğŸ’» í•˜ë“œì›¨ì–´ ìƒíƒœ\n\n", style="bold blue")
        
            # CPU
            cpu = current.get('cpu', {})
            cpu_usage = cpu.get('usage_percent', 0)
            hw_text.append(f"CPU: {cpu_usage:.1f}%", style="white")
            if cpu_usage > 80:
                hw_text.append(" ğŸ”¥", style="red")
            hw_text.append("\n")
        
            # ë©”ëª¨ë¦¬
            memory = current.get('memory', {})
            memory_usage = memory.get('used_percent', 0)
            hw_text.append(f"ë©”ëª¨ë¦¬: {memory_usage:.1f}%", style="white")
            if memory_usage > 85:
                hw_text.append(" âš ï¸", style="yellow")
            hw_text.append("\n")
        
            # GPU
            gpu_list = current.get('gpu', [])
            if gpu_list:
                for i, gpu in enumerate(gpu_list):
                    gpu_load = gpu.get('load_percent', 0)
                    gpu_memory = gpu.get('memory_percent', 0)
                    hw_text.append(f"GPU {i}: {gpu_load:.1f}% (VRAM: {gpu_memory:.1f}%)", style="white")
                    if gpu_memory > 90:
                        hw_text.append(" ğŸš¨", style="red")
                    hw_text.append("\n")
            else:
                hw_text.append("GPU: ì‚¬ìš© ë¶ˆê°€ (CPU ëª¨ë“œ)\n", style="yellow")
        
            # NPU
            npu = current.get('npu', {})
            if npu.get('available'):
                hw_text.append(f"NPU: ì‚¬ìš© ê°€ëŠ¥\n", style="cyan")
        
            # ì¶”ì²œì‚¬í•­
            recommendations = hardware_info.get('recommendations', [])
            if recommendations:
                hw_text.append("\nğŸ’¡ ìµœì í™” ì¶”ì²œ:\n", style="bold yellow")
                for i, rec in enumerate(recommendations[:2], 1):
                    hw_text.append(f"{i}. {rec[:50]}...\n" if len(rec) > 50 else f"{i}. {rec}\n", style="yellow")
        
            hardware_panel = Panel(hw_text, title="ğŸ–¥ï¸ í•˜ë“œì›¨ì–´", border_style="blue")
        
            # í•˜ë‹¨ íŒ¨ë„ (í‘¸í„°)
            footer_panel = Panel(
                "Press Ctrl+C to stop monitoring (training continues in background)",
                style="dim"
            )
        
            # ë ˆì´ì•„ì›ƒ êµ¬ì„±
            # ìƒí•˜ ë¶„í• 
            main_layout.split_column(
                Layout(header_panel, name="header", size=3),
                Layout(name="body", ratio=1),
                Layout(footer_panel, name="footer", size=3)
            )
        
            # ë°”ë””ë¥¼ ì¢Œìš°ë¡œ ë¶„í• 
            main_layout["body"].split_row(
                Layout(stats_panel, name="left", size=45),
                Layout(hardware_panel, name="right", ratio=1)
            )
        
            return main_layout
    
        # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹¤í–‰
        try:
            with Live(create_training_layout(), console=self.ui.console, 
                    refresh_per_second=1) as live:
            
                while training_thread.is_alive():
                    try:
                        live.update(create_training_layout())
                        time.sleep(1)
                    except Exception as layout_error:
                        # ë ˆì´ì•„ì›ƒ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ëª¨ë“œë¡œ ì „í™˜
                        self.logger.warning(f"ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {layout_error}")
                        break
            
                # ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸
                try:
                    live.update(create_training_layout())
                except Exception:
                    pass
                
        except KeyboardInterrupt:
            self.ui.console.print("\n[yellow]ëª¨ë‹ˆí„°ë§ì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤. í›ˆë ¨ì€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ê³„ì†ë©ë‹ˆë‹¤.[/yellow]")
        except Exception as e:
            self.logger.error(f"ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
            self.ui.console.print(f"[red]ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜ ë°œìƒ: {e}[/red]")
            self.ui.console.print("[yellow]í…ìŠ¤íŠ¸ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤...[/yellow]")
        
            # í…ìŠ¤íŠ¸ ëª¨ë“œë¡œ í´ë°±
            print("í›ˆë ¨ ì§„í–‰ ì¤‘... (í…ìŠ¤íŠ¸ ëª¨ë“œ)")
            while training_thread.is_alive():
                print(".", end="", flush=True)
                time.sleep(5)
            print(" ì™„ë£Œ!")
    
        # í›ˆë ¨ ì™„ë£Œ ëŒ€ê¸°
        training_thread.join()
    
        # ê²°ê³¼ í‘œì‹œ
        if self.training_stats.get('success'):
            self.ui.console.print("\n[green]ğŸ‰ í›ˆë ¨ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤![/green]")
            self.show_training_results()
        else:
            error_msg = self.training_stats.get('error', 'Unknown error')
            self.ui.console.print(f"\n[red]âŒ í›ˆë ¨ ì‹¤íŒ¨: {error_msg}[/red]")
    
    def show_training_results(self):
        """í›ˆë ¨ ê²°ê³¼ í‘œì‹œ - í´ë˜ìŠ¤ ì •ë³´ í¬í•¨"""
        if not self.current_config:
            return
        
        results_dir = Path(self.current_config.project_name) / self.current_config.experiment_name
        best_model = results_dir / "best.pt"
        
        # ê¸°ì¡´ ê²°ê³¼ í‘œì‹œ
        if not RICH_AVAILABLE:
            print(f"\nğŸ‰ í›ˆë ¨ ì™„ë£Œ!")
            print(f"ğŸ“ ê²°ê³¼ ë””ë ‰í† ë¦¬: {results_dir}")
            
            # í´ë˜ìŠ¤ ì •ë³´ ê°„ë‹¨ í‘œì‹œ
            if best_model.exists():
                class_summary = self.quick_class_summary(str(best_model))
                print(f"ğŸ“‹ {class_summary}")
            
            return
        
        # Rich ê¸°ë°˜ ê²°ê³¼ í‘œì‹œ
        result_text = Text()
        result_text.append("ğŸ‰ í›ˆë ¨ ì™„ë£Œ!\n\n", style="bold green")
        result_text.append(f"ğŸ“ ê²°ê³¼ ê²½ë¡œ: {results_dir}\n\n", style="cyan")
        
        # í´ë˜ìŠ¤ ì •ë³´ ìš”ì•½ ì¶”ê°€
        if best_model.exists():
            class_summary = self.quick_class_summary(str(best_model))
            result_text.append(f"ğŸ“‹ {class_summary}\n\n", style="yellow")
        
        # íŒŒì¼ ëª©ë¡
        if results_dir.exists():
            key_files = {
                'best.pt': 'ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸',
                'last.pt': 'ğŸ“± ë§ˆì§€ë§‰ ëª¨ë¸', 
                'results.png': 'ğŸ“Š í›ˆë ¨ ê²°ê³¼ ê·¸ë˜í”„'
            }
            
            for filename, description in key_files.items():
                file_path = results_dir / filename
                if file_path.exists():
                    file_size = file_path.stat().st_size / (1024 * 1024)
                    result_text.append(f"  âœ… {description} ({file_size:.1f}MB)\n", style="green")
        
        result_panel = Panel(
            result_text,
            title="ğŸ† í›ˆë ¨ ê²°ê³¼",
            border_style="green"
        )
        
        self.ui.console.print(result_panel)
        
        # í´ë˜ìŠ¤ ì •ë³´ ìƒì„¸ ë³´ê¸° ì˜µì…˜
        if best_model.exists():
            if Confirm.ask("ğŸ·ï¸ ìƒì„¸í•œ í´ë˜ìŠ¤ ì •ë³´ë¥¼ ë³´ì‹œê² ìŠµë‹ˆê¹Œ?", default=True):
                self.show_class_detection_results(str(best_model))
        
        # ê²°ê³¼ í´ë” ì—´ê¸° ì˜µì…˜
        if Confirm.ask("ğŸ“‚ ê²°ê³¼ í´ë”ë¥¼ ì—¬ì‹œê² ìŠµë‹ˆê¹Œ?", default=False):
            try:
                if platform.system() == "Windows":
                    os.startfile(results_dir)
                elif platform.system() == "Darwin":  # macOS
                    subprocess.run(["open", results_dir])
                else:  # Linux
                    subprocess.run(["xdg-open", results_dir])
            except Exception as e:
                self.ui.console.print(f"[red]í´ë” ì—´ê¸° ì‹¤íŒ¨: {e}[/red]")

    def _show_training_progress_summary(self, config: TrainingConfig):
        """í›ˆë ¨ ì§„í–‰ ìš”ì•½ í‘œì‹œ (ì£¼ê¸°ì )"""
        if not RICH_AVAILABLE:
            return
        
        # 5ì´ˆë§ˆë‹¤ í•œ ë²ˆì”©ë§Œ í‘œì‹œ
        current_time = time.time()
        if not hasattr(self, '_last_progress_time'):
            self._last_progress_time = current_time
        
        if current_time - self._last_progress_time < 5:
            return
        
        self._last_progress_time = current_time
        
        # í•˜ë“œì›¨ì–´ ìƒíƒœ ê°„ë‹¨íˆ í‘œì‹œ
        try:
            hw_info = self.hardware_monitor.get_performance_summary()
            current = hw_info.get('current', {})
            
            status_text = f"ğŸ’» CPU: {current.get('cpu', {}).get('usage_percent', 0):.0f}% | "
            status_text += f"ğŸ’¾ RAM: {current.get('memory', {}).get('used_percent', 0):.0f}%"
            
            gpu_list = current.get('gpu', [])
            if gpu_list:
                gpu = gpu_list[0]
                status_text += f" | ğŸ® GPU: {gpu.get('load_percent', 0):.0f}%"
            
            # ìƒíƒœ ë¼ì¸ ì—…ë°ì´íŠ¸ (í•œ ì¤„ë¡œ)
            self.ui.console.print(f"\r[dim]{status_text}[/dim]", end="")
            
        except Exception:
            pass

    def analyze_model_classes_standalone(model_path: str):
        """ë…ë¦½ ì‹¤í–‰ ê°€ëŠ¥í•œ ëª¨ë¸ í´ë˜ìŠ¤ ë¶„ì„ í•¨ìˆ˜"""
        
        print("ğŸ” ëª¨ë¸ í´ë˜ìŠ¤ ë¶„ì„ ì¤‘...")
        
        if not Path(model_path).exists():
            print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
            return
        
        try:
            model = YOLO(model_path)
            
            print(f"\nğŸ“ ëª¨ë¸: {Path(model_path).name}")
            
            # í´ë˜ìŠ¤ ì •ë³´ ì¶”ì¶œ
            if hasattr(model.model, 'names'):
                names = model.model.names
                
                if isinstance(names, dict):
                    class_names = names
                    num_classes = len(names)
                    class_list = [names[i] for i in sorted(names.keys())]
                elif isinstance(names, list):
                    class_names = {i: name for i, name in enumerate(names)}
                    num_classes = len(names)
                    class_list = names
                else:
                    print("âŒ í´ë˜ìŠ¤ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return
                
                print(f"ğŸ“Š ì´ {num_classes}ê°œ í´ë˜ìŠ¤:")
                print("-" * 40)
                
                for i, class_name in enumerate(class_list):
                    print(f"  {i:2d}. {class_name}")
                
                print("-" * 40)
                print(f"âœ… ë¶„ì„ ì™„ë£Œ!")
                
            else:
                print("âŒ ëª¨ë¸ì—ì„œ í´ë˜ìŠ¤ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        except Exception as e:
            print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")

    # ì‚¬ìš© ì˜ˆì‹œ
    if __name__ == "__main__":
        import sys
        
        if len(sys.argv) > 1:
            model_path = sys.argv[1]
            analyze_model_classes_standalone(model_path)
        else:
            print("ì‚¬ìš©ë²•: python script.py model.pt")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ® ë©”ì¸ ì‹œìŠ¤í…œ í´ë˜ìŠ¤
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AITrainingSystem:
    """
    AI í›ˆë ¨ ì‹œìŠ¤í…œ ë©”ì¸ í´ë˜ìŠ¤
    - ëª¨ë“  ì»´í¬ë„ŒíŠ¸ í†µí•© ê´€ë¦¬
    - ì›Œí¬í”Œë¡œìš° ì œì–´
    - ì‚¬ìš©ì ì¸í„°ë™ì…˜
    """
    
    def __init__(self):
        # í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.language_manager = LanguageManager()
        self.logger = AdvancedLogger("AITrainingSystem")
        self.ui = AdvancedUI(self.language_manager, self.logger)
        self.help_system = HelpSystem(self.language_manager, self.ui)
        
        # ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸
        self.security_manager = SecurityManager(self.logger)
        self.config_manager = ConfigurationManager(self.logger)
        self.integrity_manager = DataIntegrityManager(self.logger)
        self.hardware_monitor = HardwareMonitor(self.logger)
        
        # AI ì‹œìŠ¤í…œ
        self.dataset_finder = SmartDatasetFinder(self.logger, self.security_manager)
        self.archive_processor = AdvancedArchiveProcessor(self.logger, self.integrity_manager)
        self.error_solver = AIErrorSolver(self.logger, self.ui)
        self.training_engine = TrainingEngine(self.logger, self.ui, self.hardware_monitor)
        
        # í˜„ì¬ ìƒíƒœ
        self.current_workflow = None
        self.system_config = None
        
        self.logger.info(f"AI í›ˆë ¨ ì‹œìŠ¤í…œ v{SystemConstants.VERSION} ì´ˆê¸°í™” ì™„ë£Œ")
    
    def run(self):
        """ë©”ì¸ ì‹¤í–‰ ë£¨í”„"""
        try:
            # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            if not self._initialize_system():
                return
            
            # í™˜ì˜ í™”ë©´
            self.ui.show_welcome_screen()
            
            # ë©”ì¸ ì›Œí¬í”Œë¡œìš°
            self._main_workflow()
            
        except KeyboardInterrupt:
            if RICH_AVAILABLE:
                self.ui.console.print("\n[yellow]ì‚¬ìš©ìì— ì˜í•´ í”„ë¡œê·¸ë¨ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.[/yellow]")
            else:
                print("\ní”„ë¡œê·¸ë¨ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            self.logger.critical(f"ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
            self.error_solver.show_error_analysis(str(e), {
                'operation': 'system_startup',
                'framework': 'AI Training System v3.0'
            })
        finally:
            self._cleanup()
    
    def _initialize_system(self) -> bool:
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™” - ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”"""
        try:
            # Windows í˜¸í™˜ì„± ì„¤ì • (ì¶”ê°€)
            if platform.system() == "Windows":
                self.training_engine._setup_windows_compatibility()
            
            # ê¸°ì¡´ ì´ˆê¸°í™” ì½”ë“œ...
            self.system_config = self.config_manager.load_config()
            self.language_manager.set_language(self.system_config.language)

            # ì„¤ì • ë¡œë“œ (ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ì„¤ì • ì‚¬ìš©)
            try:
                self.system_config = self.config_manager.load_config()
            except Exception as config_error:
                self.logger.warning(f"ì„¤ì • ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ ì„¤ì • ì‚¬ìš©: {config_error}")
                self.system_config = SystemConfig()
            
            # ì–¸ì–´ ì„¤ì • ì ìš©
            self.language_manager.set_language(self.system_config.language)
            
            # í•„ìˆ˜ ë””ë ‰í† ë¦¬ ìƒì„±
            directories = ['logs', 'backups', 'configs', 'datasets']
            for directory in directories:
                try:
                    Path(directory).mkdir(exist_ok=True)
                except Exception as dir_error:
                    self.logger.warning(f"ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨ ({directory}): {dir_error}")
            
            # ì²´í¬ì„¬ ìºì‹œ ë¡œë“œ (ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
            try:
                self.integrity_manager.load_checksum_cache(Path("configs/checksum_cache.json"))
            except Exception as cache_error:
                self.logger.warning(f"ì²´í¬ì„¬ ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {cache_error}")
            
            # í•˜ë“œì›¨ì–´ ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
            try:
                self.hardware_monitor.start_monitoring()
            except Exception as monitor_error:
                self.logger.warning(f"í•˜ë“œì›¨ì–´ ëª¨ë‹ˆí„°ë§ ì‹œì‘ ì‹¤íŒ¨: {monitor_error}")
            
            self.logger.info("ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
        
    def debug_config_file(self):
        """ì„¤ì • íŒŒì¼ ë””ë²„ê¹… ì •ë³´ ì¶œë ¥"""
        if not self.config_file.exists():
            self.logger.info("ì„¤ì • íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
            return
        
        try:
            with open(self.config_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            self.logger.info(f"ì„¤ì • íŒŒì¼ í¬ê¸°: {len(content)} bytes")
            self.logger.info(f"ì„¤ì • íŒŒì¼ ë‚´ìš© (ì²˜ìŒ 200ì): {content[:200]}...")
            
            # JSON íŒŒì‹± í…ŒìŠ¤íŠ¸
            config_data = json.loads(content)
            self.logger.info(f"JSON íŒŒì‹± ì„±ê³µ, í‚¤: {list(config_data.keys())}")
            
            # ë©”íƒ€ë°ì´í„° í™•ì¸
            if '_metadata' in config_data:
                metadata = config_data['_metadata']
                self.logger.info(f"ë©”íƒ€ë°ì´í„°: {metadata}")
            
        except Exception as e:
            self.logger.error(f"ì„¤ì • íŒŒì¼ ë””ë²„ê¹… ì‹¤íŒ¨: {e}")
    
    def _main_workflow(self):
        """ë©”ì¸ ì›Œí¬í”Œë¡œìš°"""
        # 1. ì›Œí¬í”Œë¡œìš° ì„ íƒ
        self.current_workflow = self.ui.show_workflow_menu()
        self.logger.info(f"ì›Œí¬í”Œë¡œìš° ì„ íƒ: {self.current_workflow}")
        
        # 2. ì‹œìŠ¤í…œ í™˜ê²½ ê²€ì‚¬
        if not self._check_system_environment():
            return
        
        # 3. ë°ì´í„°ì…‹ ê²€ìƒ‰ ë° ì„ íƒ
        selected_datasets = self._dataset_workflow()
        if not selected_datasets:
            if RICH_AVAILABLE:
                self.ui.console.print("[red]ë°ì´í„°ì…‹ì„ ì„ íƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.[/red]")
            else:
                print("ë°ì´í„°ì…‹ì„ ì„ íƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        # 4. ë°ì´í„°ì…‹ ì²˜ë¦¬
        processed_dataset = self._process_dataset(selected_datasets[0])
        if not processed_dataset:
            return
        
        # 5. í›ˆë ¨ ì„¤ì •
        training_config = self._training_configuration(processed_dataset)
        if not training_config:
            return
        
        # 6. í›ˆë ¨ ì‹¤í–‰
        self._execute_training(training_config)
    
    def _check_system_environment(self) -> bool:
        """ì‹œìŠ¤í…œ í™˜ê²½ ê²€ì‚¬"""
        with self.ui.show_progress("ì‹œìŠ¤í…œ í™˜ê²½ ê²€ì‚¬ ì¤‘...", total=5) as progress:
            
            # Python ë²„ì „ í™•ì¸
            progress.update(1, "Python ë²„ì „ í™•ì¸")
            if sys.version_info < (3, 8):
                self.ui.show_error("Python ë²„ì „ ì˜¤ë¥˜", 
                                 "Python 3.8 ì´ìƒì´ í•„ìš”í•©ë‹ˆë‹¤.",
                                 f"í˜„ì¬ ë²„ì „: {platform.python_version()}")
                return False
            
            # í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸
            progress.update(1, "í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸")
            missing_libs = []
            
            if not TORCH_AVAILABLE:
                missing_libs.append("torch")
            if not ULTRALYTICS_AVAILABLE:
                missing_libs.append("ultralytics")
            if not PIL_AVAILABLE:
                missing_libs.append("Pillow")
            
            if missing_libs:
                self.ui.show_error("ë¼ì´ë¸ŒëŸ¬ë¦¬ ëˆ„ë½", 
                                 f"í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {', '.join(missing_libs)}",
                                 f"ì„¤ì¹˜ ëª…ë ¹: pip install {' '.join(missing_libs)}")
                return False
            
            # í•˜ë“œì›¨ì–´ í™•ì¸
            progress.update(1, "í•˜ë“œì›¨ì–´ í™•ì¸")
            hardware_summary = self.hardware_monitor.get_performance_summary()
            current_hw = hardware_summary.get('current', {})
            
            # GPU í™•ì¸
            progress.update(1, "GPU í™•ì¸")
            gpu_info = current_hw.get('gpu', [])
            if not gpu_info and TORCH_AVAILABLE:
                if not torch.cuda.is_available():
                    if RICH_AVAILABLE:
                        self.ui.console.print("[yellow]âš ï¸ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.[/yellow]")
                    else:
                        print("âš ï¸ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
            
            # ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
            progress.update(1, "ë””ìŠ¤í¬ ê³µê°„ í™•ì¸")
            disk_usage = shutil.disk_usage('.')
            free_gb = disk_usage.free / (1024**3)
            
            if free_gb < 5:  # 5GB ë¯¸ë§Œ
                self.ui.show_error("ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±", 
                                 f"ì‚¬ìš© ê°€ëŠ¥í•œ ë””ìŠ¤í¬ ê³µê°„: {free_gb:.1f}GB",
                                 "ìµœì†Œ 5GBì˜ ì—¬ìœ  ê³µê°„ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                return False
            
            progress.complete()
        
        if RICH_AVAILABLE:
            self.ui.console.print("[green]âœ… ì‹œìŠ¤í…œ í™˜ê²½ ê²€ì‚¬ ì™„ë£Œ[/green]")
        else:
            print("âœ… ì‹œìŠ¤í…œ í™˜ê²½ ê²€ì‚¬ ì™„ë£Œ")
        
        return True
    
    def _dataset_workflow(self) -> List[Dict[str, Any]]:
        """ë°ì´í„°ì…‹ ì›Œí¬í”Œë¡œìš°"""
        # ê²€ìƒ‰ ê²½ë¡œ ì„¤ì •
        search_paths = self._get_search_paths()
        
        # ë°ì´í„°ì…‹ ê²€ìƒ‰
        with self.ui.show_progress("AI ë°ì´í„°ì…‹ ê²€ìƒ‰ ì¤‘...", total=None) as progress:
            datasets = self.dataset_finder.find_datasets(search_paths, max_results=20)
            progress.complete()
        
        if not datasets:
            if RICH_AVAILABLE:
                self.ui.console.print("[red]âŒ ë°ì´í„°ì…‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.[/red]")
            else:
                print("âŒ ë°ì´í„°ì…‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        # ì›Œí¬í”Œë¡œìš°ë³„ ì„ íƒ
        if self.current_workflow == 'auto':
            # ìë™ ëª¨ë“œ: ìµœê³  ì ìˆ˜ ë°ì´í„°ì…‹ ìë™ ì„ íƒ
            selected_datasets = [datasets[0]]
            if RICH_AVAILABLE:
                self.ui.console.print(f"[green]ğŸ¤– ìë™ ì„ íƒëœ ë°ì´í„°ì…‹: {datasets[0]['name']}[/green]")
            else:
                print(f"ğŸ¤– ìë™ ì„ íƒëœ ë°ì´í„°ì…‹: {datasets[0]['name']}")
        else:
            # ë°˜ìë™/ìˆ˜ë™ ëª¨ë“œ: ì‚¬ìš©ì ì„ íƒ
            selected_indices = self.ui.show_dataset_selection(datasets)
            if not selected_indices:
                return []
            
            selected_datasets = [datasets[i] for i in selected_indices]
        
        # ì‚¬ìš©ì ì„ íƒ íŒ¨í„´ í•™ìŠµ
        for dataset in selected_datasets:
            self.dataset_finder.learn_user_preference(dataset)
        
        return selected_datasets
    
    def _get_search_paths(self) -> List[Path]:
        """ê²€ìƒ‰ ê²½ë¡œ ìƒì„±"""
        search_paths = []
        
        try:
            # ì‚¬ìš©ì í™ˆ ë””ë ‰í† ë¦¬ì˜ ìš°ì„  í´ë”ë“¤
            home_dir = Path.home()
            
            for folder_name in SystemConstants.PRIORITY_FOLDERS:
                folder_path = home_dir / folder_name
                if folder_path.exists():
                    search_paths.append(folder_path)
            
            # í˜„ì¬ ë””ë ‰í† ë¦¬
            search_paths.append(Path.cwd())
            
            # í™˜ê²½ ë³€ìˆ˜ë¡œ ì§€ì •ëœ ê²½ë¡œ
            dataset_env = os.environ.get('DATASET_PATH')
            if dataset_env:
                dataset_path = Path(dataset_env)
                if dataset_path.exists():
                    search_paths.append(dataset_path)
        
        except Exception as e:
            self.logger.warning(f"ê²€ìƒ‰ ê²½ë¡œ ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")
        
        return search_paths
    
    def _process_dataset(self, dataset_info: Dict[str, Any]) -> Optional[Path]:
        """ë°ì´í„°ì…‹ ì²˜ë¦¬ (ì••ì¶• í•´ì œ ë“±)"""
        dataset_path = Path(dataset_info['path'])
        
        # ì••ì¶• íŒŒì¼ì¸ ê²½ìš° í•´ì œ
        if dataset_path.suffix.lower() in SystemConstants.ARCHIVE_EXTENSIONS:
            extract_dir = Path("datasets") / dataset_path.stem
            
            with self.ui.show_progress(f"ì••ì¶• í•´ì œ ì¤‘: {dataset_path.name}", total=None) as progress:
                result = self.archive_processor.extract_archive(
                    dataset_path, 
                    extract_dir
                )
                progress.complete()
            
            if result['success']:
                if RICH_AVAILABLE:
                    self.ui.console.print(f"[green]âœ… ì••ì¶• í•´ì œ ì™„ë£Œ: {result['extracted_files']}ê°œ íŒŒì¼[/green]")
                else:
                    print(f"âœ… ì••ì¶• í•´ì œ ì™„ë£Œ: {result['extracted_files']}ê°œ íŒŒì¼")
                return extract_dir
            else:
                self.ui.show_error("ì••ì¶• í•´ì œ ì‹¤íŒ¨", 
                                 result.get('error_message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'))
                return None
        else:
            # ì´ë¯¸ í•´ì œëœ í´ë”
            return dataset_path
    
    def _training_configuration(self, dataset_path: Path) -> Optional[TrainingConfig]:
        """í›ˆë ¨ ì„¤ì • êµ¬ì„± (ëª¨ë“  ëª¨ë“œì—ì„œ ì‚¬ìš©ìê°€ ëª¨ë¸ ì„ íƒ)"""
    
        # ëª¨ë“  ì›Œí¬í”Œë¡œìš° ëª¨ë“œì—ì„œ ì‚¬ìš©ìê°€ ëª¨ë¸ ì„ íƒ
        selected_model = self.training_engine.show_model_selection(self.current_workflow)
    
        if self.current_workflow == 'auto':
            # ì™„ì „ ìë™ ëª¨ë“œ - ëª¨ë¸ì€ ì‚¬ìš©ì ì„ íƒ, ë‚˜ë¨¸ì§€ëŠ” ìë™
            config = self.training_engine.auto_configure_training(dataset_path, self.current_workflow, selected_model)
            if RICH_AVAILABLE:
                self.ui.console.print("[green]ğŸ¤– ì„ íƒëœ ëª¨ë¸ë¡œ ìµœì  ì„¤ì •ì„ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.[/green]")
            else:
                print("ğŸ¤– ì„ íƒëœ ëª¨ë¸ë¡œ ìµœì  ì„¤ì •ì„ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.")
        
        elif self.current_workflow == 'semi_auto':
            # ë°˜ìë™ ëª¨ë“œ - ëª¨ë¸ì€ ì‚¬ìš©ì ì„ íƒ, AI ì¶”ì²œ í›„ ì‚¬ìš©ì í™•ì¸
            config = self.training_engine.auto_configure_training(dataset_path, self.current_workflow, selected_model)
        
            if RICH_AVAILABLE:
                # AI ì¶”ì²œ ì„¤ì • í‘œì‹œ
                config_table = Table(title="ğŸ¤– AI ì¶”ì²œ ì„¤ì •", show_header=False)
                config_table.add_column("ì„¤ì •", width=15, style="cyan")
                config_table.add_column("ê°’", style="white")
            
                config_table.add_row("ëª¨ë¸", config.model_name)
                config_table.add_row("ì—í­ ìˆ˜", str(config.epochs))
                config_table.add_row("ë°°ì¹˜ í¬ê¸°", str(config.batch_size))
                config_table.add_row("ì´ë¯¸ì§€ í¬ê¸°", str(config.img_size))
                config_table.add_row("í•™ìŠµë¥ ", str(config.learning_rate))
            
                self.ui.console.print(config_table)
            
                if not Confirm.ask("ì´ ì„¤ì •ìœ¼ë¡œ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?", default=True):
                    # ìˆ˜ë™ ëª¨ë“œ - ëª¨ë“  ì„¤ì •ì„ ì‚¬ìš©ìê°€ ì§ì ‘ ì…ë ¥
                    config = TrainingConfig()
                    config.model_name = selected_model  # ì‚¬ìš©ì ì„ íƒ ëª¨ë¸ ì ìš©
                
                    # ê¸°íƒ€ ì„¤ì •ë“¤
                    if RICH_AVAILABLE:
                        config.epochs = IntPrompt.ask("ì—í­ ìˆ˜", default=100)
                        config.batch_size = IntPrompt.ask("ë°°ì¹˜ í¬ê¸°", default=16)
                        config.img_size = IntPrompt.ask("ì´ë¯¸ì§€ í¬ê¸°", default=640)
                    else:
                        try:
                            config.epochs = int(input("ì—í­ ìˆ˜ (ê¸°ë³¸ê°’ 100): ") or 100)
                            config.batch_size = int(input("ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’ 16): ") or 16)
                            config.img_size = int(input("ì´ë¯¸ì§€ í¬ê¸° (ê¸°ë³¸ê°’ 640): ") or 640)
                        except ValueError:
                            print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            else:
                print("AI ì¶”ì²œ ì„¤ì •:")
                print(f"ëª¨ë¸: {config.model_name}")
                print(f"ì—í­: {config.epochs}")
                print(f"ë°°ì¹˜ í¬ê¸°: {config.batch_size}")
            
                confirm = input("ì´ ì„¤ì •ìœ¼ë¡œ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower()
                if confirm != 'y':
                    # ìˆ˜ë™ ëª¨ë“œ - ëª¨ë“  ì„¤ì •ì„ ì‚¬ìš©ìê°€ ì§ì ‘ ì…ë ¥
                    config = TrainingConfig()
                    config.model_name = selected_model  # ì‚¬ìš©ì ì„ íƒ ëª¨ë¸ ì ìš©
                
                    # ê¸°íƒ€ ì„¤ì •ë“¤
                    if RICH_AVAILABLE:
                        config.epochs = IntPrompt.ask("ì—í­ ìˆ˜", default=100)
                        config.batch_size = IntPrompt.ask("ë°°ì¹˜ í¬ê¸°", default=16)
                        config.img_size = IntPrompt.ask("ì´ë¯¸ì§€ í¬ê¸°", default=640)
                    else:
                        try:
                            config.epochs = int(input("ì—í­ ìˆ˜ (ê¸°ë³¸ê°’ 100): ") or 100)
                            config.batch_size = int(input("ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’ 16): ") or 16)
                            config.img_size = int(input("ì´ë¯¸ì§€ í¬ê¸° (ê¸°ë³¸ê°’ 640): ") or 640)
                        except ValueError:
                            print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        else:
            # ìˆ˜ë™ ëª¨ë“œ - ëª¨ë“  ì„¤ì •ì„ ì‚¬ìš©ìê°€ ì§ì ‘ ì…ë ¥
            config = TrainingConfig()
            config.model_name = selected_model  # ì‚¬ìš©ì ì„ íƒ ëª¨ë¸ ì ìš©
        
            # ê¸°íƒ€ ì„¤ì •ë“¤
            if RICH_AVAILABLE:
                config.epochs = IntPrompt.ask("ì—í­ ìˆ˜", default=100)
                config.batch_size = IntPrompt.ask("ë°°ì¹˜ í¬ê¸°", default=16)
                config.img_size = IntPrompt.ask("ì´ë¯¸ì§€ í¬ê¸°", default=640)
            else:
                try:
                    config.epochs = int(input("ì—í­ ìˆ˜ (ê¸°ë³¸ê°’ 100): ") or 100)
                    config.batch_size = int(input("ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’ 16): ") or 16)
                    config.img_size = int(input("ì´ë¯¸ì§€ í¬ê¸° (ê¸°ë³¸ê°’ 640): ") or 640)
                except ValueError:
                    print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
        config.dataset_path = str(dataset_path)
    
        # í›ˆë ¨ í™˜ê²½ ì„¤ì •
        if not self.training_engine.setup_training_environment(config):
            return None
    
        return config
    
    def _execute_training(self, config: TrainingConfig):
        """í›ˆë ¨ ì‹¤í–‰"""
        if RICH_AVAILABLE:
            self.ui.console.print("\n[bold green]ğŸš€ AI ëª¨ë¸ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤![/bold green]")
        else:
            print("ğŸš€ AI ëª¨ë¸ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤!")
        
        # í›ˆë ¨ ì‹¤í–‰
        success = self.training_engine.start_training(config)
        
        if success:
            if RICH_AVAILABLE:
                self.ui.console.print("\n[green]ğŸ‰ í›ˆë ¨ í”„ë¡œì„¸ìŠ¤ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤![/green]")
            else:
                print("ğŸ‰ í›ˆë ¨ í”„ë¡œì„¸ìŠ¤ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            if RICH_AVAILABLE:
                self.ui.console.print("\n[red]âŒ í›ˆë ¨ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.[/red]")
            else:
                print("âŒ í›ˆë ¨ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    def _cleanup(self):
        """ì •ë¦¬ ì‘ì—…"""
        try:
            # í•˜ë“œì›¨ì–´ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€
            self.hardware_monitor.stop_monitoring()
            
            # ì„¤ì • ì €ì¥
            self.config_manager.save_config()
            
            # ì²´í¬ì„¬ ìºì‹œ ì €ì¥
            self.integrity_manager.save_checksum_cache(Path("configs/checksum_cache.json"))
            
            self.logger.info("ì‹œìŠ¤í…œ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"ì •ë¦¬ ì‘ì—… ì¤‘ ì˜¤ë¥˜: {e}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸš€ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        # AI í›ˆë ¨ ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ì‹¤í–‰
        system = AITrainingSystem()
        system.run()
    except Exception as e:
        print(f"ì‹œìŠ¤í…œ ì‹œì‘ ì‹¤íŒ¨: {e}")
        traceback.print_exc()

if __name__ == "__main__":
    main()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¯ AI í›ˆë ¨ ì‹œìŠ¤í…œ v3.0 ì™„ì„±!
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
ğŸ‰ ì¶•í•˜í•©ë‹ˆë‹¤! AI í›ˆë ¨ ì‹œìŠ¤í…œ v3.0ì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!

âœ¨ v2.2 â†’ v3.0 ì£¼ìš” ì—…ê·¸ë ˆì´ë“œ ìš”ì•½:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ—ï¸ ì•„í‚¤í…ì²˜:
   â€¢ ì™„ì „í•œ ëª¨ë“ˆí™” ì„¤ê³„ë¡œ ì¬êµ¬ì„±
   â€¢ ê°ì²´ ì§€í–¥ í”„ë¡œê·¸ë˜ë° íŒ¨ëŸ¬ë‹¤ì„ ì ìš©
   â€¢ ê° ì»´í¬ë„ŒíŠ¸ì˜ ë…ë¦½ì„±ê³¼ ì¬ì‚¬ìš©ì„± ê·¹ëŒ€í™”

ğŸ›¡ï¸ ë³´ì•ˆ ë° ì•ˆì •ì„±:
   â€¢ ê²¬ê³ í•œ ê²½ë¡œ ê²€ì¦ ì‹œìŠ¤í…œ (ê²½ë¡œ íƒìƒ‰ ê³µê²© ë°©ì§€)
   â€¢ ì…ë ¥ ê²€ì¦ ë° SQL ì¸ì ì…˜ ë°©ì§€
   â€¢ íŒŒì¼ ë¬´ê²°ì„± ê²€ì¦ (SHA-256, CRC32)
   â€¢ ìë™ ë°±ì—… ë° ë³µì› ì‹œìŠ¤í…œ

ğŸ“Š ëª¨ë‹ˆí„°ë§:
   â€¢ CPU, GPU, NPU ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
   â€¢ ì˜ˆì¸¡ ë¶„ì„ ê¸°ë°˜ ì„±ëŠ¥ ìµœì í™”
   â€¢ Rich ë¼ì´ë¸ŒëŸ¬ë¦¬ ê¸°ë°˜ ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ
   â€¢ í•˜ë“œì›¨ì–´ë³„ ë§ì¶¤í˜• ì¶”ì²œ ì‹œìŠ¤í…œ

ğŸ§  AI ê¸°ëŠ¥:
   â€¢ ìŠ¤ë§ˆíŠ¸ ë°ì´í„°ì…‹ ê²€ìƒ‰ (ê°€ì¤‘ì¹˜ ì ìˆ˜ ì‹œìŠ¤í…œ)
   â€¢ ì••ì¶•íŒŒì¼ AI ë¯¸ë¦¬ë³´ê¸° ê¸°ëŠ¥
   â€¢ ì‚¬ìš©ì íŒ¨í„´ í•™ìŠµ ë° ê°œì¸í™”
   â€¢ AI ê¸°ë°˜ ì˜¤ë¥˜ í•´ê²° (ChatGPT ì—°ë™)

ğŸ¨ ì‚¬ìš©ì ê²½í—˜:
   â€¢ Rich ê¸°ë°˜ ê³ ê¸‰ í„°ë¯¸ë„ UI
   â€¢ ë‹¤êµ­ì–´ ì§€ì› (í•œêµ­ì–´/ì˜ì–´)
   â€¢ ìƒí™©ë³„ í†µí•© ë„ì›€ë§ ì‹œìŠ¤í…œ (!help)
   â€¢ ì›Œí¬í”Œë¡œìš° ì„ íƒ (ì™„ì „ìë™/ë°˜ìë™/ìˆ˜ë™)

âš¡ ì„±ëŠ¥:
   â€¢ ë©€í‹°ìŠ¤ë ˆë”© ë³‘ë ¬ ì²˜ë¦¬
   â€¢ ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬
   â€¢ ìºì‹± ì‹œìŠ¤í…œìœ¼ë¡œ ë°˜ë³µ ì‘ì—… ìµœì í™”
   â€¢ NPU ê°€ì† ì§€ì› (Intel NPU ìš°ì„ )

ğŸ”§ ê¸°ìˆ ì  ê°œì„ :
   â€¢ í¬ê´„ì ì¸ ì˜ˆì™¸ ì²˜ë¦¬
   â€¢ 5ë‹¨ê³„ ë¡œê¹… ì‹œìŠ¤í…œ (DEBUG â†’ CRITICAL)
   â€¢ ì„¤ì • ë°±ì—…/ë³µì› ì‹œìŠ¤í…œ
   â€¢ ë²„ì „ ê´€ë¦¬ ë° í˜¸í™˜ì„± ë³´ì¥

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸš€ ì‚¬ìš©ë²•:
   1. Python 3.8+ í™˜ê²½ì—ì„œ ì‹¤í–‰
   2. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜: pip install torch ultralytics rich pillow psutil GPUtil
   3. ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰: python automatic_training_v3.py
   4. í™”ë©´ ì•ˆë‚´ì— ë”°ë¼ ì§„í–‰

ğŸ’¡ ì£¼ìš” íŠ¹ì§•:
   â€¢ ì–´ë–¤ í”„ë¡¬í”„íŠ¸ì—ì„œë“  !help ì…ë ¥ìœ¼ë¡œ ë„ì›€ë§ í™•ì¸
   â€¢ ESC í‚¤ë¡œ ì´ì „ ë‹¨ê³„ ë³µê·€ (ì§€ì›ë˜ëŠ” ê²½ìš°)
   â€¢ Ctrl+Cë¡œ ì•ˆì „í•œ í”„ë¡œê·¸ë¨ ì¢…ë£Œ
   â€¢ ìë™ ì„¤ì • ì €ì¥ ë° ë‹¤ìŒ ì‹¤í–‰ì‹œ ë³µì›

ğŸ”® ë¯¸ë˜ í™•ì¥ ê°€ëŠ¥ì„±:
   â€¢ ë” ë§ì€ AI í”„ë ˆì„ì›Œí¬ ì§€ì›
   â€¢ í´ë¼ìš°ë“œ í›ˆë ¨ ì—°ë™
   â€¢ ëª¨ë°”ì¼ ì•± ì—°ë™
   â€¢ ì›¹ ì¸í„°í˜ì´ìŠ¤ ì œê³µ

ì´ì œ ì—¬ëŸ¬ë¶„ì˜ AI ëª¨ë¸ í›ˆë ¨ì´ ì´ì „ë³´ë‹¤ í›¨ì”¬ ì‰½ê³  íš¨ìœ¨ì ì´ ë  ê²ƒì…ë‹ˆë‹¤! ğŸ¯
"""
